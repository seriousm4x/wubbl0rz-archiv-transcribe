MonkaW
Moin Leute
Es sei aber schnell gewesen
Soll ich mal eine Minute
unterstreamen
So
Ein Mod-Check.
Ach, wenn wir gerade dabei sind.
Ich mach mal kurz meine VM an und mach mal Updates und Reboot.
Wir haben zwar gestern schon Updates und Reboot gemacht, aber ihr wisst ja, arch Linux by
the way, da vergehen keine 15 Minuten bis es neue Updates gibt.
Letzte Woche war ich nicht online, da ging es mir nicht gut, aber heute ist es wieder besser.
Ja, den Stream von gestern habe ich gelöscht, weil irgendjemand meine Anfangsbuchstaben vom Namen
und zumindest...
Ja, das wollte ich nicht im Chat stehen haben.
Da hat irgendjemand, frag mich nicht wie, wahrscheinlich arbeitet der bei Vodafone oder so, keine Ahnung.
Oder bei irgendeinem Dienstleister.
Und hat dann irgendwie mal was rausgekriegt, ach keine Ahnung.
Was willst du machen, ja.
So.
Guck mal hier, Updates.
AWS.
Warum haben wir Updates?
AWS Sachen.
Nur 16, ja.
Nur 16 Updates.
Ich weine immer hin.
Gestern bin ich off.
Wann? Um 15 Uhr oder so haben wir Updates gemacht.
16 Uhr.
Also hatten wir jetzt zumindest schon mal einen halben Tag Zeit.
Da kann es schon mal 16 Pakete Updates geben.
Warum haben wir überhaupt AWS-Sachen installiert, Chat?
Warum habe ich AWS-SDK-C++ installiert?
Was, warum?
Wir aninstallen das mal und gucken, ob sich irgendwas beschwert.
AWS.
Alter, warum?
Warum ist es so viel?
Ah.
Required by?
Okay, das uninstallen wir alles jetzt.
Ich weiß wirklich nicht, warum ich das installiert habe.
Required by?
Ach, nix hat das.
Das habe ich gelesen.
Ja, mit dem Public Peering.
Das wird noch Paints Champ.
Oder auch nicht.
Vielleicht merkt man auch.
Ich tippe ja irgendwie drauf, dass man wahrscheinlich fast gar nichts davon merken wird.
Außer vielleicht am Wochenende, wenn viele Leute es wieder benutzen.
Aber gucken wir mal.
Ich hoffe ja, dass es bald Glasfaserausbau endlich gibt.
Das wollte ich dich fragen.
Was denn?
Das? Was ist das?
Okay, das können wir nicht aninstallen, weil nix am Start ist.
Die haben in den 90ern teilweise Glasfaser ausgebaut.
Aber die waren doch dann inkompatibel zu neueren Sachen.
War das nicht so, dass im Osten teilweise in den 90ern Glasfaser ausgebaut wurde?
Und das konnte man dann nicht verwenden.
Wisst ihr, was mir teilweise auffällt, wenn man alte Sachen im Fernsehen guckt?
Dass wir gar nicht so krass hinten dran waren, was Digitalisierung und Technik angeht, mal früher.
Und zwar, meine Mutter, die guckt gerne so richtig altes Zeug im Fernsehen.
Was ist richtig altes Zeug? So Zeug irgendwie aus den 80ern oder so.
Guckt die gerne in der Mediathek oder bei Amazon oder so.
Die ist halt selbst schon ein bisschen älter.
Und die guckt immer so altes Zeug.
Hat die letztens irgendeine Polizeiserie oder so geguckt aus den 80ern.
und da meinte einer
ja ja
überall nur noch Computer
oh
die Mods schlagen zu
wieso Max hat er noch was geschrieben
gerade oder
oder hast du das von gestern rausgekriegt
Ja, ich finde das auch nicht gut.
Also.
Genau, da meinte so irgendwie in dieser, ich weiß nicht was das war, in irgendeiner Serie, die sie geguckt hat, meinte so, meinte irgendein Polizist dann im Fernsehen in dieser Serie, ja, ja, überall nur noch Computer.
und das war irgendeine Serie von, frag mich nicht, 1985 oder so.
Und das war wohl echt mal eine Zeit, da waren wir gar nicht schlecht,
da waren wir relativ zukunftsweisend.
Aber dann ging es bergab.
Dann ist einfach 30 Jahre nichts passiert.
Ich meine, 85?
Der hat gesagt, der PC wird sich nicht durchsetzen.
Ja, es gab doch auch mal irgendwie diese Aussage, 384k reichen für immer, die übrigens nicht
von Bill Gates kommt, auch wenn ihm das immer nachgesagt wird.
Ja, man muss sich mal vorstellen, 1985, da war das ja wirklich noch was richtig Neues.
In Japan ist es noch schlimmer, die nutzen noch Discount.
Ich dachte eigentlich in Japan sind die voll modern.
Ich habe letztens ein Video geguckt von...
Da war einer in so einem Rahmenshop.
Und das ging komplett automatisch.
Da bist du hingegangen an irgendeinen Automat.
Da kam dann ein Zettel raus.
Den hast du dann irgendwo woanders wieder reingesteckt.
Und da ging eine Klappe auf.
Da kam dann eine Suppe raus.
Und sonst war es voll automated.
In Japan nutzen sie auch noch Faxgeräte.
Wo wir gerade beim Thema Faxgeräte sind.
Ich habe Digitalisierung in Deutschland letztens wieder gespürt.
Und ich war ganz grob gesagt, ich war beim Arzt.
Und der meinte, also ich habe da vorher angerufen.
einen Tag vorher und hab
gefragt, ob ich vorbeikommen kann und sie, ja passt
und hat gemeint, bringen sie doch mal
die letzten Blutwerte mit
und
ja, hab ich gesagt, okay
bin ich morgens bei meinem Hausarzt vorbei
hab gefragt, kann ich die letzten Blutwerte
haben, aber das war noch nicht so lange, die waren noch nicht da
also anscheinend kommt diese
diese Sache vom Labor immer
keine Ahnung, ich sag jetzt mal
um 9 oder so
und da meinte die dort
ja aber macht nix gehen sie dahin
wenn es dann kommt um 9
dann fax ich das dahin
was ich übrigens sehr nett fand
dass die sich da so mühe gegeben hat
aber es war halt auch geil
da wurde das dann dahin gefaxt
muss man sich mal überlegen
wir haben 2025
Du hast gehört, Japan wollte Disketten abschaffen.
Warum?
Wenn es funktioniert? Disketten sind nice.
Ich, ich, ich mag, ich mag Disketten.
Okay, das ist der Boomer, der aus mir spricht, ne?
Dass ich Disketten mag.
Man muss sagen, Disketten war eigentlich ein bisschen, ein bisschen vor meiner Zeit schon.
Ich hab natürlich auch noch mit Disketten rumhantiert, so ist das nicht.
Aber das war schon auslaufend, ja?
Also, es waren eigentlich dann später hauptsächlich CDs und, achso, ich wollte eigentlich Updates
und kann sich noch einer an die ersten
CD-Brenner erinnern?
Wenn du da eine CD gebrannt hast, natürlich
selbstverständlich nur Linux-Distributionen, die man runtergeladen
hast.
Ne, die
5 Zoll Disketten habe ich nicht mehr benutzt.
Ich habe die sicherlich mal in der Hand gehabt und sicherlich auch mal
irgendwo reingesteckt.
Hyper-Gachi. Aber
ich hatte kein PC mit
5 Zoll oder 5,2 Zoll
Diskettenlaufwerk. Ich hatte nur diese 3,5 Zoll.
Ja, aber kann sich noch irgendjemand...
Ich hab mal reboot.
Kann sich noch irgendjemand an die...
ersten CD-Brenner erinnern?
Die waren nicht schnell.
Die waren dann irgendwie...
einfach zweifach oder so.
Oder maximal vierfach.
Ich glaube, ich hatte einen Vierfachbrenner.
Das war schon voll krasser Hightech-Shit.
Und wenn du...
während dem CD brennen,
den Rechner benutzt hast,
dann gab es
einen Buffer-Underrun und die CD war
kaputt.
Antwe, danke schön für den Sub.
Kann sich an diesen Buffer-Underrun-Brenner-Zeug
noch irgendjemand erinnern? Wahrscheinlich
alle, die hier ein bisschen jünger sind,
die denken, Max, was laberst du
wieder für altes Zeug?
Aber das war damals so.
Wenn der Rechner nicht schnell genug die CD
beschreiben konnte, weil er was drauf
gemacht hat, dann ist das irgendwie
abgerissen und der Brenner konnte dann
nicht mehr an der gleichen Stelle weitermachen.
Und dann war die CD im Arsch.
Das heißt, wenn du gebrannt hast,
wenn du damals eine CD gebrannt hast,
hast du am besten für die
halbe Stunde,
die das gebraucht hat,
oder je nachdem, was du da gebrannt hast,
hast du am besten mal die Finger vom Rechner
gelassen oder nur ganz, ganz wenig gemacht.
Also das...
Da hast du dich wirklich wie der krasse Hacker-Man gefühlt, wenn du da so Sachen wie...
Ach, was auch richtig nice war...
Gibt es eigentlich noch CD-RW-Rohlinge?
gibt's noch
gibt's noch früher hatte ich auch mal so eine 50er spindel zumindest was ich eigentlich was
ich eigentlich sagen wollte ich habe mich damals wieder ultra hacker mein gefühlt und zwar ich
hatte einen cd lw brenner habe ich jetzt eigentlich schon gebootet leute ich
glaube schon oder aber hier nochmal package updates aber gucken ob die
mochi heute geht jetzt wie man sie warum es eigentlich okay war wie mochi
Aua! Warum ist das eigentlich kaputt? Solve by deleting cache. Okay.
You're done?
Achso, ja Moment, yes. Okay und jetzt geht das oder was?
easy moment jetzt lasst uns mal gucken ob es auch funktioniert
hat man jetzt habt wie mochi das ist das falsche das neue team og das da wir
machen nämlich gerade ein Fimoji Update
auf 17. Wir hatten
vorher 16.
New Emojis
this release. Was ist das für einer?
Chat.
Der ist ja pock.
Den brauche ich. Was ist das
für einer? Wie heißt das?
Das ist ein Distorted Face Emoji.
Okay, noch haben wir das nicht.
Das...
Okay, haben wir noch nicht.
Gibt's noch nicht.
Gibt's noch nicht.
Okay.
Jetzt updaten wir das Emoji.
Packet Tracer failed.
Moment, das geht jetzt wahrscheinlich.
Guck, jetzt haben wir's.
Bam.
Timoji-Update hat es gefixt.
Das ist ja geil.
Aber Moment, mein Terminal hat es noch nicht gecheckt.
Immer noch nicht.
Also mein Terminal kann das nicht.
Ich glaube, wir sind zu neu.
Guck mal, mein Browser kriegt es auch nicht hin.
das ist wir sind zu bleeding edge mit den emojis wisst ihr was wir fixen das jetzt
was wollte ich jetzt eigentlich erzählen mit der cd rw ach genau ich habe mich damals wieder
ultra krasse hackerman gefühlt weil ich hat ein cd rw brenner und ich habe
damals den cd rw brenner als laufwerk in windows gemountet das ging ich bin mir
nicht mehr sicher ob das windows bordmittel waren oder ob das ja irgendeine
zusatzsoftware war keine ahnung
Also anscheinend kann mein Browser die Emojis auch noch nicht.
Ne, ne, ne, okay, das ist zu neu.
Ja und da habe ich mein CD-RW Laufwerk gemountet, quasi als Disk in Windows hier.
Ich meine, das sah damals noch ein bisschen anders aus.
Und ja, im Endeffekt hatte ich dann hier quasi meinen Brenner als Disc und habe mich richtig geil gefühlt, weil ich mir eingeredet habe, ich habe jetzt unendlich Speicher, also ich habe quasi eine unendlich große Festplatte, habe ich mir damals eingeredet.
Weil ich konnte ja da einfach Dateien drauf kopieren und runter kopieren und sowas.
Das war halt lahm as fuck, weil es war ein CD-LW-Brenner mit einem Vierfach oder so.
Aber ich dachte mir, okay, jetzt hast du unendlich Festplattenplatz.
Total dämlich, ja, hat damit überhaupt nichts zu tun.
Aber ich habe mich super krass gefreut, weil ich nahezu unendlich Festplattenplatz hatte,
dadurch, dass ich meinen LW-Brenner gemountet habe unter Windows.
Ich habe gedacht, ich bin der Hyper-Hacker, man.
Ich bin der Einzige, der auf so eine geile Idee gekommen ist.
Benutzt habe ich es dann nie, weil es langsam wie Sau war.
Es war schon cool.
Also ich muss sagen, ich vermisse das jetzt nur zum Teil, dieses Oldschool-Zeug.
Also ich glaube, zum größten Teil vermisse ich halt die Zeit und dass das halt alles neu und nice war.
Man muss sagen, so wirklich toll war das damals auch nicht.
Also, wie gesagt, Buffer-Underrun beim CD brennen.
Generell CD brennen und so Zeug, das war schon ziemlich Painstrap.
So mit USB-Stick und gerade mit einem schnellen USB ist das heute schon deutlich angenehmer und nicer als CDs zu brennen.
Ja, ISDN-Internet war auch nicht so geil.
ich sehe übrigens gerade meine readme ist ist voll voll fail das ding heißt
überhaupt nicht ihr seid exporter beim ausführen als lob ried mi leute
aber wo ich mich immer gefreut habe damals ist wenn ich windows neu installieren konnte
kennt jemand dieses hype gefühl wenn man windows neu installiert das kat das kann man sich heute
glaube ich nicht mehr vorstellen heute ist die windows installation übelst für den arsch und
irgendwie unspektakulär sag ich mal ja aber damals auf windows installation voll hype weil weil man
dann hoffte irgendwas was vorher nicht funktioniert hat würde nach dem neu installieren funktionieren
Und witzigerweise war das auch oft so.
Es gab mal Zeiten, da hat man sich zusammen getroffen und hatte seinen Rechner dabei.
Beziehungsweise man hat sich von seinen Eltern fahren lassen mit dem Rechner im Kofferraum und einem Röhrenmonitor.
Ich hatte damals einen 21 Zoll CRT.
Das war ein Fond von Samsung, glaube ich.
Oder Samsung?
Was war Sync Master?
Ja!
Genau!
Und die Dinger waren übelst schwer!
Lass mal kurz gucken, ob wir irgendwie rauskriegen, was das Ding wiegt.
Gibt es hier irgendwie Specs?
Gewicht?
Gewicht
120 Watt für den Monitor.
Das braucht heute
das komplette Setup.
Hier.
21,6
Was ist denn LBS?
Pounds oder sowas?
Zu Kilogramm.
7, Alter!
28 28 kilo für den monitor da warst du wenn du das lange noch getragen hast was hier richtig
richtig hier muskulös danach und man hatte damals ja auch nicht einfach nur so ein fett monitor
sondern er macht da so einen richtig krassen
Big Tower.
Aber ne...
Moment.
Was ist das bitte schön für ein Ding?
Changes Shredded.
Was zum Teufel ist das?
So 90er.
Ja, genau.
So Dinger.
Nicht mit so vielen Disketten, aber mit zwei Laufwerken und so drin.
Ja, so sahen die Dinger damals aus.
Also, die Teile waren schwer.
Der Monitor war schwer.
Und du hast dann bestimmt so, keine Ahnung, 35 Kilo oder so geschleppen müssen.
Und dann hat man sich getroffen zusammen.
Jeder hat seinen fetten Big Tower gehabt.
Umso fetter der Big Tower, umso größer der Schwanzvergleich.
Damals hatte man riesenfette Big Tower, die eigentlich damals auch schon zum größten Teil leer waren.
Ne, die hatten keinen Turbo Knopf mehr.
Die waren dann schon Turbo Knopfless.
Zumindest hat man sich da getroffen.
und hat dann seine Rechner zusammengestöpselt, entweder noch über BNC-Kabel oder schon mit einem der ersten Hubs oder Switches
und ganz normalen Netzwerkkabeln mit R45-Stecker.
Zumindest, nachdem man das gemacht hat, ging bei einem, bei mindestens einem oder bei meistens eher mehr Leuten, ging irgendwas nicht.
Damals ist man immer in die Windows-Netzwerk-Umgebung gegangen
Windows 98
Netzwerk-Umgebung
So sah das damals aus
Gibt es da bestimmt ein Bild von
Äh
Netzwerk-Umgebung
Ja, das sieht er aber kein Bild von
Das ist ja doof
Wie heißt das Ding?
Network
Wie heißt das Ding auf
Ja, so sah das aus damals
Bam
Damn.
ZX.
Alter.
Genau.
Guck, da hat man die Netzwerkumgebung aufgemacht.
Und dann hat man gehofft, man sieht die PCs von den Leuten, mit denen man sich zusammengestöpselt hat.
Und das ging meistens aus irgendwelchen Gründen nicht.
Und was hat man dann gemacht?
Wenn das nicht ging?
selbstverständlich hat man windows neu installiert was sonst das heißt von allen möglichen netzwerk
party aber das damals genannt von allen möglichen so netzwerk geschichten war immer eigentlich der
erst am ersten tag die ersten zwei drei stunden waren alle leute damit beschäftigt erst mal
windows neu zu installieren windows neu installieren und danach wurde erst mal
wild die neuesten sachen geschert selbstverständlich nur linux
distribution was sonst die neuesten sachen wurde geschert über hier windows
shares deswegen war das wichtig dass die netzwerk umgebung ging bis wir irgendwann
mal drauf gekommen sind man kann auch glaube ich hier oben das war glaube ich
unter windows 98 da sind wir immer drauf gekommen
Man kann hier oben auch die Adresse eingeben.
Zumindest hat man dann die ersten paar Stunden damit verbracht, Windows neu zu installieren.
Und dann die neuesten Sachen zu sharen.
Und dann hat man beispielsweise Half-Life gespielt.
Alle möglichen Half-Life-Mods.
Also Multiplayer.
Und hat sich gefreut, wie geil das ist.
Wir haben damals auch ein bisschen zusammen Half-Life-Maps gebaut und sowas.
War eigentlich richtig, richtig cool.
Ja.
Aber Windows-Installation, Windows-Neuinstallation jedes Mal.
Ach ja, und jetzt wo ich es hier gerade sehe.
Moment, der hat es nicht richtig gemacht.
Das ist falsch, wie der das macht hier.
Du musstest...
Hier.
musstest du eigentlich noch
NetBIOS und NetBUI
hinzufügen, damit die
Netzwerkumgebung richtig funktioniert hat.
Ich weiß bis heute
nicht, was NetBUI
überhaupt ist.
NetBIOS
Okay, NetBIOS
Extended User Interface.
Alles klar.
Und
IPX, ich
Ich bilde mir nämlich ein, dass damals viele Games haben noch IPX gebraucht, dass das funktioniert hat, netzwerktechnisch.
Und ich glaube sogar, dass Half-Life 1 am Anfang IPX gebraucht hat.
Ja.
Ich glaube, am Anfang für lokalen Multiplayer war das IPX.
und später, mein Half-Life wurde ja
damals auch wirklich, also
das kannte man gar nicht, so viel wurde das
gepatcht damals, gab es ja laufend neue Versionen
also laufend alle paar Monate
und die musste man ja auch irgendwo herkriegen
irgendeiner hatte da eine CD dabei
mit einer neueren Half-Life-Version und dann haben erstmal alle geupdatet
und sowas
zeig mal
Retro-inspiriertes Tower-Gehäuse.
Aber so ganz, der ist wirklich nur retro-inspiriert.
Also sah das damals nett aus.
Der Powerknopf, also der, der, diese Ding war in der Regel am Netzteil hinten und vorne hat es so einen ganz normalen Knopf.
Oder ist es noch, ist es noch von noch was Älterem inspiriert?
Ach, guck mal, die haben sogar oben Fake CD-Laufwerke, äh, nicht CD-Laufwerke, Diskettenlaufwerke.
Okay, das ist noch
Das ist noch
Von noch älteren Gehäusen inspiriert
Weil du hast hier noch so eine Megahertz Anzeige
Und sowas mit einem Turbo Knopf
Das hatten meine PCs
Gar nicht mehr
Naja, so, genug
Alles Zeug
Aber so war das damals
Erstmal 27 Kilo schweren Monitor geschleppt
Die sind nicht fake?
Aber die Blende ist fake, oder?
Die Blende ist fake.
Du kannst die wahrscheinlich rausmachen.
Die Blende hier vorne ist halt so eine 5,2 Zoll Diskettenlaufwerkblende.
Die kannst du wahrscheinlich rausmachen.
Steht ja auch hier drei Fronteinschübe.
Und das dann.
Dental Rocks, danke schön für den Sub.
kannst du hier wahrscheinlich dann,
falls du ein CD-Laufwerk hast. Ich muss euch sagen,
meine letzten, boah,
keine Ahnung,
kann mich gar nicht dran erinnern,
ähm,
bestimmt die letzten 5 PCs oder so,
die ich hatte,
Desktop-PCs,
die hatten alle keine optischen Laufwerke
mehr. Habt ihr noch optische Laufwerke
bei euch am Computer? Also so
eingebaut im Gehäuse? Ich hab hier
hinter mir
im Haufen mit
Technik-Krams habe ich ein
USB-CD oder
DVD-Laufwerk liegen.
Falls man mal wirklich irgendwie was braucht.
Aber das brauche ich eigentlich nie.
Ich habe zur Not eins halt.
Ja, aber...
habt ja auch nicht was und dvd laufwerk ist
wisst ihr ich würde mir gerne aber das ist ich weiß dass es schwachsinn ist ja also ich werde
damit nichts machen ich wollte mir mal meinen damaligen traum rechner zusammenbauen so aus
der zeit 19 97 so rum also sprich mit einer wu2 sli und sowas drin aber ich habe mir gedacht
erstens ist das zeug wahrscheinlich schweine teuer heutzutage und ich würde es glaube ich
nur machen das zusammenbauen willens nicht dass ich da ich würde danach keine retro games drauf
spielen, so wie ich mich kenne.
Wir gucken mal, was kostet eigentlich eine Voodoo 2
heutzutage?
Voodoo 2.
Oh, oh, oh, oh.
Hier.
Hier kannst du zwei Voodoo 2 SLI holen.
Die kosten 450 Euro.
Nutzt hier jemand Sandscheine?
Ich habe letztens Apollo installiert.
Auf so einem Mini-PC.
Nicht Sandschein, sondern Apollo.
Ich weiß auch nicht mehr, was...
Ich glaube, weil der Sound damit funktioniert hat, mit Sunshine nicht, irgendwie sowas war das,
habe ich installiert und das ging eigentlich ganz gut.
Aber ich habe es danach auch nicht mehr verwendet, ich wollte einfach nur mal angucken.
Das ist ja so die Nvidia Game Stream Reimplementierung.
Also, man könnte sich ja fast schon überlegen, das als Geldanlage zu kaufen
und in 10 Jahren ist das dann das 30-fache Wert oder so.
Vielleicht.
Vielleicht auch nicht.
War das das SLI-Kabel?
Man musste ja damals noch
den Output
durchpassen.
Also die konnten ja wirklich nur 3D, diese Dinger.
Man muss sich das vorstellen,
du hast damals zwei Grafikkarten
gebraucht. Du hast so eine Voodoo 2
Gebraucht zum Beispiel Für. 3d Beschleunigung und Damit Du 2d Sachen Darstellen Konntest hast Du noch normale Grafikkarte Gebraucht also dass
Das ging gar nicht so
Du musstest also durchschleifen
Da Wurde das bild signal wurde quasi Durch durchgeschleift Durch Die Grafikkarte
Später Konnten Die Grafikkarten also eine generation Später Konnten Die Grafikkarten an 3d und 2d zusammen Da Gab's Dann
genau und danach gab es dann mit AGP
da gab es dann so die erste
Nvidia TNT
Riva TNT 1 hieß das Ding noch
ich hatte auch eine, hatte ich glaube ich schon mal
so eine
so eine hatte ich damals
und die hat glaube ich
250 Schmack oder sowas gekostet
und ich hab mir gedacht, boah sind Grafikkarten teuer
hätte ich mal gewusst, dass du heute
2000 Euro ausgibst für eine Grafikkarte
dann
Tja, das hätte ich nicht geglaubt damals.
Ja.
Die war extremely
pog.
Damals.
Testberichte.
Auf der Karte
verrichtet ein TNT mit 90
Megahertz und 110 Megahertz
Speichertakt seine Dienste.
Hui!
Teuren SG-Ramm spendiert.
Guck mal hier,
guck mal hier, Leute.
Die Karte, lasst euch das mal auf der Zunge zergehen.
Wir reden hier von 1998.
Die Karte kann Auflösung
bis
1900 mal 1200
85 Hertz darstellen.
Das war massive, Alter, für die damalige Zeit.
Natürlich 4 zu 3 Auflösung.
Das ist mehr Pixel als Full HD, Leute.
Das war richtig...
Ich glaube, ich hatte auch keinen Monitor, der das kann.
Äh, waren das wirklich...
Chat, war das nicht 1600x1200?
War das 1900x1200?
Ne, das war doch 1600x1200, oder?
Ja.
Die haben sich verschrieben.
Moin, Mümpf...
Schön, dass du da bist.
Ja, das war 1.600, aber 1.200.
Ich wollte gerade sagen,
da hat sich der Tester verschrieben.
Hier unten.
Ach so.
Aha.
Bei 16 Millionen Farben sind es noch 1.600.
Okay, die konnte anscheinend wirklich so viel.
Abgedreht.
85 Hertz.
hast du dich damals nicht beschwert.
85 Hertz war top.
Das kannst du aber auch nicht direkt
vergleichen mit einem LCD.
85 Hertz war top.
85 Hertz hat nichts mehr geflimmert.
Später hatte ich 100.
Konnte mein Monitor 100 Hertz.
aber auch nicht scheiß kommt man damals hat man noch wertgelegt auf ein gutes deutsches handbuch
mit for speed 3 gab es damals dabei
sogar fachbegriff wie frame buffer opencl werden erklärt hier ist immer alles handbuch
Ja, hier erstmal schöne Encoding-Probleme.
Die Seite wurde garantiert damals nicht UTF-8 encoded, sondern, wie hieß das Ding?
Wie hieß das Encoding, was man in Deutschland immer verwendet hat?
Das war so eine, das waren zwei Buchstaben und dann vier Zahlen, glaube ich, so ganz...
cp 1252 kann sein kann sein
genau damals hatten die grafikkarten noch hier so eigene so eigene settings
die sich in die in die systemeinstellung eingehängt haben
Das braucht kein Mensch
Das waren schon coole Zeiten
Irgendwie, 3DMark99
Das waren schon coole Zeiten
Weil
gar nicht so sehr wegen der Technik
allein, sondern weil das halt alles so neu war.
Ja, man war da voll begeistert damals.
Ich glaube, dass es Leuten heute
immer noch so geht, wenn die halt
in meinem Alter sind, wie ich damals
war. Na, 1998
war ich 14
und ich könnte mir durchaus vorstellen,
dass 14-Jährige heute auch noch von Technik
mega begeistert sind, weil die halt
zum ersten Mal damit in Kontakt kommen.
Könnte ich mir vorstellen.
So, aber jetzt gucken wir mal, nachdem wir uns jetzt etwas sidetracked lassen haben, gucken wir, was auf GitHub so trendet.
Und ja, auf die Dinger bin ich tatsächlich gespannt.
Ich habe letztens gesehen, von Asus gibt es einen neuen OLED-Bildschirm mit 700 Hertz, glaube ich.
Ich warte mal. Asus oder 720
Hertz Monitor?
Genau, dieses Ding hier.
Das Ding hat halt wieder einen super griffigen
Produktnamen. Asus ROG Swift
OLED PG27A
QWP-W.
Alles klar.
Gibt es den eigentlich mittlerweile zu kaufen? Und wenn ja,
was kostet
der?
weiß man nicht
also gaming monitor 27 zoll black klasse tannemann bla bla bla dual
mode es gibt okay es gibt was ist ein qhd 1440 p
ja also 1440 p macht der 540 hertz und in 1080p macht 720 hertz oder meinen die
mit HD nur 1280x720. Das wäre natürlich hier ganz nice zu wissen an der Stelle.
G-Sync-kompatibel, Proximity-Sensor, was auch immer. Mich würde mal interessieren, was es kostet.
gibt es da irgendwie sowas wie specs
bla bla bla bla bla
jetzt ich will es nicht anschauen
ich hätte technische daten da oben
haben wir es doch
ok wir akzeptieren
wir müssen die cookies akzeptieren dafür
logisch was sonst
Ne, hier steht keine Auflösung drin.
Ist natürlich auch geil.
Wenn in den technischen Daten nicht die Auflösung drin steht,
das ist schon auch pock.
Oder nicht pock.
Geil.
Ne, ich meine die Auflösung, wo das 720 Hertz schafft.
Support.
Wir gucken jetzt ins Handbuch rein.
Handbuch.
User Guide.
in Phasi.
Alter.
So.
1280.
Aha.
Siehste?
Nicht 1080.
1280.
1200. Also nicht Full HD,
sondern ganz wirklich
das Oldschool HD, wo er 720
Hertz supportet.
Und wo kann der 720?
Ich sehe es hier nicht.
Es geht immer nur bis 540.
Ja, wie jetzt?
Ich sehe hier nichts.
Hier steht immer nur drinne.
Ach hier.
Okay.
1720.
Äh nicht 1720.
1780 mal 720.
Okay das.
Also mit Info-Lady
macht er nur
120? Hä?
Das macht doch
keinen Sinn.
Der macht...
Das da macht er in 540.
Warum macht er kein 1920?
Okay.
Whatever.
Mich interessiert eigentlich nur noch, was das Ding kostet.
Weiß man nicht.
Preis.
price is around
1100
wird wahrscheinlich in Euro das gleiche
sein am Ende, schon ordentlicher Preis für
ein Monitor, ich meine das ist ja auch ein absoluter
Monster Monitor
aber schon krass
Da komme ich mir richtig outdated vor.
Ich habe einen 240, glaube ich zumindest, habe ich einen 240 Hertz Monitor?
Sekunde.
Äh, wo sieht man das? Hier?
Ja, 240 Hertz Monitor habe ich.
Aber auch nur ein Full-HD Monitor.
Ich sitze aber auch ziemlich nah davor.
Kann er noch mehr?
Nee.
Und ich muss sagen, also bis jetzt
bin ich da eigentlich ganz gut mit
gefahren.
Der ist nice.
Der ist groß vor allem.
Funktioniert das überhaupt mit aktuellen Games,
diese Refreshrate? Ja.
Wenn du die passende Grafikkarte hast und nicht alles unbedingt auf Ultra High spielen
musst, geht das.
Wo es natürlich Probleme gibt bei top aktuellen Unreal 5 Games, die nicht auch richtig optimiert
sind, da wo keiner was auf die Reihe kriegt.
Ich kann, das seht ihr nicht, wenn ich euch das hier zeige mit 60 Hertz.
Ich streame ja nur mit
60 FPS oder mit 48.
Mit 48 FPS streame ich.
Das sieht man nicht.
Es ist aber ein Riesenunterschied.
Also 120 zu 60
ist ein Mega-Unterschied.
Man muss sich
vorstellen, es gibt
Leute, die erkennen
den Unterschied zwischen 15 und 30
nicht.
Das kann man sich nicht vorstellen, aber das ist so.
jetzt ist ja kein unterschied was ist das doch sieht doch genauso aus
du kannst frame generation machen ja aber ich bin kein fan von frame
generation das sorgt für input lag
Ja, also
60
60
ist das Mindeste.
Ja.
Drunter ist Geruckel.
Wobei man da echt
anspruchsvoll geworden ist, ne?
Ich glaube, als ich Far Cry 1
gespielt habe damals da hatte ich irgendwie fragt mich nicht da bin ich
wahrscheinlich teilweise nicht mal auf 30 fps gekommen und habe mich gefreut
ich benutze windows eigentlich nur für das nötigste noch deswegen habe ich
doch jemand linux am start benutzt eigentlich für fast alles was ich nicht
unbedingt unter windows machen muss ich benutze windows eben halt für so für
streaming k für bisschen bildbearbeitung und halt spiele mit anti cheat
wobei ich das eine ganze weile nichts mehr gespielt haben mit anti cheat aber
ich werde demnächst tatsächlich wenn ich mal neu installiert habe battlefield 6
spielen das geht also wenn also ich glaube ich könnte mit linux leben wenn es nicht die
einschränkt also komplett mit linux leben wenn es sich die einschränkungen gebe was spiele mit
anti cheat angeht wenn das funktionieren würde also wenn ich auch bei 46 beispielsweise spielen
könnte dann könnte ich auch die streaming und videobearbeitung und bildbearbeitung
unter windows verzichten dann würde ich irgendwas lernen was unter linux geht weil es ist ja nicht
so als mache ich da was super advances müsste ich müsste ich mich immer keine ahnung der wind
sie resolve oder irgendwie so einarbeiten da kann man ja auch gut videoschnitt und sachen
zeug machen unter linux das jahr des linux nächstes jahr ist immer jahr des linux desktops
das nächste jahr ist immer das jahr des linux desktops wisst ihr doch so wir gucken mal kurz
was auf GitHub so trendet.
Wie hast du das alles realisiert?
Alle deine OS-Verteilung auf Platten?
Gar nicht.
Das liegt alles auf C.
Ich habe nicht mal allzu viel Platz.
Aber ich habe die anderen Laufwerke nicht gemountet.
Ich habe noch mehr.
Ich habe auch noch eine Magnet-Festplatte drin.
Aber ich bin gerade mit dem anderen Account nicht eingeloggt.
Das ist eine VM.
Guck hier.
Aber mit dem Setup funktioniert das halt ohne Probleme.
Die VM ist aber auch recht fett.
Die VM hat 8 Kerne.
Und 24 Gig RAM.
Also mehr als genug, was man irgendwie brauchen könnte.
Übrigens hier wird es auch bald.
By the way, ich sollte mal
Das, was ich gestern angelegt hab, sollte ich mal löschen, oder?
Wo haben wir das angelegt?
Repos
Monitoring Champ
Ne, das hab ich schon gelöscht
Dann müsste ich mal nachher gucken, was hier so viel Speicherplatz verbraucht
Wir können mal Pac-Man Cache löschen
Das wird wahrscheinlich ein bisschen was bringen
Schau mal, 27 Gig einfach wieder frei
Ja, also im Prinzip habe ich auf dem zweiten Desktop, also so läuft das, guck mal
Es gibt mehrere Desktops unter Windows
Auf dem ersten Desktop habe ich halt nur Windows-Kram
Auf dem zweiten Desktop habe ich hier die 4M im Fullscreen
Das heißt, ich kann Windows-Desktop switchen
Mit Ctrl-Windows-Taste-Pfeil-Tasten kann man hier gucken, zwischen Windows-Desktops durchswitchen
Und auf dem ersten Desktop mache ich halt alles mögliche
auf dem zweiten desktop ist mein linux im fullscreen da kann ich dann hieraus
zack switchen rein und so dass man sieht es nicht direkt dass es eine vm ist weil
ich das hier im fullscreen habe und das läuft ganz gut
es laufen sogar ein paar sachen die 3d beschleunigung brauchen wenn die open gl
können aber 3d oder generell sachen die halt gpu brauchen funzen halt in der vm
nicht richtig dementsprechend ist videos schauen auf youtube ist natürlich möglich hier ohne
probleme in der vm ja aber bei der wahl hier oben ist übrigens meine cpu auslastung guck
wenn ich jetzt hier mal ein bisschen cpu last generiere da seht ihr hier cpu kerne cpu auslastung
geht hoch also so eine mini übersicht cpu auslastung und wenn ich jetzt auf youtube gehe
hier zum max und machen irgendwie mal ein video auch von mir was haben wir schön dass auf der
startseite zack aber das video aufmachen in 1440p dann seht ihr schon cpu auslastung ist relativ
hoch gerade auf einem kern gehen tut aber halt viel auslastung wenn ich das ganze auf windows
mache habe ich nahezu keine cpu auslastung weil das alles über die grafikkarte geht ja
und umso größer ich das machen so höher höher wird also dafür ist das natürlich in der vm nix
aber braucht man das wirklich in der vm kann man youtube auch im browser unter windows gucken oder
halt mit ein bisschen höherer cpu auslastung leben was halt gar nicht geht es in irgendwelche 3d
beschleunigten Sachen, die die GPU-Access
brauchen. Das funktioniert
nicht in der VM, aber da habe ich auch nichts,
wozu ich das brauche.
Deswegen bin ich auch immer noch auf i3.
i3
unter X und nicht
irgendwie Hyperland
unter Wayland oder so,
weil das einfach in der VM nicht gescheit funktioniert.
Leider.
Da schieben sie sich dann seit Jahren
ein bisschen so die Schuld zu, wer dann jetzt
das verbrochen hat. Also
Also ist es Wayland, ist es irgendwie der Mesa-Treiber, ist es was auch immer.
Wer ist daran schuld, ist mir aber als Anwender ziemlich wurscht.
Wie hast du da deine Shell so schön?
Ich hab...
Ich hab... Wie heißt das Ding laufen?
Starship.
Starship hab ich laufen.
Starship RS.
da kann man sein prompt hübsch machen mit guck da gibt es eine config config starship
und mein terminal will sachen anzeigen die es nicht gibt und da kann man das hier schön
konfigurieren gibt es auch andere sachen als starship aber das finde ich eigentlich ganz
ganz nice. Meine Config
selbst ist glaube ich irgendwo
hier auf GitHub.
Ja. Wobei ich mir nicht sicher
bin, ob das wirklich so top aktuell ist.
Aber so halbwegs aktuell wird es sein.
Ich habe da seit zwei Jahren schon nichts mehr gepusht.
Also richtig top aktuell wird es nicht sein.
Ich dot com fall, dot config fall.
Gandalf ist da.
Moin.
Es wird mal wieder Zeit, Leute.
Irgendwann muss ich mir nochmal
paar Stunden lang.
Irgendwann muss ich mir nochmal
10 Stunden das hier geben.
aber zu viel tors
hier habe ich nicht
so also jetzt guck mal was auf github trendet was haben wir hier
Das kenne ich, das hatte ich auch mal eine Weile installiert, um Besucherzahlen,
Aufrufe, Seitenaufrufe zu tracken. Umami.is. Das war ganz nice.
Finde ich cool, dass das trendet. In was ist das denn written?
Wahrscheinlich nicht Rust TypeScript.
Denkt ihr ein HP Elitebook als gebraucht ist okay für ein bisschen Coding, Surfen und so?
Ja, bestimmt.
Bestimmt.
Man muss sich ja mal überlegen, die Rechner der letzten Jahre, die haben alle so viel Power,
du kannst heute ohne Probleme dein ganz normales Zeug erledigen an einem Rechner, der 10 Jahre alt ist.
Weil ich meine, was für eine CPU war vor 10 Jahren irgendwie aktuell?
ein Quadcore
also
2000, 2016.
Da hattest du irgendeinen Quadcore
mit, was weiß ich,
8 Gigramm oder so.
So.
Das reicht halt heute immer noch
für normales Zeug.
Zum Spielen jetzt vielleicht nicht unbedingt, aber
für alles Normale reicht das Dicke.
Warte mal.
Damals hatte man Intel-Kisten gehabt.
list of intel prozess gucken wir mal gucken wir mal kurz was 2000 irgendwo
das jahr drin hier da gucken wir mal was 2016 so angesagt war
ja
aber in der mittelklasse ding
irgendwie so was da keine ahnung
vier kerne
hier kurs oder so also hat es zwei bis vier kerne okay
kerne vielleicht ein bisschen ein bisschen mies aber du hattest schon sachen mit vier kernen
vier kerne und 8g gramm und so also kannst heute selbst im rechner von vor zehn jahren
kommst du gut klar mit so standards zeug dementsprechend wenn du dir ein bisschen
älteres notebook aus müsste das voll klar gehen ein bisschen basic zeug und
das ist ja neuer als zehn jahre also das ist halt ich finde das in der heutigen
zeit sowohl gut als auch schlecht irgendwie gleichermaßen ich finde es gut
dass hardware so lange hält der anderen seite fehlt mir so ein bisschen so dieser
hype des neuen von früher man früher war es so wenn ein rechner zwei jahre alt
war dann konnte den eigentlich austausch und nach drei jahren konnte sie
wirklich endgültig in die tonne schmeißen aber nach zwei jahren war das
ding eigentlich schon zu langsam für aktuelle sachen heute zwei jahre alte
rechner ist immer also eine high end rechner von vor zwei jahren ist heute
immer noch ziemlich high end ich habe mir 2022 vor 33 jahre muss man sich mal
auf der zunge zergehen lassen vor drei jahren ist das schon her vor drei jahren
habe ich mir den rechner hier gekauft
mit einer 4090 im 13.900k so und das ding ist heute immer noch ziemlich high end
das wird nur getoppt vielleicht noch von der kiste mit einer 5090 drin wobei die
5090 jetzt macht jetzt auch nicht so den riesenunterschied das wird nur noch
getoppt von einer 5090 und irgendwie einem aktuellen gaming ryzen oder sowas
Aber das ist immer noch ziemlich High End.
Und das nach drei Jahren.
Das muss man sich mal auf der Zunge zergehen lassen.
Nach drei Jahren ist ein High End Rechner immer noch recht High End.
Krass, oder?
32 spielt Cool on Physics
Ja, das verstehe ich auch nicht, warum sie das abgesägt haben
Die Festplatte ist deutlich teurer geworden
Ja.
Und eines muss ich halt nochmal sagen, wenn ich mir das hier so angucke.
Die Hardwarequalität ist nicht wirklich besser geworden.
Also Intel CPUs hatten ja das Problem mit dem Verschleiß.
Erinnert sich vielleicht noch einer dran, der musste man irgendwie gefühlt 5 BIOS Updates einspielen,
einspielen dass die intel cpu nicht verreckt kann sich ja noch einer dran
erinnern dass ein jahr oder so her
also intel die cpu hatte die cpu hatte verschleißprobleme die ssd hatte
probleme die partner auch die brauchte auch den firmware update oder zwei
klub der ein firmware update brauchte die ssd weil die hatte auch das problem
dass mit dem firmen mit der firma mit der hatte irgendwie einen bug in der
und zu hoher verschleiß und der ram der angeblich hier krasses overclocker
progress timing ram ist der schafft es auch nicht unter last ganz also ich habe
ziemlich ein mist bekommen und und und die grafikkarte hat diesen tollen
stecker wo sie abbrennen kann den ich ausgetauscht habe ich benutze nicht mehr
ich habe so ein extra ich habe mir für das netzteil so ein extra stecker
gekauft dass das quasi direkt ins netzteil geht und ist zwischenstecker
also muss man sich überlegen haben hat nicht das erfüllt was er können soll
grafikkarte ist fragwürdig cpu ist fragwürdig und ssds fragwürdig also
ziemliche ziemlich schlechter schlechte ausbeute für so einen teuren rechner
oder wenn du überlegst dass vier teile davon probleme hatten
der bauer hat ein extra load balancing tool für den stecker gemacht ja
load testing meinst du oder nicht load balancing tool
soll wieder richtig teuer werden ssd und ram ich kaufe mir auch erstmal keinen
neuen rechner
Sagst du die CPU wie die Transistoren durchbauen? Ja genau, deswegen musste man da 5 BIOS Updates machen bis es dann endlich gefixt war.
Ich sag doch, also die Hardwarequalität ist ganz mies gewesen diese Generation.
Das einzige was wirklich wieder Rock Solid ist, ist das Netzteil.
Da kann man gar nichts sagen.
Das funzt einfach.
Die Wasserkühlung funzt auch ohne Probleme.
Und das Gehäuse ist auch top, wie immer.
Aber Fractal Design hat dann einfach Poggers Gehäuse.
Das Gehäuse ist übrigens riesig.
Riesiges Gehäuse ist das.
Ich glaube, das kommt hier auf den Bildern gar nicht so raus.
Das sieht man gar nicht.
Aber das Gehäuse ist riesig.
weiß gar nicht ob man das vielleicht irgendwie so im vergleich zu anderen sieht oder so
aber das ist das ist wirklich riesig
ich will einfach nur mal gucken ob man das vielleicht im vergleich
guckt euch das das ist riesig das gehäuse
also das ist wirklich groß aber das ist wirklich rock solid wie man so schön sagt also das gehäuse
die wasserkühlung und das netzteil das ist wirklich top die würde ich mir jederzeit wieder kaufen
ob ich das ding gebraucht hätte weiß ich nicht
aber aber der 8auer hat das empfohlen da muss das taugen
das mainboard ist auch okay
das mainboard geht auch klar
okay sagen mal gucken was er noch so trendet auf github
Alert Manager, warum trendet der ProMix?
Das ist auch so ein uraltes Projekt,
das gibt es schon jahrelang.
Aber gut, wenn es trendet, soll es halt...
Gab es ein neues Release oder sowas vielleicht?
Vor fünf Tagen, ja.
Aber ist Alain schon heute 400 Sterne gekriegt?
Man weiß es nicht.
Aha.
Das ist sowas wie der 4M-Champ, hä?
Nur in gut und mit 18.000 Sternen.
Wobei, nee, Focus on Running Containers?
Dann nicht.
Nee, dann ist es nicht sowas wie der 4M-Champ.
AI Power No Code Low Code Plattform, ok hör mal bloß auf.
Database Tool, Local Stack, ist für alle AWS Enjoyer.
AI, Betafish, das ist China-Chinesen Zeug, keine Ahnung was das ist.
Da müssen wir doch gerade mal kurz Chrome öffnen und Translaten und mal schauen, was das ist.
Multi-Agent Public Opinion Analyst Assistant Accessible to Everyone.
Aha, das ist bestimmt AI, oder?
Chat, ich habe
absolut keine Ahnung,
was das sein soll.
AI-Driffen.
Okay, weg damit.
Ich weiß nicht.
Ich weiß immer bei Firefox nicht, wo der
Button dafür ist.
Wo der Button zum Übersetzen ist.
Bei Chrome weiß ich es.
Couchy, moin.
so airwave
perfect programming language golf of mexico
examples ok
alles klar jetzt wissen wir bescheid
Debated.
Penpot.
Open Source Design Tool
for Design and Collaboration.
Aha. Okay.
Gibt keine Demo.
Aha, da kann man zusammen
ist das quasi so eine Art
Multiplayer-Figma-Light.
Du hast Videos vor dem Bewerbungsgespräch
und hast das gebracht.
XD HD
Das ist so ein Multiplayer-Figma
hier.
Gar nicht verkehrt, nur
Bup-Marken.
so irgendwelches zeug wenn ich das schon lese mcp weiß dass er gedöns public art
in voices
ffm pack assembly language lessons was für ein ding
das erste bewerbungsgespräch verboten los scheiße ja das ist normal ganz ehrlich das
aber auch nicht schlimm weil mit jedem mal wirst du besser genau danach wesentlich besser
Ausbildungsstelle heißt GZGG Eats. Was ist denn dieses Repo hier?
Was machen die da? Assembly Stells?
monka es die meinen das wirklich ernst
ich kann euch sagen was wir schon mal nicht im stream machen werden das ist die ffm pack
als m lästens okay das trendet ok develop seit wann chat bin ich blöd die über ging
das die ganze zeit schon konnte man sich angucken was für developers trennten
habe ich nie reingeguckt
und auch ganz spannend
medien mod gui in rast placing die fast
task manager das ist nice so was könnte man gebrauchen
planify die sache ist das ist linux only
oder benutzt man das denn
So was für Windows hätte ich ganz gerne.
To-Do-Manager.
Für Windows, der Kaldarf kann.
Wobei, was mir hier fehlt, ist ein bisschen so eine Kalenderübersicht.
Das gibt es hier glaube ich nicht.
Ne.
Ne, das ist Linux-only.
Naja.
Ah ja ja
The cutest instant messenger
Chat ist was für euch
Da müssen wir erstmal gucken
Warum ist das der cutest instant messenger
Bluffy chat
Schön Emoji-Fighter-Readme.
Letzter Zeit nix geguckt.
RF-Programmer.
Fluffy Chat.
Okay.
Ne schöne Webseite haben sie, muss man sagen.
Die trifft genau meinen Geschmack.
Ich finde das auch gut.
Hier oben sieht es noch halbwegs seriös aus.
Und wenn du dann runter scrollst, so hier.
Aha.
So, jetzt wissen wir, was der cutest Matrix-Messenger ist.
Alles klar.
Ja, denn?
Wissen wir Bescheid.
Trends durch.
Dann schauen wir mal, was wir uns auf YouTube heute so geben können.
Wisst ihr, was ich mit euch gerne mal gucken würde?
das da das wollte ich die ganze zeit schon gucken und zwar ist das ein defcon vortrag
und die haben irgendwie im darknet eine auftragskiller webseite gehackt
Da wollte ich mal gucken, was da rauskommt bei.
Ob der Titel das verspricht, was im Vortrag dann auch kommt, weiß ich nicht.
Was fangen wir denn an?
Lokale KIs, das wollte ich, Moment.
Das interessiert mich tatsächlich auch, das wollte ich nämlich mal ausprobieren.
mit...
Wie hieß das Ding nicht?
AI Studio? LM Studio?
Heißt das LM Studio? Kann das sein?
Ja.
LM Studio meine ich.
LM Studio.
Das wollte ich mal ausprobieren.
Gibt es das eigentlich?
Na gut.
das ist halt was, das kann ich...
Siehst du, Chat? Das ist wieder so ein schönes Beispiel
für, das kann man jetzt nicht gut in der VM machen.
Weil
meine VM keinen Zugriff auf meine Grafikkarte
hat.
Das heißt, ich muss das unter Windows machen.
Hat mir gar nichts anderes da übrig.
In der VM
ist das lahm as fuck.
Und unter Windows mit der 4090
ist das eigentlich wahrscheinlich ganz nice.
Solange das Model
nicht zu groß ist. Aber schauen wir mal.
Das interessiert mich.
Guck mal hier, hier lasse ich mir gerade was von einem KI-Modell coden in irrsinniger Geschwindigkeit.
Das Beste, das passiert alles lokal.
Guck mal hier, hier lasse ich mir gerade was von einem KI-Modell coden in irrsinniger Geschwindigkeit.
Sehr zackig, ja.
Das Beste, das passiert alles lokal auf meinem Rechner und das Ergebnis ist manchmal sogar besser als das, was die großen kommerziellen Anbieter wie ChatGPT von OpenAI oder Cloud liefern.
Wobei das echt schwierig ist, da mitzuhalten.
Da ist halt doch ein bisschen größere Models dahinter.
Und wahrscheinlich auch ein bisschen fettere Cluster.
PewDiePie hat auch einen AI-Monsterrechner gebaut.
Ich hoffe mit Arch Linux.
Okay, die Betonung liegt auf manchmal.
Aber ich war ehrlich gesagt wirklich erstaunt, wie sich die lokalen...
Zeit mal her.
Jetzt, das wäre jetzt echt, das wäre jetzt echt Premiere. Ich glaube, ich habe noch nie ernsthaft ein PewDiePie-Video geguckt.
Zauber aber erstmal das hier. Ne, Moment, das ist das Falsche.
In diesem Video, das sich wirklich auch an Leute richtet, die noch nicht so viel Ahnung von lokaler KI haben.
Das ist gut, ich habe keinen Plan.
Ich frage euch, was braucht man für einen Rechner dafür? Was braucht man für Software dafür? Und vor allem, welche KI-Modelle nimmt man am besten?
Ja, NVIDIA's DJI X Spark kommt auch vor, auch wenn ich davon bislang ziemlich enttäuscht bin.
Bleibt dran.
Ja, Mensch, was meinst du denn? Das ist alles...
Dö-dö-dö-dö-dö-dö-dö.
Äh, äh.
Liebe Hackerinnen, liebe Internet-Surfer, herzlich willkommen hier bei...
Ja, wenn ihr euch für KI interessiert, möchtet ihr vielleicht auch mal Dienste nutzen, die in Deutschland noch nicht verfügbar sind.
Ah, Werbung, exzellent.
Da hilft euch NordVPN, die sponsern...
Ne, die helfen mir heute nicht.
Auf NordVPN habe ich jetzt keinen Bock.
Wobei, normalerweise lasse ich die Werbung immer durchlaufen, wenn wir uns Videos angucken, aber komm.
Das wurde jetzt zum fünften Mal in einem unabhängigen Audit bestätigt, diesmal von D-Loid.
Außerdem gibt es sinnvolle Sicherheitsfeatures, zum Beispiel eine Fake-Shop-Erkennung im Rahmen des Bedrohungsschutz-Pro.
Die zeigte bei der Zertifizierung von AV-Comparatives eine der besten Erkennungsparten bei Tests mit neu erstellten Fake-Shops.
Ja, und auch die Anti-Phishing-Funktion wurde als äußerst effektiv eingestuft.
Probiert das doch alles mal aus mit unserem Code CT3003.
Auf nordvpn.com slash ct3003 bekommt ihr vier Monate...
Hätte ich auch mal verwenden sollen, hätte ich letztens nicht mal in der IP geleakt.
Aufs 2-Jahres-Abo obendrauf und natürlich alles risikofrei mit 30 Tagen Geld-Zurück-Garantie.
Link ist in der Beschreibung.
Erbung Ende.
Okay, lokale KI-Modelle.
Das ist bei euch ein Riesenthema.
Kann ich nicht anders sagen.
Ich kriege da viel Feedback von euch.
Auch übrigens schon öfter in der echten Welt, dass ihr mich darauf ansprecht.
Und eine häufige Frage ist, was brauche ich dafür für einen Rechner?
Was kaufe ich mir am besten?
Könnt ihr da mal einen Rechner empfehlen?
Welche Modelle taugen überhaupt fast?
Sind die inzwischen so gut wie ChatGPT oder Cloud?
Und das alles versuche ich in diesem Video zu beantworten.
Ich habe letztens auf Reddit einen Post gesehen,
da hat sich einer einen KI-Rechner irgendwie gebaut.
Das hat mich ein bisschen, so genau gecheckt habe ich es nicht,
das hat mich ein bisschen an diese Mining-Rigs erinnert,
noch vor ein paar Jahren,
wo die Leute sich irgendwelche PCI-Express-Extender-Dinger
oder so gekauft haben,
um dann möglichst viele Grafikkarten fürs Mining reinzubauen.
So ein bisschen sah das auch aus.
Ich sag mal, das wird ein heißer Ritt.
Ich hoffe, dass ich euch nicht alle nach und nach verliere.
Ja, weil da gibt es schon viel zu besprechen.
Zumindest ich finde es alles richtig interessant.
Und das ist ja die Hauptsache von meinem Video.
Fangen wir mal mit dem optimalen Rechner dafür an.
Und das ist tatsächlich eine Frage, die in der CT-Redaktion,
und ich übertreibe nicht, zu Stunden und sogar tagelangen Diskussionen geführt hat.
weil das Problem ist halt, KI ist nicht gleich KI
und man den optimalen Rechner eben deswegen schlecht verallgemeinern kann.
Also zum Beispiel wollt ihr einfach ein lokales LLM als Chatboard mit LM Studio anzapfen,
wollt ihr Bilder, Videos oder Musik generieren,
wollt ihr Audio mit Whisper transkribieren,
wollt ihr vielleicht sogar Modelle feintunen.
Äh, Audio mit Whisper transkribieren?
Äh, Max, bist du noch da?
Machst du das nicht auf dem Archiv?
Ich glaube, das Archiv läuft mit Whisper.
sind alles unterschiedliche Nutzungsszenarien und ich weiß, dass das schwierig ist, aber
ich versuche das jetzt trotzdem mal mit einer Empfehlung.
Fangen wir mal an mit lokalen KI-Modellen, die man mit LM Studio zum Beispiel anzapft,
um so einen lokalen Chatbot hinzukriegen.
Viele nennen diese Modelle ja Open Source Modelle, aber das ist mindestens irreführend.
Ich würde sogar sagen falsch, weil wenn die wirklich Open Source wären, dann müssten
da ja auch Informationen darüber drin sein, wie genau die trainiert wurden.
Also eigentlich müsste es dann auch zumindest Zugriff auf die Trainingsdaten geben.
Und das ist so gut wie nie der Fall.
Das wollen die wahrscheinlich auch nicht.
Dann wird man sehen, woher sie sich alles ihre Trainingsdaten geklaut haben.
Präziser Open Waits zu sagen statt Open Source.
Das heißt, dass man die Parameter des Modells runterladen kann und auf eigene Hardware laufen lassen kann.
Also wenn wir hier von lokalen LLMs oder lokalen Modellen reden, dann sind das Open-Rates-Modelle.
Aber lokales Modell finde ich eigentlich am einfachsten, weil das sagt aus, kann ich auf eigene Hardware mitmachen, was ich will.
Ja, also jedenfalls, wenn ihr damit euer eigenes Chat-GPT bauen wollt, was nehmt ihr dann für Hardware?
Da würde ich jetzt erstmal ganz kurz diese Tabelle hier einblenden, die ich gerade zusammengestellt habe.
Die ist nämlich dafür extrem hilfreich.
beim abzapfen von lms die ki crowd nennt das ja in ferren ist wirklich zum allergrößten teil die
speicher datentransfer rate relevant das heißt habt ihr eine grafikkarte mit schnellem speicher
und passt das sprachmodell da komplett rein dann läuft das schnell hier guck mal das ist
mit 3.2 komplett in meiner rtx wie gab es denn nicht in den sprüchen wo kein kläger da kein
richter oder sowas so ein bisschen ist das ja da auch wer will die verklagen ja
aber manchmal musste einfach nur groß genug sein dann sind illegale dinger ja
anscheinend okay kann sich ja da auch darüber streiten wie das da in den usa
teilweise läuft wenn trump irgendwas verkündet was die aktienkurse
beeinflusst da würde ich auch sagen also andere würden damit probleme
kriegen.
4090 Grafikkarte.
Bam. Über 40 Token
die Sekunde. Ja, GDDR6X
Speicher mit ungefähr einem Terabyte
Datentransferrate pro Sekunde. Das ist
schnell. Wenn ich das gleiche Modell
Moment, Moment, lass mal kurz gucken.
Achso, das ist der Speichertuch.
Ja, doch hier hinten.
Okay, also meine Grafikkarte
ist gar nicht mal so übel.
Anscheinend.
4090
Ist ganz brauchbar dafür, hä?
Datentransferrate pro Sekunde, das ist schnell.
Wenn ich das gleiche Modell nur auf meiner CPU laufen lasse,
die auch echt nicht langsam ist mit ihren 16 Kernen,
die aber dafür nur DDR5 5600 Speicher zur Verfügung hat
mit nur 90 Gigabyte Datentransferrate,
ja, dann kriege ich nur 3 Token pro Sekunde.
Und ich bin selbst echt überrascht, wie das skaliert.
Denn 1000 Gigabyte sind ja ungefähr das Elffache von 90 Gigabyte und 40 Token pro Sekunde sind, ja gut, sind das 13-fache von 3 Token.
Aber natürlich so ganz exakt funktioniert das natürlich in der Praxis nicht, weil da natürlich noch mehr Faktoren eine Rolle spielen.
Aber grob gesagt kann man das schon sagen, dass das ungefähr so funktioniert.
So, das Problem ist halt nur, wenn ich eine einzelne Grafikkarte haben will mit diesem schnellen Speicher im Preisbereich unter mehreren 10.000 Euro,
Dann bekomme ich zur Zeit nur die RTX 5090 mit 32 GB Speicher.
Wie viel Speicher hatten eigentlich meine?
Ich weiß das gar nicht.
16? 24?
Moment.
Äh.
Sekunde.
Ihr wisst das besser als ich, was meine Grafikkarte für Speicher hat, ja?
Chat wieder, ey.
24
Okay, ihr wisst das wirklich besser als ich
Naja
High IQ Chat, ja
Max, ich lebe
Ich lebe
Glücklicherweise.
Aber schön, dass du deinen Weg hergefunden hast.
Masashini.
Ich hoffe, ich habe das richtig ausgesprochen.
Super schnell, aber 32 GB
halt nur. Das heißt, wenn ich Sprachmodelle
schnell abzapfen will, dann
kann ich nur Sprachmodelle benutzen, die da reinpassen.
Und zum Beispiel...
Du hast früher mein YouTube-Stuff geguckt.
Das ist nice. Aktuell
gibt es ja auf YouTube kein Stuff zu gucken.
ich hab seit zwei Jahren oder so nichts mehr hochgeladen
ich weiß, da sind einige richtig
sadge, ich krieg immer noch
Comments von YouTube, Alter, Max Battlefield 6
wann geht's los
zumindest spielen werde ich tatsächlich jetzt nach der Windows
Neuinstallation auf die neue SSD
und Secure Boot und alles
und dann mal gucken, wenn ich so geil
finde, dass ich mich da voll reinsteigern kann
dann, wobei ich wahrscheinlich, ich meine, ich hab jetzt
so Competitive-mäßig
Shooter, na Competitive ist das falsche
Wort, also Multiplayer-Shooter, aber schon eine ganze Weile
jetzt nicht mal richtig gespielt, also ich werd
wahrscheinlich voll reinscheißen für die
ersten 1-2 Wochen
bis ich wieder was treffe
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...

...
...

...
...
...
...
...
...
...
...
...
...

...
...
...
...
...

...
...

...
...

...
von OMAI, also mit 120
Milliarden Parametern, das braucht
63 Gigabyte. Boah, nee, das passt nicht rein.
Also vielleicht einfach zwei 5090er
kaufen? Nee, geht nicht,
denn Nvidia unterstützt
NVLink nicht mehr, also die Technik zum
Bündeln von mehreren Grafikkarten.
Das war ja auch Shit. Für Gaming.
Für sowas
ist es wahrscheinlich nice.
Nur Grafikkarten,
bis einschließlich der 3090er
Generation. Und das ist auch der Grund,
By the way, by the way, chat,
Chat, ich habe mich damit nicht beschäftigt, aber jetzt kleine Verschwörungstheorie.
Kann das sein, dass Nvidia das absichtlich abgeschafft hat, dass sich Gaming-Grafikkarten nicht so gut für AI-Content eignen?
Könnte das sein?
Oder ist das Kek-Alu?
Weil für Gaming war so SLI schon immer Schrott.
... sich einige KI-Freaks Workstation-Mainboards kaufen und da dann zum Beispiel drei gebrauchte 3090er reintun.
Ich glaube, sowas in der Richtung habe ich auf Reddit gesehen.
Auf dem Gebrauchtmarkt so ab 700 Euro das Stück.
Und ja, das ist aufwendig zu kühlen, aber das knallt ganz schön was weg in Sachen Token pro Sekunde
und unterstützt halt Sprachmodelle bis 72 GB Größe.
Also die 3090 hat 24 GB pro Stück, also 3 mal 24 sind 72 GB.
Ja, und solche Rigs schaffen mit GPT-OSS 120B laut etlicher Quellen im Netz deutlich über 50 Token in der Sekunde, zum Teil noch viel mehr.
Also wirklich, wirklich gute Werte.
Wenn ihr jetzt die aktuellen News verfolgt und jetzt sagt, hä, warum denn so viel Aufwand?
Man kann inzwischen doch für ungefähr 4000 Euro eine Nvidia DGX Spark kaufen.
Die hat doch 128 GB schnellen Unified Speicher.
Also da wird ja gar nicht zwischen normalen RAM und schnellem Videoram unterschieden, übrigens wie bei Apple auch.
und die ist ja extra für KI-Workloads gemacht.
Moment, Chat.
Das ist das beste lokale Model.
Okay, woher weißt du das?
Hast du das selbst ausprobiert?
Kimi K2.
Ah, habe ich das nicht letztens?
Chat, habe ich da nicht bei Theo
letztens ein Video zugesehen,
dass das irgendeinen Test besonders gut abgeschnitten hat?
Kann das sein?
Ne, wie heißt der Chat?
T3.
T3.
Ne, äh.
Jetzt blöd, wie heißt er denn nochmal?
Heißt doch so.
Ne, hier meine ich, ach hier, T3GG, genau.
Hat er, hat er, ja hier Kimi, genau, das Video habe ich doch geguckt.
Das kommt mir da, daher kam mir das bekannt vor.
Kimi K2 ist best model ever
und warum ist das das beste Model
speicher boah alter wo sieht man denn wie viel speicher das braucht sind sind ist das
hier der RAM oder was?
2,5 Terabyte
Speicher?
Das ist aber ganz schön viel.
Ich habe
legit absolut kein
Plastenschimmer, was das hier
vorne bedeutet. 1-Bit, 2-Bit, 3-Bit,
4-Bit, 5-Bit, 6-Bit, 8-Bit, 16-Bit.
Ich habe keinen Plan.
Wenn du das Modell mit CPU berechnen willst,
musst du den RAM haben.
Aber das heißt doch auch, ich könnte mir eine SSD
reinbauen und damit
dann
swappen.
So für 0,001 Token pro Sekunde.
Das wird wahrscheinlich nicht ordentlich funktionieren.
Wenn ich das mit der GPU...
Das heißt, ich brauche einen GPU-Cluster
mit 2 TB RAM.
Nicht schlecht.
Da brauchst du aber viele GPUs für.
Also ich sehe schon, das werde ich bei mir nicht laufen lassen können.
Oh, fertig.
Also weil es da wirklich Leute quasi in der SSD benutzt, zum RAM-Swappen.
Oder zum Memory-Mappen oder wie auch immer man es genau nennen mag.
Ja, aber das ist bestimmt lahm as fuck, oder?
Wenn das schon auf einer Grafikkarte, sagen wir mal, nur okay schnell läuft,
wie lahm wird das dann erst mit CPU und Swappen auf einer SSD laufen?
Das kannst du gar nicht benutzen dann.
So, aber gucken wir jetzt erstmal Video fertig.
Die müsste doch super damit funktionieren.
Ja, ich habe das Teil zwar selbst noch nicht testen können, aber dafür viele Tests im Netz gesehen.
Ja, und da kommen die Leute mit...
Ich wusste bis eben gar nicht, dass es dieses Ding überhaupt gibt.
... das S120B maximal auf 43 Token die Sekunde, zum Teil noch deutlich weniger.
Ich habe euch mal ein paar Tests verlinkt in der Beschreibung.
Das ist also deutlich weniger als die selbstgebauten Kisten mit mehreren 3090ern.
Aber nochmal der deutliche Disclaimer, die Benchmarks hier sind nicht von uns, also alles mit Vorsicht genießen.
Was aber definitiv sicher ist, die DJI Xperia hat eine deutlich geringere Leistungsaufnahme als solche Rechner mit mehreren 3090ern.
Was ich vor allem krass finde, Rechner mit AMD Strix Halo, also Ryzen AI Max Plus 395, die gibt es ja so ab 1800 Euro.
Ja, und die schaffen ungefähr genauso viele Token pro Sekunde wie eine DJI Xperia, nur halt deutlich günstiger.
Ich habe hier ja noch mein Framework Desktop stehen mit AI Max plus 395 und damit habe ich in LM Studio ungefähr 36 Token die Sekunde mit GPT OSS 120 B gemessen.
Also zumindest, wenn ich manuell alles auf die GPU gemappt habe.
Achso, ich muss hier mal kurz einschieben.
Wir sprechen hier nur von den Decode Werten, also der reinen Ausgabe der LLMs.
Sagte mal, da geht es ja nur um Grafikkarten gerade.
Die, dass das so richtig zackig ist.
Wie sieht denn das mit aktuellen Mac-Rechnern aus? Die haben doch auch AI-Gedöns und großen RAM, großen Grafikspeicher. Damit müsste das doch eigentlich auch ganz gut funktionieren.
Und die Dinger kann man doch, glaube ich, sogar zusammenstöpseln, mehrere Macs.
In der das LLM den Prompt und den Kontext liest und daraus dann den internen Speicher,
also den KV-Cache baut, da ist Rechenkraft, also Compute relevant und da ist die DJI X Park
deutlich schneller als die AMD Konkurrenz. Das will ich der Vollständigkeit halber gerne nochmal
sagen. Aber für so ein normales LLM anzapfen, ja, da kommt man günstiger bei rum. Zum Beispiel mit
Apple Rechnern. Also Macs sind auch eine Alternative. Da gibt es auch Kisten mit 120
Gigabyte Unified schnellen Speicher. Aber ja, das wird natürlich dann auch schnell teuer. Ich habe
GPT OSS 120 B gerade mal auf dem MacBook Pro mit M3 Max laufen lassen. Der ist über zweieinhalb
Jahre alt und schafft aber 40 Token die Sekunde. Also schon ungefähr in der Range wie die DJI X
Spark auf dem Notebook. Was ich halt bei meinem eigenen Rechner gemacht habe, da will ich auch
linux nutzen und so habe ich mir für ungefähr 500 euro 2 x 64 gb normalen ddr5 speicher gekauft und
den da einfach reingeworfen also in den rechner mit meiner rtx 40 90 gut das ist aber deutlich
langsamer darauf schaffe ich mit gpt os s 120 b ziemlich annehmen ja das geht doch eigentlich von
der Geschwindigkeit her. Das war doch vollkommen in Ordnung. Könnte das sein, dass deswegen
RAM in nächster Zeit teurer wird? Damit reiße ich jetzt keine Bäume aus, aber ich kriege halt
ein 63 GB großes Sprachmodell zum Laufen auf einem Rechner mit nur 24 GB Grafikspeicher. Für alle,
die es genau wissen wollen, ich habe den GPU Offload auf 13 von 36 eingestellt, was ich euch
auf jeden Fall generell als Empfehlung sagen kann.
Checkt, welche Sprachmodelle ihr genau laufen lassen wollt.
Wenn die kleinen sind, also sagen wir mal kleiner als 24 GB,
dann reichen natürlich 24 GB schneller Grafikspeicher.
Und dann reicht auch zum Beispiel eine 3090er oder 4090er.
Also wenn ihr KI machen wollt und ihr eine gebrauchte 3090er auftreiben könnt,
dann seid ihr auf jeden Fall ziemlich gut bedient.
Die Geschwindigkeitsvorteile der beiden nachfolgenden Generationen,
die sind bei KI nicht so richtig groß.
Die ganzen Textsachen, also zum Beispiel so ein lokaler Chatbot mit LM Studio, die funktionieren aber auch gut mit AMD Grafikkarten.
Also da könntet ihr auch zuschlagen.
Oder ihr nehmt halt ein Mac, die haben auch schnellen gemeinsamen Speicher, je nach Modell.
Aber die sind teuer, oder?
Seht ihr hier in der Tabelle nochmal.
Aber für andere KI-Anwendungen als LLM.
Na gut, teurer als Grafikkarten werden die auch gar nicht sein.
Glauben zu lassen, zum Beispiel mit LM Studio.
Grafikkarten ist ja dieses neue Gold irgendwie.
Comfy UI zum Bilder oder Videos generieren. Da seid ihr vor allem mit Nvidia Grafikkarten am besten im
Fall. Die halt cooler können und diese Programmierschnittstelle wird halt von vielen KI-Programm noch hauptsächlich genutzt.
Jetzt gerade, jetzt war ich gerade gestern da, Grafikkarten sind das neue Gold. Erinnert sich noch einer an Klopapier-Knappheit?
Da war Klopapier das neue Gold, ey. Da haben sich die Leute bei mir voll aufgeregt auf Twitter damals.
Ich habe damals bei so einem Großhandel im Internet, habe ich so ein 20er Pack oder irgendwie sowas Klopapier bestellt und so wie ich bin, habe ich ein Foto gemacht, auf Twitter gepostet. Alter, hat sich Twitter damals aufgeregt, dass ich die Klopapierversorgung zerstöre und sowas.
Da haben sie sich aufgeregt, ey.
Aber, ich muss dazu sagen, ich habe das Klopapier heute noch, was ich damals bestellt habe.
Ich habe das nämlich dann gar nicht wirklich gebraucht.
Ich habe davon vielleicht, wenn es hochkommt, die Hälfte verbraucht bisher.
Egal, gucken wir weiter.
Immer mehr Programme, wie eben LM Studio, beherrschen aber zum Beispiel auch MLX.
Das ist das Apple-Pendant zu CUDA oder halt Rock-N.
Also nicht, weil ich so wenig Klopapier brauche, sondern einfach, weil es anderes ja wieder gibt.
Das ist die AMD-Variante, aber eben auch viele Programme nicht.
Die können dann nur CUDA.
Das heißt, wenn ihr viel experimentieren wollt mit unterschiedlichen Sachen, muss ich Nvidia.
Und die 5090 kann kein 32-Bit-CUDA mehr, habe ich gelesen.
Aber zum Beispiel auch mit gebrauchten Nvidia-Karten, eben der 3090er-Empfehlung.
Ganz kurz zwischengefragt, interessiert euch das, dass wir mal so ein Multi-GPU-System mit KI,
mit gebrauchten 3090ern aufbauen?
Ist halt ziemlich viel Aufwand, aber wenn das Interesse bei euch daran groß genug ist, dann würden wir das schon machen. Also ich hätte Bock, wenn es keinen interessiert, natürlich nicht. So, das war jetzt erstmal zur Hardware, jetzt kommen die lokal laufenden Sprachmodelle. Was nimmt man da denn?
Das frage ich mich auch.
Ich bin da ein bisschen noob, was das angeht.
Also das Höchste der Gefühle ist,
dass ich Gemini benutze in Visual Studio Code
oder AI Studio mal aufmache
oder in Chat-GPT.
Wobei, nee, das Höchste der Gefühle war jetzt,
dass ich mir den Gemini-Agent mal installieren wollte
und damit mal Just-for-Fun-Pull-Requeste eröffnen
auf einem eigenen Repo von mir
und mal gucken, ob da was Gescheites bei rauskommt.
Aber ansonsten bin ich da ziemlich noob.
Gerade was Lokale.
Ja, es gibt von Gemini so einen Agent.
Der kann dann für ein Pull-Request und sowas machen.
Nee, nicht Gemini.
Claude war das, glaube ich.
Claude, nicht Gemini.
Gemini habe ich schon in der Visual Studio Code Plugin.
Inzwischen so gut wie Chat-GPT.
Lange war die Antwort Nein.
Und ich meine wirklich deutlich, deutlich schlechter.
Also man kann auch sagen, unbrauchbar.
Also hier mal so ein älteres Modell auf die Frage, was ist das CT-Magazin?
Der CT-Magazin ist ein Zeitschrift für alles, was heute im Thema ist.
Das CT-Magazin ist ein wichtiges Leitfadenspiel.
Ein Leitfadenspiel?
Um sich mit den Menschen in Beziehung zu setzen und das ganze Leben damit zu verbinden.
Also einfach, man kann es nicht anders sagen, Kauderwelsch.
Was ich auch sehr schön finde, ist hier die Antwort auf diese Rechenaufgabe.
Viel und dann so, nee, vier.
Was? What?
Aber das waren wirklich alte Modelle, die ersten.
Und dann kam Anfang des Jahres DeepSeek aus China.
Und das war wirklich das erste lokal betreibbare LLM, was mit der US-Konkurrenz in der Cloud mithalten konnte.
Allerdings, und das war das Problem, die vollständige Deep-Seq-Variante braucht über 700 GB.
Chat, wir müssten Deep-Seq mal lokal ausprobieren, weil mich würde interessieren, ist Deep-Seq schon im Model zensiert oder passiert das irgendwie per Post-Processing auf der Webseite?
Wenn man Deep-Seq irgendwelche China-kritischen Sachen fragt, dann sieht man ja, das fängt an zu antworten und auf einmal geht es weg.
Also das sieht für mich so aus, als ist es quasi Post-Processing auf der Webseite.
Im Model, okay
Warum fängt das Model dann aber überhaupt erst an zu antworten und irgendwann geht es weg?
Speicher, möglichst extrem schnellen Speicher, also wie es halt mit Profi-Rechenzentren-GPUs hinkriegt
für viele, viele 10.000 oder sogar 100.000 Euro.
Aber jetzt sind ja wieder ein paar Monate vergangen
und ich muss sagen, ich bin erstaunt,
wie gut inzwischen auch ganz kleine Modelle performen.
Also Modelle, die so gut wie jeder Rechner
oder sogar Smartphones laufen lassen können.
Vor allem beim Coding.
Ich habe ja gerade schon ein paar Mal LM Studio erwähnt.
Das habe ich in diesem Video nur verwendet.
Das gibt es für Linux, Windows, macOS.
Und das ist aktuell meine Lieblingsplattform
zum Anzapfen von Sprachmodellen.
Ich habe früher immer Ulama verwendet,
Aber ich mag LM Studio inzwischen lieber.
Einmal, weil man bei LM Studio viel einfacher die ganzen Parameter drumherum einstellen kann.
Also zum Beispiel, wie viel man auf die Grafikkarte auslagert, wie groß das Kontextfenster ist.
Also quasi das Kurzzeitgedächtnis.
Und weil Ulama mit so komischen Sachen wie Cloud-Unterstützung und Accounts angefangen hat.
Und ja, bei lokaler KI geht es ja gerade darum, dass man sich eben nicht an Cloud-Anbieter hängt.
Und ja, ich will Ulama jetzt auch nicht schlecht reden.
wenn ihr das lieber benutzt, könnt ihr das natürlich auch gerne
machen, also kein Ding.
Also ich habe auf jeden Fall einfach LM Studio.
Interessant, wie gesagt, ich will das in nächster Zeit
auch mal ausprobieren, oder wollte ich
die ganze Zeit schon mal ausprobieren, das sieht ja
an sich relativ easy aus,
LM Studio.
Also für mich sieht es so aus,
du wählst ein Model aus, machst ein paar Settings,
stellst irgendwie ein, dass er die
Grafikkarte verwenden soll und dann kriegst du ein Chat,
vermutlich, ne, New Chat,
und kannst loslegen.
Also sieht echt fast, würde ich mal sagen, so kacknubsicher aus. Gut für mich.
... installiert, dann hier unter Entdecken ein paar Sprachmodelle installiert und dann hier im Chat oben das gewünschte Modell ausgewählt und dann einfach gepromptet.
Ich brauche eine Website, die die Uhrzeit in Hannover, New York und Tokio hübsch darstellt.
Okay
Ich würde das Model fragen
Nenne mir 10 Gründe, warum C++
Scheiße ist
Okay, wir fragen ChatGPT mal, Sekunde
Das muss ChatGPT jetzt mal machen
Nenne mir
10 Gründe, warum
C++ Scheiße ist
Der mag das Wort Scheiße
wahrscheinlich nicht, aber
das ist dann
höllisch überspitzt formuliert.
Hier sind 10 Gründe,
warum viele Entwickler C++ nervig
oder scheiße finden.
Komplexität ohne Ende.
Das stimmt
wohl, da gebe ich dem recht.
Komplexe, sündungsunzählige Features.
Es gibt oft 10 Wege
das gleiche zu tun und jeder
davon kann schief gehen.
Ja, das trifft's eigentlich ganz gut.
Wie findest du Rust?
Ich finde Rust super für die Nische, wo es sich lohnt, Rust zu verwenden.
Also Sachen, wo es wirklich krass auf Performance ankommt,
die Memory-safe sein müssen.
Das in Kombination.
Also für die meiste Software jetzt nicht unbedingt so die erste Wahl,
gerade weil die Entwicklungsgeschwindigkeit in Rust
auch immer ein bisschen langsamer sein wird wie in anderen Sprachen.
Legacy Ballast, das stimmt auch.
Die Sprache schleppt 40 Jahre Abwechskompatibilität mit C herum.
Viele Konstrukte, zum Beispiel C-Style Arrays,
C-Style Arrays sind, ganz ehrlich, wir sind C-Style Arrays,
fast lieber als C++-Style Arrays,
sind Relikte aus den 80ern, immer noch existieren,
damit alter Code läuft, ja, stimmt.
Steile Lernkurve, man kann es,
Kurve, Lernkurve,
echtes Verständnis für Speicherfall,
Terminerei, Undefined Behavior und so weiter und ewig,
Anfänger werden schnell frustriert, ja, okay, das stimmt.
Aber auch Fortgeschrittene werden schnell frustriert in C++.
Und Defined Behavior.
Viele scheinbar harmlose Dinge führen zu undefiniertem Verhalten
und der Compiler darf dann machen, was er will.
Einzige Fehler... Ja, das stimmt.
Und Defined Behavior ist...
Wisst ihr eine Sache, die mich in C++ auch abfuckt?
Du hast ja 50 Arten, wie du irgendwas initialisieren kannst.
Mit Klammern, ohne Klammern, mit New
oder mit
Unique Pointer
oder mit
Memset is old school
und es gibt 30.000 Varianten.
Manuelle Speicherverhaltung, ja gut,
das ist nicht schlimm.
Das finde ich eigentlich eines der größten Vorteile
davon. Templates,
Compiler,
das ist Blödsinn.
Templates sind eigentlich
eines der nicesten Sachen von C++,
wenn es halt auch zu ganz ekligen
Sachen führt.
Templates ist noch eines der coolsten Sachen,
die mir an C++ gefallen.
Lange Compiler-Zeiten?
Naja, schon.
Aber bei den meisten Projekten fällt es
jetzt nicht so ins Gewicht. Zumindest bei meinen Sachen,
die sind ja nicht so groß.
Fehlende einheitliche Toolchain? Das stimmt wohl.
Das stimmt.
Das ist kein offiziellen C++,
Package Manager gibt. Das ist wirklich räudig.
Sicherheitsrisiken.
Kannst du leicht ins Knie schießen.
Das stimmt wohl. Nächstes Mal keinen Wartepack.
Naja. Also
der bisschen, bisschen konkretere
Beispiele hätten es schon sein dürfen.
Chat GPT.
Guck mal, das Video war fertig.
Gib mir was, was ich einfach in eine HTML-Datei
copy-pasten kann. Das Ganze auf Englisch,
weil ich gerade bei kleineren Modellen nicht so sicher bin,
welche Deutschfähigkeiten die so haben.
Und es soll ja fair und gerecht so gehen.
Das Beste... Moment, Chat, das muss ich mal lesen, was?
Clockbench AI.
Was ist das?
Clockbench evaluates, ob das Model eine analoge Uhr lesen kann.
Das einfach ist für Menschen,
aber viele aktuelle Modelle Probleme mit haben.
Aha.
Und wie sieht die...
Ach hier, Sample Clocks.
Hä.
Interesting.
Menschen nur 90%.
Na mal ganz ehrlich,
bei der Uhr hier hätte ich auch mal Schwierigkeiten,
die zu lesen.
Oder bei der hier ganz ohne Zahlen und sowas.
Das würde es auch erklären...
Das würde es auch erklären, warum ChatGPT es nicht hinkriegt,
ordentlich
meine
Druckanzeige von der Heizung auszulesen.
Kriegt das einfach nicht richtig hin.
Wie sah das Ergebnis bei den großen, teuren
Cloud-Sprachmodellen aus? Also
ChatGPT mit GPT-5 Thinking,
Moment, was hat er jetzt? Jetzt habe ich den Anschluss
verpasst. Was hat er gemacht?
Und es soll ja fair und gerecht so gehen.
Ja, und so sah das Ergebnis bei
Er will eine Webseite mit Uhren.
Passt ja jetzt gerade zu Clock AI.
Eine Webseite mit Uhren generieren lassen.
Habe ich das richtig verstanden?
Jetzt habe ich zu viel Pause gemacht im Video. Eine Webseite
mit großen, teuren Cloud-Sprachmodellen
aus. Also ChatGPT mit GPT-5.
Ach hier, World Clock. Okay.
Chat, macht das Sinn, wenn es hier 13 Uhr ist und GMT-4 ist dann 7?
Macht das überhaupt Sinn?
Nee, oder? Wir sind GMT, was ist Mitteleuropäische Sommerzeit? GMT plus 2, genau. Na gut, 6. Doch, dann stimmt das. Dann stimmt das. Dann ist das richtig.
... mit Abo, Gemini 2.5 Flash und Claude Sonnet 4.5.
Und das ist hier von Quen34B2507.
Und jetzt mal kurz innehalten, dieses Sprachmodell ist läppische 2,5 Gigabyte.
Das läuft also wirklich auf jeder Kartoffel.
Und das produziert das meiner Meinung nach visuell am besten gelungene Ergebnis.
Seht ihr, wie der Sternen-Hintergrund so ein bisschen animiert ist?
Ah, richtig nice.
Ja, okay, den Sternen-Hintergrund, den habe ich mit einem zweiten Prompt nachtrieben.
Was ich auch sehr nice finde, ist dieser Hintergrund, der so geblurrt ist.
Da hätte ich keine Ahnung, wie man das in CSS gescheit macht.
Also quasi, dass das dahinter...
Ich meine, es könnte natürlich auch gefaked sein und das einfach hier reingeschnitten als Geblöder.
Das hat ein bisschen was von iOS, ja.
Generell habe ich den Eindruck, die Designabteilung bei Apple beschäftigt 300 Leute,
die den ganzen Tag nichts anderes machen, wie verschiedene Blur-Stufen auszuprobieren.
Was kommt denn als nächstes nach Liquid Class?
Kommt dann Hot Class oder irgendwie sowas?
Frozen Class.
Oder denen wird schon irgendwas einfallen als nächstes.
Ja, okay, den Stellenhintergrund,
den habe ich mit einem zweiten Prompt
nachträglich hinzugefügt, aber das hat
wunderbar funktioniert, was ja nicht immer der Fall ist.
Allerdings habe ich dann gemerkt, dass die Uhrzeit
nicht stimmt, aber das konnte ich im Quellcode
dann selbst hinbiegen. Ja, ich finde
auf jeden Fall Quen 3 4b für die
Größe nicht gut. Das ist übrigens von
Alibaba in China. Ah, die China-Kinesen.
Läuft echt in einer beeindruckenden Geschwindigkeit, weil es so klein ist, weil es halt locker in meine 24 GB Grafikkartenspeicher passt.
Kann man auch den Kontext, also das Kurzzeitgedänz, richtig hochziehen und dann kann man da ganz gute Sachen mit machen.
Andere lokale Open-Rate-Sprachmodelle haben mein Uhrzeit-HTML übrigens auch ganz gut hinbekommen.
Das ist GPT-OSS von OpenAI mit 20 Milliarden Parametern.
Das ist das mit 120 Milliarden Parametern.
Und das ist Mistral Small 3.2 mit 24 Milliarden Parametern.
Wenn ihr gerade genau auf meine Liste mit den Sprachmodellen geguckt habt,
dann habt ihr vielleicht gesehen, dass die Zahl der Parameter nicht mit der Gigabyte-Angabe des Modells korreliert.
Hier zum Beispiel Mistral Small 3.2 hat 24 Milliarden Parameter.
Die Parameter seht ihr immer in dieser Spalte hier.
Der Computer muss gar nicht so gut sein.
Wenn das Model plus 2,5 Gig groß ist, passt das in jede Grafikkarte rein.
20B steht da.
für Billion, Milliarden. Das ist aber über ein Gigabyte größer als QN3-Coder mit 30 Milliarden
Parametern. Und dann denkt ihr vielleicht, hä, wie kann das denn sein? Ja, das hat mit der
sogenannten Quantisierung zu tun. Also statt zum Beispiel jeden Parameter in 32-Bit-Gleitkommagenauigkeit
zu beibringen, was ja in unserem Fall 30 Milliarden mal 32 Bit bedeutet, kann man das Ganze auch
quantisieren, also vereinfacht gesagt runden, zum Beispiel auf 8 oder sogar 4 Bit Ganzzahlen.
Das hat viele Vorteile, neben weniger Speicherplatz natürlich auch höhere Geschwindigkeit, aber wenn man zu aggressiv rundet, ja, dann arbeitet das Sprachmodell schlechter.
Da wird mit sogenannten K-Quants gearbeitet, aber das müsst ihr gar nicht wissen.
Ihr müsst nur verstehen, dass es viele Modelle eben in unterschiedlichen Quantisierungsstufen gibt.
Ihr wisst, was diese Codes da bedeuten.
Guckt mal hier zum Beispiel bei Quan3 Coder 30b.
Wenn ihr da in LM Studio auf Download Options klickt, seht ihr die vier Quantisierungsstufen.
3-Bit, 4-Bit, 6-Bit, 8-Bit.
Wenn ihr ein Mac habt, dann seht ihr sogar noch mehr.
Dann seht ihr nämlich noch...
Chat, wollen wir das jetzt mal ausprobieren?
Wir probieren das aus mit der Frage von gestern.
Gestern hatte ich doch bei Stack Overflow...
So, hier.
Das da habe ich gestern, glaube ich,
Chat-GPT hingeschmissen.
Perplexity und
und
weiß gar nicht, wie wir das alles hingeschmissen haben.
Probier mal,
übersetzt das mal in modernes Go.
Wollen wir das?
Komm, wir installieren uns jetzt
LR im Studio.
Hier, Tab.
Ich will das jetzt mal ausprobieren.
Wir machen jetzt AI-Stells.
Äh.
Hier?
Ist das das Richtige? Chatge.
Ja, ne? Download.
Das ist das Richtige, was ich hier runterlade, oder?
LRM Studio.
Nicht, dass ich mir hier irgendwelchen Hacker-Krams installiere.
Der Kriege, das ist das Richtige.
Gut.
Guck mal, die haben sogar Blogposts.
Dann kann ja nichts schief gehen.
Haben die auch hier irgendwie
einen GitHub-Link?
GitHub. Okay.
So, dann
LM Studio.
Ja.
Geht schon gut los
Was auch immer
Hä?
Es hat einfach rumgebuckt
Only for me
Yes
Okay, brauchen nicht so viel.
Ich habe nicht mehr allzu viel Platz, Leute, auf C, ja?
Historischer Moment.
Warum ist das historischer Moment?
Max installiert LM Studio, oder was meinst du?
Okay, run LM Studio.
So, und jetzt?
Aha.
Get started.
Choose your level.
äh, Chat, macht es irgendeinen Sinn
hier, was
was soll ich, was soll ich aus
was soll ich auswählen
Power User
Def, show me everything
okay, continue
äh
Was macht das?
Local LLM, Sir?
Ne, ne, das wollen wir nicht.
Ähm.
Ich will das gar nicht runterladen.
Ich will das andere.
Ich will oben rechts skip.
Bam.
Genau.
Okay.
Zack.
So.
Äh.
Select the model to load.
So, wir wollen jetzt, wie heißt das?
Q-Van?
Oh, was brauche ich davon jetzt?
Äh
8B?
Quen-Coder?
Welche sind meine GPU-Pass?
Das hier passt in meine GPU.
Gucken wir mal.
Wir haben Quen-Coder.
Ach Moment, das ist das alte hier unten.
Okay, dann nehmen wir doch mal das da, oder?
QuenCoder 3.30b.
Passt in meine...
Passt in meine GPU.
Okay, Download.
Das braucht jetzt wahrscheinlich ein bisschen.
Ja, das braucht jetzt ein bisschen zum Downloaden.
Ich hoffe, ich habe genug Speicherplatz.
Ich muss mal wieder ein bisschen aufräumen.
gleich.
Okay, da können wir das Video fertig gucken
in der Zeit.
MLX-optimierten Versionen zusätzlich. Aber ihr sucht
auf jeden Fall das aus, was am besten in
euren GPU-Speicher passt.
Da zeigt euch LM Studio auch so Icons an.
Also hier zum Beispiel vollständiges
GPU-Offloading möglich
oder eben nicht.
Wenn es nicht möglich ist, dann wird es langsam.
Geht aber auch. Wenn ihr dann
im Chatfenster das Modell auswählt,
sollte LM Studio direkt automatisch
den besten GPU-Offload einstellen.
also wie viel vom Sprachmodell in euren GPU-Speicher geladen wird.
Außerdem könnt ihr dann noch das Kontextfenster oder wie LMStudio anzeigt, die Kontextlänge einstellen.
Das bedeutet, wie viele Tokens, ein Token ist ungefähr eine Silbe, das Sprachmodell im Kurzzeitgedächtnis halten kann.
Das ist wichtig, wenn ihr mit viel Code im Sprachmodell einstellt.
Moment, das muss ich mir nochmal angucken.
Wenn ihr aus dem Chatfenster das Modell auswählt, sollte LMStudio direkt automatisch den besten GPU-Offload einstellen,
also wie viel vom Sprachmodell in euren GPU-Speicher geladen wird.
Außerdem könnt ihr dann auch das Kontextfenster oder wie LM Studios anzeigt, die Kontextlänge einstellen.
Das bedeutet, wie viele Tokens ein Token hat.
Ja, ich stelle ihm ja nur eine Frage und gucke, was rauskommt.
Das Sprachmodell, das ihr im Kurzzeitgedächtnis halten könnt.
Das ist wichtig, wenn ihr mit viel Code herumantiert.
Aber das ist auch wichtig für RAG, Retrieval Augmented Generation, RAG.
Also das Generieren ergänzt durch Abrufen.
Zum Beispiel Abrufen von Informationen.
Das klingt jetzt kompliziert, ist aber wirklich in der Praxis total super und total praktisch.
Und es klappt inzwischen auch wirklich gut mit den aktuellen lokalen Modellen.
Ein Beispiel mal, ihr habt ein unübersichtliches PDF und wollt da eine bestimmte Info draus haben,
aber habt keine Lust, euch da durchzuquälen.
Ja, und dann werft ihr das einfach auf LM Studio.
Ich habe hier mal das Programm von einer Tagung, wo ich vor vier...
Wobei ich sagen muss, PDF-Zusammenfassung hat mir ChatGPT auch schon teilweise echt heftigen Mist zusammengefasst.
Beziehungsweise Zusammenhänge nicht richtig gecheckt.
... vielen Jahren mal einen Vortrag gehalten habt.
Ja, und dann kann ich einfach schreiben, wann findet der Vortrag von Jan Keno Jansen statt und dann kriege ich super schnell eine korrekte Antwort. Man kann aber natürlich auch aufwendigere Dinge tun, zum Beispiel guckt ihr mal die Vornamen aller Personen an, die da sprechen und rechnet mir dann das Geschlechterverhältnis aus. Ja, zack, funktioniert, hätte manuell ewig gedauert. Und klar, das können ChatGPT und Co.
Also gerade ChatGPT hat diesen Research Mode, so nach dem Motto, such mir Studien da und dazu und dann sagt dann ChatGPT, ah hier gibt es eine Studie dazu, bla bla bla bla und hinter dem Link gibt es dann überhaupt keine Studie. Das hat sich einfach so rausgedacht.
Kimi.com, okay, wollen wir das mal ausprobieren? Okay, Kimi.com.
So, dann fragen wir doch, machen wir mal hier einen Vergleich.
Was sagt Kimi?
Stack Overflow Directory.
Can you rewrite this function in modern Go?
Speichern wir uns mal, weil das brauchen wir gleich.
Was sagt Kimi?
Kimi sagt, kein Bock.
Okay, dann probieren wir das nicht mit Kimi aus.
Dann probieren wir das mit LM Studio gleich aus.
Auch, aber man will ja vielleicht auch mal PDFs analysieren, die man nicht unbedingt im Internet herumschicken will und nicht an OpenAI in die USA.
Mit lokalen Modellen bleibt das eben alles, ja, eben lokal.
Und wenn es auf die Grafikkarte passt, geht es richtig schnell.
Der Nachteil allerdings, weil die Modelle eben lokal laufen, können die nicht out of the box im Netz mal was suchen.
Das geht mit MCP, Model Context Protocol, darüber haben wir schon ein eigenes Video gemacht.
Das führte jetzt ein bisschen zu weit, aber es ist halt so, dass die kommerziellen Cloud LMS,
die TCP und Cloud und Gemini, halt inzwischen standardmäßig selbst im Netz suchen.
Das machen unsere lokalen Modelle hier nicht.
Deshalb geben die auch auf viele Fragen schlechte oder falsche Antworten.
Als ich zum Beispiel gefragt habe, was ist das CT-Magazin, da kam bei einigen eine korrekte Antwort.
Zum Beispiel bei Mistral Small 3.2 aus Frankreich, aber oft auch richtiger Schrott.
Das schon ältere Lama 3.2 3B sagt zum Beispiel, dass CT zu Tulo Times ist.
Okay, ja, mhm, mhm, ja.
Okay, das ist vielleicht ein bisschen fail.
manchmal sieht die Antwort auf den ersten Blick okay aus,
aber dann steht da auf einmal sowas wie, dass
CT zur Famitsu Publishing Group
gehört. Okay. Also
als lokale Wikipedia, wenn man gerade
kein Netz hat, ja, dann sollte man auf jeden Fall
nicht diese kleinen Modelle verwenden.
Aber zum Beispiel, dass... Frag mal
Gwen Coder hier. Ich frag Gwen Coder gleich
lokal.
Guck mal, gleich
durch. S120B.
Okay, wir können das tatsächlich
chat.
Punkt Q-Van.ai
Wir vergleichen das mal mit was das hier im Browser sagt.
Soll ich hier irgendwie noch was umstellen?
Thinking.
Soll ich das anklicken oder nicht?
Soll es denken?
Oder soll es nicht denken?
Ich finde das richtig cool, wie viele Videos die mittlerweile machen.
Ich habe das schon von fast Anfang an richtig gerne geguckt.
Das ist ein anderes Modell.
Ah, du meinst oben links.
Quen Coder.
Ah, das kann ich denken.
Okay.
Okay, der checkt auch, dass man
Filepath Walkdir verwenden soll.
Und mehr oder weniger ist das ja
das Gleiche.
Ja.
Das ist mehr oder weniger das gleiche.
Alternative
Version with Arrow Wrapping.
Ah.
Äh.
Hä?
Das macht wenig Sinn, oder?
Das ist das gleiche Custom Error Message, aber ansonsten ist da eigentlich kein Unterschied dazwischen.
Heise hat vermutlich gemerkt, dass die verkaufte Auflage extrem sinkt.
auch bei der, ähm,
weißt du das irgendwoher, oder,
oder vermutest du das?
Ich hab immer noch ein CT-Abo.
Hab ich seit Ewigkeiten
schon und lass ich auch weiterlaufen.
Ich, äh, blätter da immer noch
ganz gerne durch beim Abendessen.
Ja, ich les aber tatsächlich wenig, ja.
Also, so von einer CT-Ausgabe
les ich vielleicht,
keine Ahnung,
so wirklich
fünf Seiten oder so,
von der gesamten Zeitschrift.
Ich blätter aber gerne durch
und schau mal ein bisschen, was so drin ist.
Den werde ich aber auch weiterhin
lassen. Also okay, das da unten kann man eigentlich fast vergessen.
Gucken wir jetzt das Video fertig und dann probieren wir hier
LM Studio aus.
Das produziert auch schon ganz gute Fakten.
Wenn ihr hier in LM Studio so eure
installierten Modelle anschaut, könnt ihr
mit diesem Ordner-Icon hier, dann seht ihr
nicht nur die Zahl der Parameter hier
oder Quantisierung da, sondern
ihr seht auch so Zusatzeikons.
Der Hammer bedeutet zum Beispiel
Tool Use, also Werkzeugbenutzung.
Das kann also mit MCP umgehen, zum Beispiel
Browser bedienen, wie gesagt.
Das brauche ich nicht wirklich. Und es gibt auch das gelbe
Auge hier. Das bedeutet Vision.
Das bedeutet, dass das Modell
also Bilder verstehen kann.
Da war ich auch echt überrascht.
Was mir da in der CT auffällt ist,
seit einer Weile sind
viele Artikel
Überschriften mit Bildern,
Die Bilder sind eindeutig AI-generated. Aber immerhin würde ich sagen, nicht nur rein AI-generated, sondern AI-generated und nachbearbeitet.
Ja, sodass es nicht ganz so AI-slop-mäßig wirkt.
Das klappt. Ich habe zum Beispiel dem nur 12 Milliarden Parameter großen Gemma3 von Google dieses Thumbnail hier gegeben und gesagt, roastet den Typen da drauf mal.
Und dann sagt Gemma3, schau dir diesen Mann an, er sieht aus wie ein Teddybär, der versucht einen Gaming-Stream zu moderieren.
In diesem Bad könnte er locker drei Hamster unterbringen.
Dieser Typ hat mehr Technik um sich herum als die NASA.
Er sieht aus, als wüsste er, was er tut, aber wahrscheinlich braucht er eine Bedienungsanleitung für den Powerknopf.
Er sieht aus, als hätte er gerade einen Kampf gegen einen Kuchen verloren.
Dieser Mann ist der Beweis, dass man mit einem Bart und teurer Hardware nicht automatisch gut im Gaming wird.
Also man kann mit diesen Modellen auch sinnvollere Sachen machen, zum Beispiel die in Visual Studio Code einbinden,
zum Beispiel mit der Software Continuum oder auch Klein.
Ah, Chat. Das heißt, passt mal auf. Das heißt, ich kann diesen Kram mit AI Studio und sowas bei mir auf Windows laufen lassen und connecte mich dann dort von, sagen wir mal, Visual Studio Code aus meiner VM drauf.
Ja, das ist nice.
Das finde ich
pock. Das geht bestimmt noch über das
Netzwerk. Ja, das ist cool.
Code LM Studio
als Provider auswählen und kann dann
ein Modell da einladen und das hilft
einem dann beim Programmieren.
Wenn ihr bis jetzt durchgehalten habt, dann habt ihr
vielleicht gemerkt, dass das ein riesiges Thema ist.
Und ich könnte da wirklich stundenlang drüber sprechen.
Aber das war jetzt, glaube ich, auch schon
fast zu viel Inhalt für ein Video.
Aber ich sehe das jetzt mal als Versuch.
Ich guck, wie das so ankommt bei euch.
Und wenn ihr da mehr drüber wisst ...
Warum haben die nur 220k Abos? Da hab ich ja mehr.
Und das ist kein Qualitätsmerkmal.
Ich hab für die heutige Zeit nicht mehr viele Abos.
Die hätten viel mehr verdient.
Und die kriegen wir hoffentlich auch mehr.
Guck mal mal.
Social Blade CT 3003.
Ich hoffe mal, die kriegen ordentlich Abos.
Ih, sieht die Seite mittlerweile kacke aus.
Äh ...
ok
so wenig ich hätte gedacht kriegen richtig krass weil die hand ja auf jeden
fall verdient
...wollt, dann mache ich halt zu den einzelnen Themen nochmal einzelne Videos.
Also eben sowas wie selbstgebauter KI-Server mit mehreren gebrauchten RTX 3090ern
oder halt lokale LLMs in...
Für einen rein deutschen Channel ist 250k viel.
Ey, ich habe 290k.
Da habe ich auch viel.
...Agenten bauen, der lokal läuft und Webseiten bedienen.
Der Keno Spaltewaffe, was spaltet denn an den Videos?
Du meinst, weil da so viele AI-Videos kommen?
Ja, aber das geht halt auch gut, ne?
Oder auch, wie man LLMs
feintunt. Oder, oder, oder.
Ansonsten finde ich die sehr massenkompatibel eigentlich,
die Videos.
So viele Themen. Sagt ihr mir einfach, was ihr sehen wollt.
Der Bruce Lee ist am Start. Bam!
Tschüss! Moin.
Bruce Lee.
Wie Bruce Lee. Bam.
Ja, gutes Video.
So, und jetzt habt ihr gesagt,
wir sollen nochmal mal PewDiePie gucken.
Ich kann euch nicht versprechen, dass ich das Video komplett gucke. Ich finde PewDiePie super anstrengend.
Aber wir können mal durchskippen, okay?
Ich finde das Video jetzt schon anstrengend.
Was?
thinking felix did you split your pc ein
lane you can fit to gps was was billig
so what because what i didn't say in my
last ich spiele mal ein bisschen vor
von der rheinland strengen moment moment
moment wir wollen lm studio ausprobieren
laut model ok
Habe ich noch Platz auf der Platte?
Please.
Nicht volllaufen.
Okay, es ist geloadet.
Und jetzt kann ich den einfach fragen, oder wie?
Ach, hier kann ich noch Settings einstellen.
Ah, das ist das, was er vorhin gezeigt hat.
Hier GPU Offload, bla bla bla, sonst was.
Ja gut, dann fragen wir das Model jetzt einfach mal.
Im Prinzip ja das hier, was wir eben schon hatten.
Boah, das flutscht aber, Alter
Das flutscht aber mal richtig
65 Tokens pro Sekunde
Bam, bam, bam
Bam
Yes, the modern go version
And you have
Walked here
Ja, okay, es ist im Prinzip das Gleiche und das ist auch richtig.
Mach mal GPU Offloading auf Maximum.
Hier?
Ne, Model.
Ne, Settings?
Ne, äh.
Ne, hier, wo ich vorhin war, gell?
Hier meinst du?
Meinst du hier?
Das, das da, oder?
Warte mal mal.
Was? Chat?
Hier, das da.
Ah.
Ist doch volle Pulle.
46 von 48.
Okay, machen wir 48.
Machen wir 48 von 48.
Dann passt auf, dann ruckelt bestimmt das Stream gleich.
Grafikkarte brauche ich auch noch ein bisschen hier für Video-Encoding
Können wir das löschen?
Kann man wie
Hier
Brrrt
Hunde, Alter
Geht der noch schneller?
Hat der das irgendwie gecached oder so?
118 talkies pro sekunde das flutscht
Hoggas
Top
Okay, okay
Wollen wir mal gucken, ob das Deutsch kann
Immerhin, immerhin
So
Nenne mir
10 Gründe, warum
Warum C++
Scheiße ist
Das flutscht richtig
Hier sind 10 Gründe, warum C++
Manchmal als scheiße empfunden wird
Komplexe, Sonntagsmann und Speicherverhaltung
Bitte ein Beispiel
Zu jedem Punkt
Naja
Das macht jetzt wenig Sinn
Das macht jetzt wenig Sinn
Das ergibt dann keinen Sinn
Ist das mit Thinking?
Ich habe keine Ahnung, wo man das überhaupt einstellen kann
Das ist Thinked
Moin Patrick
Annuelle Speicherfalle
Okay, das Beispiel ist gut. Keine Garbage Collection.
Ja, ach.
Viel Boilerplate.
Ja.
Äh.
Na, so ganz toll ist das jetzt nicht.
Nee, bei mir ist mit Thinking wirklich nicht viel.
Okay, gut.
Quitt.
Da hätten wir das doch.
Jetzt wissen wir Bescheid.
So, Leute, können wir uns das Video wirklich angucken?
Ich finde das extrem anstrengend.
Ich muss mal vorspulen.
Moment, warum streckt er seinen Fuß gerade in den PC-Express-Slot?
Boah, das ist anstrengend, das Video, Leute.
Ich kann das nicht.
Ich kann mir das nicht angucken Leute, das geht nicht.
Das ist unmöglich, ich kann das nicht gucken.
Ich kann mir das nicht angucken, das geht nicht.
Unmöglich.
Eine Frage, wie sieht deine Git, meine Shit-Strategie aus?
Branches pro Umgebung oder alles in Main Master für DevTest, Pod und darüber ist hier
entsprechend umgekehrt.
Also, willst du wissen, wie ich es gerne hätte oder wie es bei uns auf der Arbeit ist?
Ich erzähle dir mal, wie es bei uns auf der Arbeit ist.
Reden wir jetzt nur von Source Code oder reden wir jetzt auch von Infrastructure Code dabei?
Also ich sag dir einfach mal, wie es bei uns auf der Arbeit ist.
Branch pro Story.
Ah, ich sehe schon hier ein agiler Entwickler am Start.
Du schreibst dann auch User Stories für alles, ne?
So nach dem Motto, ich als Projektmitarbeiter möchte möglichst schnell meine Tickets finden.
Müsst ihr das auch in dieser Art und Weise schreiben?
Das ist glücklicherweise bei uns nicht so.
Aber auf der alten Arbeit, wer denkt sich, ey, irgendwelche Agile Leute.
Bei uns auf der alten Arbeit haben sie das mal probiert. Das war ultra cringe, Mann. So einfache Sachen mussten in sinnlose Sätze verpackt werden und sowas.
Okay, aber ich sage dir wieder, dass bei uns auf der Arbeit ist
Also ich kümmere mich ja meistens hauptsächlich um Infrastruktur-Code
Ja, also deswegen kann ich dir jetzt nicht sagen, wie das die Software-Entwickler bei uns machen
Also Infrastruktur-Code sieht bei uns meistens so aus
Es gibt ein zentrales Repo mit einem Terraform-Modul
Das macht dann halt Dinger, so wie es gemacht werden muss für das jeweilige Projekt
Ja, legt beispielsweise eine Cloud-SQL-Datenbank an
professioniert zwei VMs und ein Kubernetes-Cluster und sowas.
Das macht das Terraform-Modul.
Und dann haben wir pro Umgebung einen eigenen...
Nicht Branch, wollte sagen, stimmt überhaupt nicht.
Pro Umgebung ein eigenes Git-Repo,
was dieses Terraform-Modul referenziert und mit den passenden Variablen füttert.
Also wir haben quasi ein zentrales Repo drin.
Da gibt es auch meistens nur einen Master-Branch und ein paar Feature-Branches,
wenn leute was basteln also da ist nix irgendwie großartig gesteht das wird dann geteckt dann gibt
es eine neue modul version und in dem jeweiligen umgebungs repo also wir haben dann zum beispiel
für die für die testumgebung gibt es ein eigenes repo da wird dieses terraform modul included und
dann nur noch mit 56 variablen gefüttert für die jeweilige umgebung erst was weiß ich welches netz
soll verwendet werden oder was ist da sonst noch drin welche welche public ip für den
load balancer und so was verwendet werden soll das wird dann in der in der jeweiligen dem jeweiligen
umgebungs repo wird das terraform modul konfiguriert und dann wird das ganze über gitlab ci deployed
das macht man dann zuerst den test sondern macht man das in der abnahme umgebung und dann macht
man das im Endeffekt danach auch in der Produktionsumgebung auf genau dem gleichen Weg.
Also es ist quasi ein zentrales Repo, wo die ganze Logik
drinne passiert, Terraform mäßig und dann ein Repo pro
Umgebung. Und da kann man
auch relativ wenig dagegen machen, weil
das sehr verzahnt ist bei uns mit den ganzen
GitLab CI Runnern und GitLab CI und das muss quasi so
konfiguriert sein, dass das auch funktioniert,
dass dann dein CI auch Zugriff hat
auf die ganzen Cloud-APIs
und sowas, da geht nicht,
kann man nicht viel anders machen.
Ich würde es mir manchmal ein bisschen einfacher wünschen,
beispielsweise mit Terraform-Workspaces
für die unterschiedlichen Umgebungen,
dass man das alles in ein Repo haut,
aber das
ist nicht möglich,
wenn man die offiziellen
Pipelines verwenden will.
So läuft das
So, dann kann ich dir noch erzählen
Wenn du willst, wie ich das
Gemanagt habe beim alten Arbeitgeber
Weil da hatte ich ja quasi
Den Hut auf für Systemupdates
Und Configupdates
Und Aktualisierung und sowas
Da hatten wir tatsächlich
Nur ein Repo, da war der ganze Infrastructure
As Code
Code drinnen
Und die Leute haben dann dort
feature request aufgemacht für was weiß ich ha proxy config hat sich geändert auf den und den
system blablub dann habe ich das gemerkt und da gab es dann einmal im monat gab es dann da einen
neuen tag drauf und es gab für jede umgebung einen eigenen branche es gab dann beispielsweise
branche für test und branche für abnahme und branche für port da wurde dann das jeweilige
reingemerged und dann wurde da drauf
Infrastructure as Code ausgeführt.
Also es war
damals noch Puppet, nicht Ansible.
Schon ein bisschen her. Einmal im Monat.
Ja. Mussten warten.
Das waren zwischenzeitlich bis zu
4000 Linux-Systeme, die das da drüber gekriegt haben.
Wir haben Infrastructure as Code
gemacht, noch bevor
es einen Namen hatte.
Die waren da auch super restriktiv
Mit wann was ausgeführt werden darf
Das wurde dann auch nur nachts ausgeführt
Und sowas
Ganz abgedrehtes Zeug
Da gab es dann für jede Umgebung
Einen eigenen Branch
Wo dann einmal im Monat
Wurde dann quasi der Tag da rein gemerged
Und dann
Ja, so läuft das.
So, ich hoffe, Frage beantwortet.
Mach mal ein Video über Homeserver-Zeug, das 3,5 Millionen Views kriegt.
Das musst du so hektisch machen, das geht nicht anders, verstehe ich schon.
Also ich verstehe, warum die Videos so sind und auch, dass das irgendwie erfolgreich ist.
aber ich kann es mir trotzdem nicht angucken.
Nicht heftig im KI-Hype.
Mein größter KI-Hype ist jetzt,
dass ich LM Studio installiert habe.
Git-Hooks, keine Story, kein Push.
Ernsthaft? Krass.
Die wollen es aber wissen.
Ne, das war nicht beim Provider.
Das war noch, wo ich bei der Bank gearbeitet habe davor.
Da war es sehr restriktiv mit einmal im Monat Updates und sowas.
Und auch nur nachts.
Das ist jetzt beim aktuellen Job besser.
Also jetzt arbeite ich ja bei der Versicherung.
Da ist es nicht mehr ganz so schlimm.
So.
Oh, ich habe Hunger.
Wir haben heute so gut wie nichts gemacht.
Ich weiß, aber guck mal, komm, eine Sache können wir uns...
Ne, das können wir uns nicht mal angucken.
Also wie gesagt, ich würde mir ja gerne...
Ich würde mir echt gerne das hier angucken, aber ich kann jetzt keine 32 Minuten Konferenztalk gucken.
Was haben wir denn hier?
LKW-Fahrer im Chemietransport.
Alltag mit Tankhund, lohnt sich das?
Okay, die Dinger gucke ich mir auch immer gerne an.
Okay, Chat, jetzt lesen wir nochmal kurz, was der Helenik Guy schreibt.
Bist du Grieche?
Weil Hellenic?
Klingt irgendwie so.
Nennen sich doch irgendwie.
Das heißt doch auf Englisch irgendwie so.
Ich mache es mit Branch.
Das ist also ein Repo mit mindestens
DevTest Main als Branch und über
Git-Variablen werden die umgebungsspezifischen
Konfigurationen deployed.
Habe aber gelesen, dass der
Best Practice ist, alles in Main und über
Terra...
Ne.
Also ich weiß, ich kenne das Tool, aber ich habe das nie groß benutzt und ich glaube nicht, dass das the way ist.
Ich nutze hauptsächlich eigene Module für jede Cloud-Ressource, weil ich Sachen abfange wie Kleinschalen.
Also ich finde das zu übertrieben kompliziert.
Es spricht übrigens überhaupt nichts dagegen, das alles in einem Repo zu machen und mit Branches.
Du kannst aber auch Terraform-Workspaces verwenden.
Das ist dafür doch eigentlich echt ganz nice, oder?
Hier, Terraform-Workspaces.
Kannst du unterschiedliche Terraform-Workspaces machen für unterschiedliche Umgebungen.
Dann brauchst du noch nicht einmal großartig Git-Branches.
Warum eigentlich Chromium statt Chrome?
Ne, ne, es ist Chrome und Chromium.
Beides.
Und, und, und, dann haben wir auch noch Firefox.
Und, und, Edge,
Edge haben wir auch noch.
Aber Edge will ich nicht. Geh weg.
Moment. Ich mach immer
nicht random
irgendwelche Videos auf.
Was soll das denn sein?
Wenn man danach sucht, findet man auf YouTube irgendwelche random Dinger, die keinen Sinn ergeben.
Browserception.
Ja, die YouTube-Suche ist teilweise auch schon ziemlich Painschamp.
Wisst ihr, was ich manchmal auf dem Handy habe?
Wenn man YouTube aufmacht auf dem Handy, auf der App,
dann hat man hier oben, oder machen wir hier mal auf,
da hat man hier oben oftmals so eine, ja genau, so was hier.
Wisst ihr, was ich, also manchmal gibt es hier als Kategorie
sowas wie Go-Programming
oder Go-Lang oder sowas.
Warum gibt es auf YouTube keine
Übersicht mit diesen
Tags oder was das ist?
Also ich muss immer warten,
bis das hier oben in der Auswahl drinnen steht.
Warum gibt es keine
große Übersicht mit diesen Tags, dass ich
danach suchen kann? Warum muss ich immer
so lange die Startseite refreshen, bis das
dann auftaucht?
Das ist echt weird champ.
Keine Ahnung.
das sind filter ja aber warum gibt es nicht wenn die ja die kategorie wissen von den videos die
wissen ja die kategorie warum gibt es keine kategorie mehr auf youtube da ich sagen kann
ich interessiere mich für videos die getaggt sind mit computer programming es gibt diese
hässlichen kategorien die die nix bringen ich hätte gern so zeigt mir mal alles alles computer
Computerprogramming der letzten zwei Tage.
Das wäre doch mal ein cooles Ergebnis.
Warum kommen wieder Juden, wenn ich Windows neu installiert habe,
sodass ich Battlefield 6 spielen kann?
Wollen wir nochmal gucken, ob sich das lohnt.
LKW-Fahrer im Chemietransport.
Alltag mit Tankcontainer und Gefahrgut.
Wie? Mal einer, der was arbeitet den ganzen Tag.
Was ist denn da los?
Nein, ich habe Battlefield 6 noch nicht gespielt.
Wir müssen aufpassen, dass wir nicht Toss bekommen.
Wurde über den Tisch gezogen und verklagt.
Der Transporte, da sind giftige Sachen mit dabei, da sind brennbare Sachen mit dabei.
Berufs- und Fähigkeitsversicherung habe ich nicht.
Ein Freund hat mal gesagt, Christian, dir scheint doch eh die Sonne aus dem Arsch.
Ich hoffe, das bleibt auch so.
Ganz ehrlich, das habe ich noch nie gehabt.
Das wäre jetzt schlecht, wenn wir da mit 6000 Liter wieder nach Hause fahren.
Hi, ich bin der Christian, ich bin 54 Jahre alt.
Ich arbeite als LKW-Fahrer und nehme euch heute mit auf meinem Weg mit dem Tankcontainer.
Für mich ist die größte Herausforderung, dass die Zeit einigermaßen irgendwie im Rahmen bleibt.
Weil es gibt so viele Stellschrauben, wo man keinen Einfluss auf die Zeit hat.
Das erste ist die Fahrerkarte stecken und dann eine kleine Abfahrtskontrolle machen.
Oh, das ist Toss-Musik.
Quasi eine Start-Checklist.
Dann schau ich mal die Ecke. Toss, toss, toss, toss.
Ich schau, ob die Fläuche fest sind, ob die Sattelkupplung zu ist. Wenn jemand die Sattelkupplung aufmacht und ich losfahre, dann fällt mir das Chassis hinten runter.
So, das sieht alles gut aus. Unterm Auto sitzt auch keine Katze.
Ich kümmere mich quasi um die Abholung und um die Lieferung von flüssigen Gütern.
Wir haben auch ADR-Transporte. Da sind giftige Sachen mit dabei, da sind brennbare Sachen mit dabei, da sind ätzende Sachen mit dabei.
Also nichts, womit man in Kontakt kommen will.
Ich muss mich noch am Tablet anmelden mit meiner Fahrernummer und da ist dann der Frachtbrief hinterlegt.
Hört mal auf mit der Tossmusik, das gibt sonst wieder irgendwelche Probleme.
Wo ich dran drehen kann, dass es zeitlich einigermaßen gut geht.
hat chat dass ich habe eine fritzbox also router und die funktion sind echt
knapp für mich ich habe vor einem durch das elf open sense router zu setzen und
mir so ein access point holen wie du hast separate wlan jetzt hast du
irgendwie tipps
u
die access points würde ich wäre ich noch mal überlegen die sind echt teuer
da kannst du ja eigentlich nur ein bisschen ältere gebrauchte kaufen
weiß ich nicht, ob das so sinnvoll ist,
aber eigene Access Points machen auf jeden Fall Sinn,
wenn das Haus ein bisschen größer ist.
Fritzbox wirst du auf jeden Fall
sehr sicher behalten müssen
für Telefonanlagenkrempel.
Das willst du nicht selbst machen.
Also die bleibt
ziemlich sicher da.
Ich bin sehr sicher,
dass du die zusätzlich noch haben wirst.
Und
mit OpenSense, ja, ich habe lange
nichts mehr mit OpenSense gemacht. Ich hatte das mal
ein paar Jahre. Jetzt habe ich
mal einen MikroTik-Router und der macht halt
auch alles, was ich will.
So großartige
Tipps habe ich da jetzt aber nicht.
Hört mir jetzt gerade nichts ein.
Es ist eigentlich nur, dass ich
relativ früh anfange. Also, dass ich versuche,
der Erste an der Ladestelle zu sein.
Dass es zackig geht.
Ich bin so gesehen einfach nur
Nahverkehrs-Lkw-Fahrer. Mir ist es wichtig, dass ich abends zu Hause bin. Deswegen kommt
für mich die Übernachtung im Lkw nicht in Frage. Dann mal den Helm aufsetzen.
Gut, dann machen wir die Schwammerl zu. Ich habe jetzt hier das Öl abgeholt für die TPE
So, vier-Kammer-Tank haben wir heute.
Das ist viel Arbeit.
Alle Verschlüsse sind soweit zu.
Dann machen wir uns auf den Weg halt.
Ich hab was vergessen.
Die Papiere.
Okay.
Der Helm ist Vorschrift.
Keine weiteren Papiere.
Es ist immer ein bisschen irritierend, wenn keine Frachtpapiere drin sind.
Dann muss ich in der Dispo nachfragen und die gucken dann, ob sie die schon geschickt
bekommen haben oder müssen sie gegebenenfalls anfordern.
Wir sind auch gut in der Zeit.
Wir sind zwischen 7 und 9 Uhr angekündigt beim Kunden.
Toss, toss, toss, toss, toss, toss, toss, toss, toss, toss, toss, toss, toss, toss.
Moment, wenn wir gerade dabei sind, zu der Musik passt es einfach richtig gut.
Wo habe ich mein Kokona-Emote?
Da roll.
Toss, toss, toss.
Moment, Leute, Sekunde, das muss jetzt sein.
Ich weiß, wir skippen jetzt.
Haben wir schon eine Weile.
Warum geht das nicht?
Was ist TOS?
Terms of Service.
But I remember Twitch Chat from those days that are gone.
Twitch Emotes from long ago.
Made you feel you're not alone.
Capapuck Champ.
Keep a forehead.
Bible Thumb.
Twitch Emotes.
I remember typing Dan's game, forehead swift rage, PJ salt and fail fish.
Life was easy, spamming all the time, TOS was nowhere.
So everyone's feeling fine, twitchy modes, long ago.
Der Papock-Champ, Keeper Forehand, Bible Thumb, Wichimals,
Der Franker hat das Decker gesehen.
You're not alone. Pog is PogChamp. Cap is CapBug. BibleThumb. TwitchyModes. PeppiHands. TwitchyModes. BibleThumb. TwitchyModes.
So, das muss jetzt mal sein zwischendurch.
Irgendwie hat mich die Musik da so dran erinnert.
Wie heißt das Video, wo die Emotes durch den Wald gehen und es doch...
Ah, du meinst, Moment.
Keck W vs. Lull W.
Das da meinst du, gell?
Was meinst du, dass ich verfehlt habe?
und war 13 Jahre selbstständig. Das ging dann mit Corona.
Der hat bestimmt früher die Grafiken für die CT gemacht.
Die sind jetzt alle nur noch AI-generated.
Corona leider endgültig dem Ende zu.
Und dann habe ich halt überlegt, was ich machen möchte oder was ich machen kann.
Und ich habe von früher noch einen Zweier-Führerschein.
Da habe ich mal in der Brauerei gearbeitet.
Die Geschwindigkeiten muss man ein bisschen im Auge behalten, gerade wenn man voll ist.
Ja, und halt defensiv fahren, Abstand halten zu den Vordermännern.
Mit der Gefahrgutfahrerei, der Worst Case ist, dass ich entweder einem hinten drauf
fahre, dass es einen Personenschaden gibt.
Und das andere ist natürlich, dass mit der Fracht irgendwas ist, dass der komplette LKW
weil ich ausweichen muss hier.
Wir sind angekommen in Waldkreiburg.
Wir fahren jetzt hier auf den Hof.
Ja, die Mail ist da.
Dann baue ich mal den Drucker auf.
So, dann hoffe ich mal, dass das alles reicht.
Ist das Glas drin?
Erst mal ein Fax schicken.
die probe geht dann ins labor und dann checken die ob die zusammensetzung passt
die haben zwar das an der lüge hat bis jetzt den ganzen tag gearbeitet das
kennt man ja von vielen dieser videos da gar nicht das schlimmste video war sich
bisher in der richtung sehr war diese eine projekt managerin die den ganzen
tag in excel rum geklickt hat drin aber wenn es im tank ist es im tank dann
kriegen sie auch nicht wieder raus ja wenn die probe frei ist können abladen
Es gab schon Produkte, wo ich ein bisschen Abstand genommen habe.
Da haben wir in Memmingen Salzsäure hingefahren.
Die haben dann auch gemeint, wir sollen da Probe nehmen.
Das habe ich aber dann abgelehnt. Das haben die dann selber machen müssen.
Es gibt da schmerzfreie Leute, die sich in diese Salzsäurewolke reinsetzen und so tun, als ob das gar nichts wäre.
Da bin ich dann ein bisschen vorsichtiger tatsächlich.
Ja, das würde ich verstehen.
Normalerweise, wenn es durchfällt, gibt es einen zweiten Durchgang für die Probe.
Wenn das nicht klappt, werden die den Container abweisen
und die Lieferung abweisen.
Dann kriege ich einen Vermerk auf meinem Frachtbrief.
Die erste Frage ist, ob die Temperatur passt.
19 Grad habe ich noch draufstehen. Servus.
Sind wir noch im grünen Bereich?
Dann fahren wir mal ums Haus und stellen uns hinten an.
Ich mache dann einfach irgendwas.
Im schlimmsten Fall höre ich Radio.
Da bin ich meistens bei Bayern 2 unterwegs oder höre irgendwelche Podcasts nach, die es gibt,
bei Radio Wissen oder alles Geschichte.
So, fahr ich mal vor.
So, Entladung gestartet auf dem Tablet.
Erstmal die Sicherheitsbrille an.
Toss, toss, toss, toss, toss.
In dem Tank habe ich eine Flüssigkeit drin.
Wenn ich das mit Luft rauspressen will, dann muss ich ja irgendwie den Druck da drin aufbauen.
Und das macht man mit einem Kompressor mit Druckluft. Fertig. Kann man anschließen.
Wort von gestern gibt es nicht mehr. Hat einer den Anfangsbuchstaben von meinem Nachnamen geleakt?
Wenn ich eine Belüftung habe, also der Kreislauf nicht da ist, dann kann es passieren, dass mir der Tank zusammenzieht wie eine Cola-Dose.
oder ich pumpe zu viel auf, dann könnte es im schlimmsten Fall sein, dass der Tank, dass
den Tank zerreißt.
So, das ist die Kamera.
Das wäre schlecht.
Da fragt man sich manchmal, wie die Leute das überhaupt zugekriegt haben.
Ganz ehrlich, das habe ich noch nie gehabt und ich kann aber hier nicht mehr drehen,
weil der Haken da unten drin ist und ich kann auch das Blech nicht so weit biegen.
Das wäre jetzt schlecht, wenn wir da mit 6000 Liter wieder nach Hause fahren, weil
das Ding da nicht aufkriegen und eine Flex habe ich auch nicht dabei.
Dann haben sie es wahrscheinlich mit aller Gewalt zugedreht und ich konnte es aber mit
aller Gewalt nicht wieder aufdrehen und dann war eben das Problem, dass der Hebel sich nicht hat
weiter drehen lassen und an dem Blech aufgestanden ist. Wenn der Hebel abbricht, ist glaube ich
schlecht. Ne, der Job wäre überhaupt nichts für mich.
Wo hohe Kräfte sinnlos walten, also ich mache da die Schrauben auf und das Blech ein bisschen
runter und dann werden wir das schon aufkriegen.
Zange.
Tadaaa.
Das ist auf.
Das ist auf!
Das muss bestimmt erstmal gecheckt werden, dass es auch dicht ist, bevor man auftritt.
Ich glaube, das war's.
Berufsunfähigkeitsversicherung habe ich nicht.
Mein Freund hat mal gesagt, Christian, dir scheint doch eh die Sonne aus dem Arsch.
Bis jetzt hat er recht gehabt.
Du verdienst sechsstellig auf 40 Stunden.
Ja.
Passieren kann natürlich definitiv was.
Es gibt tödliche Abstürze bei dem Job.
Also es fallen Leute von dem Container runter.
ganz herzlichen dank
was hat für ein komisches geräusch
hat es gehört
Quack, quack, ja, was war das denn?
So als hätte das einer reingeschnitten in der Bearbeitung danach.
Von dem Chassis, ob das alles noch TÜV gerecht ist.
Die Fahrzeuge müssen regelmäßig überprüft werden, die haben eine jährliche Kontrolle.
Mit den ADR hängt das natürlich zusammen.
Es ist schon wichtig.
Es gibt Firmen, die fahren bis nicht mehr, bis das Fahrzeug steht.
Also man sieht das ja in den einschlägigen Portalen, wenn sie die Leute rausholen und
die LKWs im Grunde genommen nur noch durch den Rost zusammengehalten werden.
Beim ADR-Transport denke ich mal, dass da schon ein größeres Augenmerk drauf liegt.
Dann fahren wir zum Bahnhof und setzen den Container ab.
So, da sind wir wieder.
Den anderen Container für morgen, den muss ich oben holen.
Er ist auch den ganzen Tag beschäftigt.
Beim Gefahrgut abholen musst du dich ausweisen.
Das geht.
Fällt hin.
Auf geht's.
Wisst ihr was?
Das sieht ein bisschen aus wie Frankfurt am Ostbahnhof.
Ist es wahrscheinlich nicht?
Sieht sehr ähnlich aus.
Okay, Frankfurt auf...
Also ist es nicht, aber...
Wo kann man da jetzt mal auf...
Äh.
Ist ja schon Satellit.
Äh, wo sind denn die ganzen Container hier am Ostbahnhof?
Ist das jetzt blöd?
Hier stehen doch übelst viele Container rum.
Oder ist das eher ein bisschen davor?
Hier.
Das sind eher Züge, ne?
Ist das blöd?
Also aus irgendwelchen Gründen stehen hier keine Container rum.
Dabei ist das alles voll mit Containern am Ostbahnhof.
Na gut.
Whatever.
Hier! Da!
Das meine ich.
Ich meine, das sieht ein bisschen aus wie am Ostbahnhof, oder?
Ist auch so ein Hebeding und sowas.
.
Der Bahnhof macht erst um halb sechs auf.
Deswegen setze ich den jetzt auf,
stelle den ab und fahre morgen in aller Früh los.
Nein, schon wieder Toss.
Toss, Toss, Toss, Toss, Toss, Toss, Toss, Toss, Toss, Toss, Toss.
und dann war's das.
Toss, Toss, Toss, Toss, Toss.
Hat nicht ganz geklappt heute mit 2 Uhr.
Ja, aber das ist halt so.
Ich habe ein Grundgehalt von 3.000 Euro.
Da gibt es verschiedene Zuschläge.
Wir haben die ganz normalen Spesen.
Dann haben wir ein Urlaubsgeld
und eine Vergütung für die Betriebszugehörigkeit.
Dann gibt es dazu noch Vergütungen für...
Ich dachte, er hat irgendwie einen Gefahrenzuschlag oder so,
weil er damit so gefährlichen Sachen hantiert.
Feiertagszuschlag und Nachtzuschlag. Die Bezahlung finde ich okay. Das könnte natürlich immer mehr sein.
Immer, ja.
Grundsätzlich, glaube ich, verdienen wir gar nicht so schlecht im Vergleich.
Im August diesen Jahres hatte ich ein Brutto von 3.300 Euro ungefähr.
Ich habe ab Oktober einen Brutto-Entgelt-Festgehalt 200 Euro mehr.
Im vergangenen Kalenderjahr 1924 hatte ich ein Einkommen mit allen Zuschlägen von etwa 35.600 Euro.
Das ist aber echt nicht so viel.
Hallo?
Ich glaube, die sind noch in der Bibliothek.
Wir wohnen in dem Haus von den Schwiegereltern.
Also für die Arbeit ist das echt wenig.
Der ist den ganzen Tag beschäftigt.
Schaft er richtig was für?
Ja, hier Spielzone, wie man sieht.
Die Kinder sind kletterbegeistert gerade.
Hallo mein Schatz, der Bayerische Rundfunk ist da.
Der Große ist der Simon und der Kleine ist der Jakob.
Der freut sich ja richtig.
Meine Frau arbeitet bei der Stadt München im Klärwerksbau und managt quasi alles.
Und wenn ich zu Hause bin, versuche ich mich natürlich schon noch ein bisschen einzubringen.
Dürfen wir Knoblauch reintun? Ein bisschen schon, oder?
Es gibt jetzt keine strikte Trennung von den Finanzen. Das läuft alles in einen Topf.
Aus meiner Sicht lohnt sich das, was natürlich eine Frage der Perspektive ist.
Wenn ich jetzt nur die Zeit sehe, die ich da einbringe, ist es für mich persönlich schwierig.
Wenn ich jetzt LKW fahren möchte, wo ich nicht gegen die Uhr fahren muss, ganz wichtig, dann ist diese Tankcontainer-Geschichte super.
Dann guten Appetit.
Das war mir zu hoch, das habe ich nicht gecheckt. Finde ich das jetzt gut oder schlecht?
Toss, toss, toss, toss, toss.
Das war's von mir und dem Tankcontainer Transport. Weitere Videos von Lohnt sich das gibt's hier und hier.
War zur Abwechslung einer, der was geschafft hat. Nice.
Job, auf den ich absolut null Bock hätte. 7LQS, dankeschön.
Der Wort wurde gelöscht, weil einer den ersten Teil von meinem Nachnamen geleakt hat.
Ich vermute ja, da ist er auch nicht auf ganz legalem Wege drangekommen.
Wahrscheinlich arbeitet er bei irgendeinem Dienstleister oder so, wo man Zugriff auf Logfiles hat.
...


...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...
...

...
...
Das ist bestimmt cringe, solche Beiträge.
Moment.
Die Omas kriegen jetzt Linux.
Sekunde.
Hallo.
Brigitta Thürroller hat ein Problem.
Thürroller?
Habe ich das richtig verstanden?
Geiler Name, Alter.
Thürroller.
Ich hab grad Zeit.
Seit Mitte Oktober gibt es für ihren Laptop keine Sicherheitsupdates mehr.
Sie haben einen Laptop zum...
Genau, ArchCLI only.
Ja, das ist ein Windows 10er.
Hier bei der Computerspende Regensburg wird Menschen wie Brigitta Türoller geholfen.
Da haben sie ja noch einen antiken Monitor.
Sieht aus wie einer der ersten LCDs.
Wobei, nee, ist es nicht.
Dann gehe ich mit einem funktionierenden Laptop wieder heim.
Wunder braucht es nicht.
Die ehrenamtlichen Computerspezialisten um Aaron Holmer in Regensburg können den meisten hier helfen.
Na ja, erstmal würde ich das Gerät starten, um zu schauen, okay, ob es überhaupt geht.
Erstmal Backup von der Platte ziehen auf ein USB-Laufwerk, dass man den Kram da wieder ordentlich drauf kriegt.
Geht noch.
Aber läuft eben auf Windows 10.
Mein Vater benutzt auch Linux Mint, jetzt seit drei Jahren oder so.
Ich habe das dem einfach hingestellt.
Ich habe so einen Mini-PC hier noch gehabt, so einen kleinen.
ungefähr die Größe von einem Mac Mini
und
habe ich einfach Linux Mint drauf gehauen
mit Auto-Updates
und seitdem läuft es
geht einfach
ungefähr die Hälfte aller Windows-PCs
in Deutschland
Schätzungen zufolge sind das noch über 20 Millionen Geräte
Grundsätzlich haben User
Du darfst nicht vergessen, Windows 10 ist das letzte Windows, was es gibt
Dein Vater hat selbst Home Assistant installiert
Ist dein Vater noch im Love Scam involviert?
Du meinst, ob er noch Leute scammt?
Ne, der wird jetzt gescammt
Früher hat er Leute gescammt, jetzt wird er gescammt
Hat mich letztens angerufen?
Ja, ja, da wird noch gescampt.
Mein Vater hat mich letztens angerufen und hat gemeint, er hat ein Kind in der Karibik.
Ich hab gesagt, hä? Wie jetzt? Wie kann das sein?
Und da hat er gemeint, ja, die haben ihm ein Foto geschickt von seiner Tochter aus der Karibik.
Das ist halt offensichtlich krass obviouser Scam.
Viel offensichtlicher könnte der Scam nicht sein.
Die haben ihm halt einfach ein Bild geschickt und gesagt,
es ist deine Tochter so.
Und er glaubt es halt.
Er glaubt es halt.
Oh Mann.
Und wie soll das entstanden sein?
Der war mal da, ja
Der war mal da
Ich will da gar nicht genau wissen, was gelaufen ist
Tja, beides irgendwie
Das, okay, ich erzähl euch das
Der war
irgendwie mal im Urlaub in der Karibik.
Oder weiß nicht, ob er da zum Urlaub machen hingefahren ist
oder zum...
Ja, was...
Weiß es nicht genau.
Zumindest war der mal da.
Und
da wurde er schon
gescampt.
Die haben ihm dort
sein Geld geklaut.
Mir läuft die Nase, Alter.
Die haben ihm dort sein Geld geklaut.
Und irgendwie auch seine Bankkarte mit PIN.
Und die haben dann nachher noch Geld abgehoben und sowas.
Aber es wurde da noch schlimmer.
Das habe ich euch glaube ich schon mal erzählt.
Der ist dort dann ins Krankenhaus gegangen.
und hat sich da behandeln lassen, was auch immer die da gemacht haben, keine Ahnung.
Und dann hat er entweder zu wenig Geld dabei gehabt oder wollte sich verpissen, ohne zu bezahlen im Krankenhaus.
Und dann haben die gesagt, Herr Max Papa, wir lassen Sie hier nicht weg, bevor Sie nicht bezahlt haben.
und dann hat mich mein Vater angeschrieben
damals, das ist schon ein paar Jahre her
hat mich angeschrieben
und hat mir die abenteuerlichste Story
überhaupt erzählt
und zwar hat er gesagt
er ist gerade in der Karibik
und er würde entführt
und die wollen 500 Euro Lösegeld haben
ob ich ihm das nicht überweisen könnte
ihr müsst euch mal überlegen
wenn euch euer Vater
so ein Bullshit erzählt
ja, hat er gesagt
er wurde entführt und die wollen 500 Euro
Lösegeld haben, ob ich ihm die nicht überweisen könnte
hätte der Typ einfach gesagt
ich bin dort ins Krankenhaus
gegangen, hab zu wenig Geld
gehabt und jetzt sitze ich hier fest
bis ich es bezahlt hab, hätte ich ihm die
Kohle doch auch gegeben, der hätte ja gar
nicht, mein Vater erzählt gerne solche
Random-Stories, solche
ausgedachten Storys, ja
und
ich hab das dem damals schon nicht geglaubt
aber ich hab
realisiert, okay, der sitzt anscheinend
wirklich fest, ich hab ihm halt das Geld überwiesen
und das Geld hab ich by the way
bis heute nicht wieder gesehen
das war mir aber irgendwie damals schon klar
dass ich das Geld nie wieder sehe
ja, das hat er auch schon wieder vergessen
das hat er auch schon wieder vergessen
und dort wurde er schon
gelovscammed und moneyscammed
und alles und das sind wahrscheinlich
jetzt die gleichen, die ihm erzählen, er hätte
angeblich eine Tochter.
Wahrscheinlich haben sie, ohne
Scheiß Leute, es kann durchaus sein, dass die sogar
das
KI generiert haben,
das Bild
von seiner angeblichen Tochter.
Die haben quasi
das Bild von ihm genommen und haben
gesagt, generiere mir mal ein Kind,
was so ähnlich aussieht.
Krass, oder?
Das muss man überlegen.
Aber mein Vater hat schon immer so komisch...
Der hat schon so viel merkwürdige Dinger getrieben.
Zumindest hat er ja früher selbst Leute gelovscammed.
Weiß ich nicht, ich kenn das Bild nicht.
Früher hat er ja selbst die Leute lovscammed.
Und heute wird er lovscammed.
Jaja, hat er mir schon erzählt
dass ich ergeblich eine Schwester hab
Halbschwester hab ich ja eh
aber
ja
Das ist quasi
auch dann nur Halbschwester, wäre es
Aber das Kind wette ich mit euch
Also doch
Es kann durchaus sein, dass das existiert
Aber das ist halt irgend so ein...
Wahrscheinlich schicken die das allen vermeintlichen Vätern zum Love-Scam.
Ja, sowas ähnliches hat er tatsächlich gesagt.
Der hat mir erzählt, ja...
Wenn es ihn mal nicht mehr gibt, ob ich mich dann um die kümmern kann oder sowas, hat er mir erzählt.
Und da habe ich gesagt, nee.
Ganz bestimmt nicht.
Ich habe ihm nochmal gesagt, dass ich eh denke, er wird gescampt.
Aber für seine Eskapaden da in der Karibik unten werde ich garantiert nicht aufkommen.
Ganz bestimmt nicht.
WTF, Alter?
Wie dein Vater hat Love Scamming gemacht? Ja, mein Vater hat Love Scamming betrieben. Damals, 1900, keine Ahnung wann das war, 87, 90 rum, 1900 so in dem Dreh, hatte der eine Partnervermittlung in Frankfurt.
Das habe ich schon mal erzählt. Und das war quasi noch pre-Internet und sowas. Das war noch Offline-Love-Scamming. Ja, genau. Das habe ich schon mal erzählt. Zumindest für alle, die es nicht gehört haben, sage ich es nochmal kurz.
Der hatte da eine Partnervermittlungsfirma.
Und der hat halt keine Partner vermittelt, der hat halt Omas gescampt.
Die Omas sind da hingegangen und haben gesagt, oh, ich würde mir wieder so wünschen, dass ich hier, was weiß ich, der Karl ist gestorben vor 10 Jahren.
Und ich würde mir wieder so jemand Neues wünschen.
Und dann haben die Omas so einen übelst krassen Knebelvertrag abgeschlossen bei dem.
und der hatte dann so
drei, vier
gut aussehende, etwas ältere Herren,
die halt auch sehr gut reden konnten
und die hat er dann zu den Omas
heimgeschickt als vermeintliche
Vermittlungsversuch.
Das waren aber immer die gleichen Kerle,
die hat er zu allen Omas geschickt.
Und die haben
dann den Omas schöne Augen gemacht
und gesagt, wie
verliebt sie sind und so
und der Trick dabei war halt,
dass sie halt möglichst lange in diesem Abo-Modell bleiben bei ihm.
Und das hat halt richtig krass Geld gekostet.
Aber die hatten halt auch nette Herren und die Omas haben sich gefreut.
Unterm Strich haben sich alle gefreut, ja.
Nur als die gemerkt haben, dass sie gescampt wurden
und die Herren gar nichts von ihnen wollen,
das fanden die dann nicht mehr so gut.
Ja, also er hat die...
Das war quasi noch analoger Love Scam.
Das war analoger.
Das war noch offline.
Offline Love Scam.
Ja.
Mein Vater hat
wilde Sachen getrieben.
Ach ja, und das Beste ist ja, das Beste ist ja an der ganzen Geschichte, während er da Love gescampt hat und richtig fett Kohle verdient hat,
hat er meiner Mutter keinen Unterhalt bezahlt und hat gesagt, das müsst ihr euch mal vorstellen, meine Mutter hat gesagt, wie sieht es denn jetzt mal aus, wenn ich mit Unterhalt bezahle?
Und dann hat er darauf geantwortet, also, wenn ich nicht mindestens, ne, der hat gesagt, ich brauche mindestens 10.000 Mark im Monat für mich.
Davor kann ich nichts bezahlen.
Also sprich, der hat Love gescampt, Fettkohle gemacht und meiner Mutter nicht mal Unterhalt bezahlt.
Also dementsprechend könnt ihr euch vorstellen, war jetzt das Verhältnis zu meinem Vater auch nicht unbedingt das Beste, ja.
Also ist es auch jetzt nicht.
Mein Vater wäre der typische Kerl, der heute irgendwelche zwielichtigen Coaching-Workshops anbieten würde und auf YouTube bewerben.
Oder Krypto-Scam oder sowas.
Also wenn er heute in dem Alter wäre.
Heute würde mein Vater Cominny-Gruppe machen.
Also der hat damals richtig krass Kohle gemacht.
Leider hat er davon nichts mehr.
Weil wenn der Kohle hat, gibt er die immer quasi mit beiden Händen aus.
Der macht quasi, wo haben wir das Emote?
Hier.
Der macht quasi, sobald der Kohle hat, das hier.
Und dazu kam, dass er sich ja für den Schlauesten auf der Welt hielte damals, als er seine Partnervermittlung hatte.
Und der hat damals deutlich zu viele Steuern bezahlt, weil er gedacht hat, er ist schlauer als das Finanzamt.
Und die sind ihm natürlich auf die Fläche gekommen.
Hä?
Der hat zu wenig Steuern bezahlt.
Der hat rumgetrickst.
Und die sind ihm auf die Schliche gekommen.
Und dann ist mein Vater damals
in Untersuchungshaft gelandet.
Wegen Steuerhinterziehung.
Also der hat
einiges hinter sich, der Kerl.
Finanzamt fickt jeden.
Das ist auch eines der Gründe,
warum ich mir direkt einen Steuerberater
genommen habe, als ich
angefangen habe mit
YouTube und Sachen.
Dass meine Steuern immer
top korrekt sind.
Wurde er verknackt? Nee.
Nee. Wurde er nicht.
Alter, musst du nicht ins Gefängnis.
musste nicht ins gefängnis da hatte glaube ich dann zwei jahre
berufsverbot oder sowas danach und für übrigens für seine für seine partner
vermittlung scam ist frei gesprochen worden
er ist bei mir gar nicht so also ich bin was solche sachen angeht bin ich super
korrekt.
Deswegen habe ich auch einen Steuerberater
am Start. Da wird alles
ganz genau gemacht.
Tja, ne?
Schon ein krasser Dude.
So, aber jetzt, Leute.
Ach ja, wisst ihr, was ich gelesen habe?
Das muss ich euch mal fragen, ob das einer geguckt hat.
Ich habe gelesen es gibt jetzt auf ich glaube netflix oder so gibt es eine dokumentation über haft befehl
haft die abi die soll richtig gut sein
Habt ihr die geguckt lohnt sich das frankfurt gültig straße louis vitor store zahlt die kollektion bar fick auf sponsor
Schau sie dir an richtig gut okay
Guck ich mir an.
Haftbefehl Doku.
Wir können die nicht im Stream schauen.
WTF? Copyright stellt's.
Es kommt als nächstes.
Ah, lass uns zusammen mal
irgendwelche Kinofilme
gucken im Stream.
Oder was?
Der Scores Stream.
Dankeschön für den sub, excellent subscription hier.
Bald ist die Battlefield 6 Zeit wieder rum
Tja, macht ja nix
Äh, eigentlich hatte ich vor, heute Windows neu zu installieren
Aber ich bin zu faul gerade
Moment, wann läuft? Moment
Support Ende
23 ich muss nämlich beim windows auf jeden fall abdecken support eine 23 hat
zwei in vier tagen geschlossen bis dahin muss ich geupgradet haben leute ich habe
noch 23 hat zwei welches da muss ich das doch jetzt mal machen würde ich sagen
warum überhaupt windows weil windows und linux zusammen beste linux hier windows
da.
Okay, Leute.
Jetzt habe ich aber übelst Hunger und ihr werdet
nicht erraten, was es heute gibt. Es gibt
heute den Klassiker für mich, den es
immer sonntags gibt.
Du willst den Monitoring
Champ jetzt mal testen. Was gibt es da zu testen?
Das ist irgendein Bastelprojekt von gestern gewesen.
Nudel mit Lachs, korrekt.
So sieht es aus.
Nudel mit Lachs gibt es.
Also, Leute. Bis dann. Macht's gut.
See you!
