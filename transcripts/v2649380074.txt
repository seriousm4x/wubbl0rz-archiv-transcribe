Könnte ich statt das Geld in Versicherungen zu stecken einfach auch sparen und hätte im Schadensfall dann genau das gleiche.
F?
Hä? Hier ist nix, hier ist nix, F.
Ich seh's doch in meiner Vorschau, dass es noch funktioniert.
Ihr erzählt wieder Zeug, ihr jubiliert mich.
Es ist, guck mal, es ist nicht ein Frame Mist gewesen.
Jetzt ist es back?
Okay, das lag nicht an mir, das lag an Twitch.
Ich hab Twitch-Vorschau bei mir offen.
Ich hab nix gesehen, es lief die ganze Zeit weiter.
Ich hab jetzt aber auch nicht so hingeguckt.
Vielleicht hat sich's ja selbst refreshed.
Ah.
Gut.
Da muss man aber dem zugutehalten,
der schafft auch den ganzen Tag was.
Also da kann man nicht sagen,
der macht den ganzen Tag nur Excel.
Aber trotzdem.
Also so eine Beratergeschichte
wäre nichts für mich.
Und Max, wann kommt das Weihnachtsspecial mit Felix und dem Friseur?
Mit dem Felix?
Moment, welchen Felix meinst du?
Ach so, der Felix.
Von dem habe ich ewig nichts gehört.
18k im Monat, Freelancer.
Ja, Moment, hat das der Freelancer bekommen?
Oder wurde das dem Arbeitgeber,
also wurde das deinem ehemaligen Arbeitgeber
abgerechnet? Abgerechnet wird ja teilweise
da abartige
Beträge. Ob der das dann auch bekommt,
ist wieder was anderes.
Jetzt hat, okay, jetzt, jetzt hat's
bei mir auch mal geruckelt, Twitch, gerade.
mal gucken, ob es neue Package-Updates gibt.
Ich meine, wir haben schon immerhin 30 Minuten
nicht Package-Updates.
Jetzt hat es bei mir
Twitch auch kapiert.
Oh ja, ordentlich.
Jetzt ist
mein Stream nämlich auch nur 2 Minuten
online. Das hat wirklich, also
Twitch hat geruckelt.
Obwohl mein OBS lustigerweise
meint,
keine Frames misst oder skippt.
Komisch, oder?
Muss man nicht verstehen.
Ich habe eine neue Stream-Nachricht, Junge.
Okay, dann hatte Twitch wirklich Schluck auf.
Ah ja, gut, kann man nichts machen.
Ab und zu hat auch AWS mal seine Probleme.
Insgesamt muss man aber sagen,
seit Twitch bei Amazon ist,
gibt es viel weniger Probleme als früher.
Und das, obwohl die Plattform massiv
gewachsen ist.
Ich meine, das kannst du an einer Hand
abzählen, mal wann Twitch
das Jahr über Probleme hatte.
Ja, ab und zu ist das mal
aber viel, viel seltener als früher.
AWS funzt halt, ne?
Oder Amazon, ich meine, Amazon hat die Ressourcen.
Und die Kohle.
Können sich dann selbst überweisen.
So.
Dann.
Was schauen wir uns denn jetzt an?
Die Windows 11 Crisis.
Ne, das will ich mir nicht.
Wenn ich mir das angucke, dann rege ich mich nur auf.
AI.
AI.
AI.
Das gucken wir uns nicht zu lang.
KI.
Apple besser als Nvidia.
Okay, komm, wir gucken CT3003-Video.
Die sind immer ganz gut.
Auch wenn es KI ist.
Schauen wir mal.
Guck mal hier.
Guck mal hier.
Das bin ich.
wie ich endlich mal KI-Zeug auf Apple-Rechnern teste.
Und direkt Spoiler, das große, sehr gute Modell GPT-OSS 120.
Das ist bestimmt teuer, oder?
Da brauchst du vier, fünf Mac-Minis.
Die sind ja auch nicht ganz billig.
Wobei, wenn ich mir die Grafikkartenpreise angucke,
wahrscheinlich sogar keine schlechte Alternative.
... habe ich noch auf keinem Rechner,
der hier auf meinem Schreibtisch stand, so schnell laufen sehen.
Und da standen schon sehr viele und auch sehr taugend.
80 Tokens pro Sekunde?
Ist echt nicht übel, ja.
Also ich habe hier bei mir lokal auf der Grafikkarte
ein bisschen Code Assist Zeug laufen.
Und das lief hier mit 62 Tokens pro Sekunde.
Also.
Ja, keck weh.
Reload last used.
Mal gucken, wie schnell es mir beantwortet, wenn ich einfach nur sage Omega-Ludel.
Omega-Ludel.
Wie viele Tokens pro Sekunde das jetzt hier hinkriegt.
Ja.
Darfst laden.
Du bekommst mehr Token, wenn du alle Layer auf die GPU aufloadest.
Okay.
Du meinst das hier auf
48 Stellen, anstatt
auf 46?
Sonst nix, ja?
Okay, schauen wir mal.
Jetzt ist es geladen.
Pack W.
Okay,
166 Tokens pro Sekunde
Okay, das flutscht
Ja schon mal richtig
Okay, geben wir mal ein bisschen was
Schwierigeres
Beispielanwendung Rust Axiom
Websockets, so, bam
Das
Das flutscht
Das flutscht
Das flutscht ganz gut
166 Talks pro Sekunde.
Das ist nicht der PC, das ist die Grafikkarte.
Die hat 64 GB RAM.
Äh, was labere ich teilweise für einen Schwachsinn?
Der PC hat 64 GB RAM, die Grafikkarte hat 24 GB RAM.
64 GB Grafikkarte.
Kann ich mein Haus verkaufen für?
welches Linux,
was, welches Linux würde
man empfehlen zu installieren,
die ich nur für Twitch, YouTube, Netflix nutze,
hab so ein Mini-PC,
also wenn du damit vorhast,
so ein bisschen Linux anzugucken
und zu lernen, dann ist Linux Mint
nicht verkehrt,
so als Einstiegs-Linux,
wenn du richtig was lernen willst,
so Hardcore-mäßig
Linux Pro werden willst,
dann Artstilung selbst installiert einrichten. Für Gaming ist CacheOS auch nicht schlecht.
So, jetzt gucken wir das Video.
M-Studio quit.
Ein Mac Studio M4 Max mit 128 GB geteilten Speicher kostet mit knapp 4200 Euro ungefähr genauso viel wie die Nvidia DJI Spark Workstations, die mit GPT-OSS...
Dafür kriegst du zwei Grafikkarten für den Preis.
...120p deutlich weniger Tokens in der Sekunde machen.
Also Apple, denen man ja nachsagt, KI so ein bisschen zu verschlafen, performt viel besser als die OG-KI-Superfirma Nvidia mit ihrer KI-Workstation?
Hä?
Ja, beim Anzapfen von solchen großen Sprachmodellen wie GPT-USS 120B ist das auf jeden Fall ganz klar so.
Aber bei anderen KI-Sachen, da sieht die Sache schon wieder ganz anders aus.
Ich habe übrigens zusätzlich zu dem Mac Studio mit M4 Macs auch noch einen M3 Ultra mit 512 GB RAM getestet.
Und noch etliche andere Rechen.
Wie teuer ist denn bitte schön ein Mac mit 512 GB RAM aktuell?
Da kannst du wirklich mal das Haus für verkaufen, oder?
Wird wirklich interessant.
Achso, kurzer Bug-Report noch.
Unser neuer Podcast CT4004 war leider am Anfang kaputt bei Apple Podcasts.
war unsere Schuld. Falls ihr den abonniert habt und da nur eine einzige Folge drin seht,
einmal deabonnieren, 4004 suchen und neu abonnieren. Dann seht ihr alle zurzeit vier Folgen.
Liebe Hackerin, liebe Internet-Server, herzlich willkommen hier bei...
Falls ihr gerade eine Firma gründet, zum Beispiel wenn ihr was mit lokal laufender KI machen wollt
oder wenn ihr Creator seid oder sonst irgendwie selbstständig unterwegs seid,
dann solltet ihr euren Namen und euer Logo schützen lassen.
Und da kommt der Sponsor.
Ah, Werbung.
Exit.
Ganz coole Erfahrung.
Werbung, Ende.
Wenn ihr euch fragt, lokale KI, ja, was soll das eigentlich bringen?
Lokale KI ist super interessant, weil man da nicht mehr auf irgendwelche Anbieter aus USA oder China angewiesen ist,
die vielleicht klammheimlich irgendwas ändern an den KI-Modellen.
Stellt euch mal vor, ihr habt so in mühsamer Kleinarbeit komplexe Workflows auf ein bestimmtes KI-Modell in der Cloud angepasst und dann nimmt der Anbieter das aus dem Angebot oder ändert das und dann läuft euer Kram nicht mehr.
Mit lokalen Modellen seid ihr komplett safe, weil die liegen ja bei euch auf der SSD.
Problem ist nur, diese sogenannten Open-Rates-Modelle, Open Source werden die auch mal genannt, aber das sind die so gut wie nie, weil man nämlich die Trainingsdaten nicht kennt.
Also Open-Rates, ich nenne die ab jetzt einfach lokal.
Tja, warum kennt man wohl die Trainingsdaten nicht?
Könnte das vielleicht damit zusammenhängen, dass sie nicht genau wollen, dass man sieht, was da so drin ist?
Ob es da nicht vielleicht irgendwelche urheberrechtlich geschützten Sachen zum Beispiel drin gibt?
Waren lange Zeit ziemlich schlecht, aber die holen auf.
Die sind auf jeden Fall noch nicht auf dem Stand der State-of-the-Art-Cloud-Modelle wie Gemini 3 oder GPT-5-2.
Aber man kann damit auf jeden Fall schon arbeiten.
Das habe ich hier in diesem Video auch schon mal anschaulicher gezeigt, was man da so mitmachen kann.
Und es gibt natürlich auch Bild, Ton, Videogenerierungsmodelle, die auch lokal laufen und die ziemlich gut sind.
Und die man zum Beispiel auch selbst feintunen kann, die man also selbst anpassen kann, dass da wirklich der Stil rauskommt.
Also das müssen wir, das probieren wir heute Mittag mal aus im Stream.
Ich wollte jetzt die ganze Zeit schon mal hier Goose ausprobieren.
Da installiere ich mir Ulama auf meiner Windows-Kiste mit der Grafikkarte drin und dann greifen wir das Netzwerk da drauf zu und dann testen wir mal, wie gut das funzt mit Goose.
mit Goose kann man dann
so ein bisschen, wie nennt man das so schön?
Agentic
arbeiten. Also sprich, du gehst dann
in ein Projekt rein
und sagst dann,
füge mir eine
Readme-Datei hinzu
und bla bla bla und
das wollte ich mal ausprobieren.
Willst du mal ein Jimmy Nice CLI testen?
Ich will kein Geld für er ausgeben.
den man gerne haben will. Ganz aktuell ist da zum Beispiel Flux 2 für Bilder.
Oder gibt es da einen kostenlosen Mode?
Aus dem Schwarzwald.
Oder WAN 2.2 für Videos.
Das Problem ist nur, und das gilt vor allem für die LLMs, je besser die Modelle, desto mehr schnellen Speicher brauchen die meistens.
Und der schnelle Grafikspeicher von Grafikkarten ist dafür zwar sehr gut geeignet, aber man kriegt im Bereich bis, sagen wir mal, 2000 Euro für eine Grafikkarte nur maximal 32 GB.
Mein aktuelles Open Rates LLM GPT OSS 120B braucht ungefähr 63 GB Speicher.
Ja, schwierig.
Und ja, man kann natürlich auch normales RAM verwenden, also statt Grafikspeicher einfach DDR5 RAM, wenn man es sich leisten kann.
Aber nur auf DDR5 läuft wirklich kein Modell brauchbar schnell.
Seht ihr später auch in den Benchmarks, wie das läuft. Lahm.
Aber es gibt ja auch immer mehr Spezialrechner, die für KI ausgelegt sind.
Zum Beispiel die kleine Nvidia KI Workstation DJI X Spark, die es von etlichen OEMs gibt.
Haben wir auch schon mal ein Video zu gemacht von der Gigabyte Version.
oder auch die AMD Halo Strix Rechner, zum Beispiel Framework Desktop, da gab es auch schon mal ein Video dazu.
Und die nutzen alle Unified Memory, also CPU und GPU Speicher sind geteilt und schneller angebunden als normaler, zum Beispiel DDR5 Speicher.
Und das Ding ist aber, dass Apple dieses Unified Memory Konzept schon lange nutzt.
Also seit...
Ja, du kannst Apple Kisten, kannst ja per USB-C zusammenstöpseln, ne?
Einführung von Apple Silicon vor fünf Jahren, also vor dem KI-Hype.
Apple Silicon Rechner sind wegen des schnellen Speichers zumindest theoretisch super geeignet für KI.
Und auch in der Praxis gilt das so langsam.
Da wird nämlich immer mehr Software richtig gut angepasst.
Also zum Beispiel die zum Abzapfen von Sprachmodellen.
Also zum Beispiel für so Chat-GPT-artige Anwendungen.
Bild- und Videogenerierung, ja, da kommen wir später noch zu.
Erstmal Sprachmodelle, zum Beispiel das erwähnte GPT-USS120B.
Ja, und das habe ich auf zwei Apple Rechnern getestet.
einmal dem Mac-Studio M4 Max
mit 128 GB gemeinsamen
Speicher für 4174
Euro.
Das ist, äh,
ordentlich.
Und einmal dem Mac-Studio M3
Alter! Alter, wie teuer
der Scheiß ist!
11674
Euro. Wolle, danke
für den Sub. Boah!
Das geht ins Geld, äh.
Ultra mit 512 GB gemeinsamer Speicher für 11.674 Euro.
Tatsächlich sind beides aktuelle Geräte, denn wenn ihr euch jetzt wundert,
hä, M3, ist doch nicht alt.
Ne, tatsächlich sind beides aktuelle Geräte, denn wenn man mehr als 128 GB haben will,
gibt es kein Gerät mit M4 Max, sondern dann gibt es nur den M3 Ultra.
Und Ultra bedeutet in diesem Fall, dass da zwei M3 Einheiten zusammengebacken wurden.
Das nennt Apple Ultra Fusion.
Ja, und obwohl die M4-Generation eine bessere Speicherbandbreite hat, nämlich beim M4 Max 546 GB pro Sekunde,
kriegt man mit dem M3 Ultra trotzdem mehr, weil es sind ja zwei M3-Einheiten, was hier insgesamt 819 GB pro Sekunde entspricht.
Und was habe ich da nun genau drauf getestet?
Ist die komplette Unterseite der Kiste jetzt CPU, oder wie?
Testet, ja. Drei Sprachmodelle, ein ganz kleines Qen 3 4B, Q4 quantisiert, 2,5 GB.
Einfach zwei Hände groß so nebeneinander CPU-Größe oder was ist das mittlerweile?
Ja, Gwen Coder 3 verwende ich auch öfters.
groß, ein mittleres Mistral Small 3.2 24B, auch Q4 quantisiert, das ist 15,2 GB groß und ein recht
großes GPT-OSS 120B mit im MXFP4 Format 63,4 GB groß. So und ich habe ja bislang die Benchmarks
mit LM Studio manuell gemacht, aber da haben mehrere Leute angemerkt, dass man noch ein bisschen
mehr Tokens pro Sekunde mit der Lama-CPP-Bibliothek rausholen kann. Die wird zwar von LM Studio intern
auch verwendet, aber ist da trotzdem oft langsamer. Außerdem ein großer Vorteil, Lama-CPP hat auch ein
Benchmark eingebaut und der differenziert zwischen dem Verstehen des Prompts, also dem Prompt Processing
PP oder Prefill und der reinen Inferenz, also Decode oder Token Generation TG. Ja und weil ich letzte
Woche mehr Zeit hatte als sonst, weil ja kein Video kam, bin ich da richtig reingegangen
und habe auf sechs unterschiedlichen Plattformen nicht nur LAMA-CPP installiert, also über
die vorkompilierten Binaries, sondern ich habe LAMA-CPP auf jeder der Plattformen mit
möglichst optimalen Compiler-Flags kompiliert.
Das macht keinen riesigen Unterschied, aber bei meinem Test konnte ich da schon ein paar
Prozent nachweisen, also im Vergleich zu den einfach runtergeladenen Binaries.
Man kann mir also auf jeden Fall nicht vorwerfen, dass ich hier nicht fair getestet habe.
Und jetzt endlich die Ergebnisse, worauf ihr wahrscheinlich schon die ganze Zeit wartet.
Tatsächlich haben mit GPT-OSS 120B die beiden Apple-Rechner die besten Prompt-Generierungsergebnisse erzielt, die ich jemals gemessen habe mit GPT-OSS 120B.
Wie hat er denn auf der 4090 das zum Laufen bekommen?
ähm
ja gut, wahrscheinlich RAM
und Grafik
aber da brauchst du viel RAM
120 Gig
ach ne, nicht 120, ah
63 Gig, achso
ja gut, das könnte ich auch bei mir laufen lassen
das, wollen wir mal gucken
wollen wir mal gucken, wie schnell das bei mir wäre
GPT-OSS
Äh
Find ich jetzt blöd?
Ach hier
Da muss ich hin
GPT-OSS
120B
Warum nutzt der
Max 60G, wenn er 512?
Ich glaube, da kommt jetzt noch mehr.
Mit DDR5 ist das langsam.
Ja, ich denke auch, dass das bei mir langsam ist.
Wir probieren das jetzt einfach mal aus.
Hier, Download.
Wir laden das jetzt mal nebenbei, während das Video läuft, runter.
Ich hoffe, mein Stream kackt nicht ab.
Das wird ein bisschen dauern,
bis ich 64 Gig runtergeladen habe.
Wobei das ganz schön lahm ist gerade hier.
Guck mal hier, 1%.
Das dauert ein bisschen.
Gucken wir mal, nicht dass ich jetzt durch den Download irgendwelche Stream-Drops oder so habe.
Naja, dauert gut.
Interessiert mich einfach nur. Nur mal gucken, wie schnell es bei mir ist im Vergleich.
Ich meine, ich habe nur RAM und ein bisschen Grafikkarte, nicht so ein fettes Ding wie er hier am Start als Apple Cluster.
Aber gucken wir mal.
86 und 82 Token pro Sekunde.
Also wie erwartet etwas mehr beim M3 Ultra, weil höhere Speicherbandbreite als beim M4 Max.
Aber eigentlich ist der M4 Max die eigentliche Überraschung, weil der beim Generieren nur eine Leistungsaufnahme von 120 Watt hatte.
Und 82 Tonken die Sekunde bei 120 Watt, das ist wirklich krass effizient.
Der M3 Ultra braucht fast das Doppelte, aber ist immer noch viel effizienter als die Konkurrenz.
Also richtig doll effizient ist mein Desktop-Rechner mit...
Ja, hast du gut kombiniert, dass ich das bin.
... der RTX 4090 Grafikkarte.
Der macht tatsächlich 14 mal...
Die Seite ist bestimmt auch AI-generated.
Die sieht wirklich AI-generated aus.
... weniger Token pro Watt als der M4 Max.
Die beiden Spezialrechner mit Nvidia...
Jetzt macht mein Download.
Sieben...
Guck mal.
Ja, haben wir doch in annehmbarer Zeit runtergeladen.
... X-Park und AMD Strix Halo, die liegen im Mittelfeld.
bei den kleineren modellen die halt in den super schnellen videospeicher meiner grafikkarte passen
ja da kommen m3 ultra und m4 max nur auf platz zwei und drei ich habe okay ja klar das ist okay
das verstehe ich solange der ganze krempel in den grafikkartenspeicher passt ist es schneller gut
dass das leuchtet erwähnt ist weise mal die gpu deaktiviert und geguckt wie weit man nur mit der
cpu kommt nicht weit bei allen der drei sprachmodellen schon sehr langsam wie ihr hier
sehen könnt. Achtung, Achtung, jetzt kommt
ein kurzer Super-Nerd-Einschub.
Geht gleich wieder nochmal weiter.
Ja, ich weiß, Lama CPP nutzt
GGUF-Modelle. Bei Apple
kann man ja auch MLX mit
vorkonfigurierten... Ich hab absolut
keinen Börsenschimmer.
Oh, was da geht.
Was der Unterschied ist.
Sagt euch das was, Chat?
MLX ist das
Apple Machine Learning Framework, also quasi
der PyTorch-Konkurrent. GGUF?
Ich hab das mit LM Studio getestet. Ich hab keine Ahnung.
Tatsächlich waren da meine Ergebnisse mit GPT-OS S120B mit MLX schlechter als mit Lama CPP.
Und MLX lief auch auf dem M4 Max mit GPT-OS S120B auch gar nicht, sondern nur mit GT-UF.
Bei den kleineren Modellen war MLX aber tatsächlich ein ganzes Stück schneller.
Siehe hier meine Werte.
Also das solltet ihr tatsächlich bedenken.
Und das ist auch die Erklärung dafür, dass LM Studio auf macOS bei den meisten Modellen immer beide Varianten,
also gg uf oder gg uf und mlx anbietet nerd einschub ist vorbei so das war jetzt alles die
token generation jetzt kommt noch kurz das prompt processing wo es weniger auf die speicherbandbreite
ankommt da ist der m3 ultra zumindest mit den großen sprachmodell gibt die uss 120b immer noch
spitzenreiter aber das ding kostet 11.000 euro modellen da gewinnt ganz klar wieder die nvidia
Grafikkarte und auf dem zweiten Platz ist der Nvidia DJI Spark Rechner. Einfach weil die Nvidia
Kerne mehr rohe Compute Pferdestärken mitbringen. So, aber es gibt ja nun auch noch andere KI
Anwendungsbereiche als LLMs, zum Beispiel Bild, Videobearbeitung, Generierung und so weiter. Das
machen die meisten Menschen heutzutage wohl mit ComfyUI, dieser Node basierten Umstrahlung.
Das habe ich doch nie gesehen.
Comfy UI.
Source Software.
Hier gelten Nvidia GPUs als de facto Standard.
Einfach weil das alles sehr CUDA fokussiert ist.
Also CUDA, die Nvidia exklusive Programmierschnittstelle.
Ich war deshalb schon ziemlich positiv überrascht,
dass ich auf der Comfy UI Website direkt einen macOS Installer für die Desktop Variante gefunden habe.
Ich hatte mich da auf mehr Frickeln eingestellt.
Und es lief alles super.
Also zumindest...
Das wollte ich...
Könnte man theoretisch auch mal ausprobieren.
ComfyWire Windows Portable, Nvidia, 128, 126.
Chat
Was bedeutet das?
CUDA?
CU?
Kann man nicht einfach hier
CUDA-Version
Download-Comfy-UI
requires Nvidia Graphics Card
ich will lieber die Portable Variante
ist das die Fortnite Schrift da?
dann nehme ich einfach mal das
ich habe keine Ahnung, ob das jetzt gut oder schlecht ist
laden wir es einfach mal runter
ah Moment, Moment
ich lade hier noch gerade
das GPT runter
Ja, egal. Jetzt wird es langsam ein bisschen viel für den Stream mit Download, ha?
Jetzt kackt langsam der Stream ab.
Nö, macht er nicht. Aber gut.
Ich guck mal das Video mal fertig.
Ist die Installation.
Aber als ich dann für meine Tests einfach mal das Flux 2 Template aufgerufen hab und die Modelle runtergeladen hatte, bekam ich dann einfach ganz lapidar diese Fehlermeldung.
Das ist normal.
Wir denken alle, dass wir keinen Plan haben.
Macht ja nichts draus.
Ich denke das auch.
Und wir haben ja auch, ehrlich gesagt, keinen Plan.
Wenn man mal ehrlich ist, haben wir von viel, viel weniger Sachen Ahnung,
als wir keine Ahnung haben.
Das ist einfach so ein großes Gebiet.
Das ist einfach normal, dass man keine Ahnung hat.
Solange du dich in deinem Gebiet gut auskennst, reicht.
Du kannst nicht alles wissen.
Und stellt sich raus, Apple Silicon kann nicht mit FP8 umgehen, also dem 8-Bit-Gleitkomma-Format, in dem aber dummerweise so gut wie alle Comfy-UI-Modelle vorliegen, also sowohl für Bildgenerierung als auch für Videogenerierung.
Man kann sich damit behelfen, Modelle im FP16-Format zu verwenden, aber das verbraucht deutlich mehr Speicher und ist auch langsamer als FP8.
Also wenn man denn auch ein FP16-Modell überhaupt findet.
Also man will, also ich will das, auch vielleicht einfach nur die Templates anklicken und dann funktioniert das und will da jetzt nicht in den Nodes dann auch so viel rumfummeln.
Naja, bei einigen Workflows reichte das in meinen Tests auch einfach aus, in der Konfiguration von Config.UI einfach auf FP16 hier umzuschalten.
aber ich habe so kein plan von den ganzen setting weil flugs 1 dev stabil
laufen bekommen und konnte das sieht aber das sieht aber wirklich nach einer
krassen wissenschaft für sich aus
da ein bild zu erzeugen dass das sieht ja wirklich absolut next next gen high
iq aus
... da die Geschwindigkeit messen.
Ja, die Geschwindigkeit auf den Max war nicht berauschend.
Ganz grob kann man sagen, 110 Sekunden für ein Standard-Preset-Flux-1-Bild auf dem M4 Max.
65 Sekunden hat der M3 Ultra gebraucht.
35 Sekunden zum Vergleich die DJI Xperia X.
Ich werde das nochmal ausprobieren, kommt 4UI.
Und nur 12 Sekunden meine RTX 4090.
Und ja, mit Videos fange ich gar nicht erst an.
Das ist alles noch frickeliger gewesen.
Und leider haben bei den Comfy Standard Workflows auch der riesige Speicher der Apple Rechner keine Vorteile.
Einfach weil die Modelle, die ich da gesehen habe und die ich so kenne, also auch die Videogenerierungsmodelle,
die sind so gut wie alle für Grafikkarten Speichergrößen optimiert.
Ja, meistens so im Bereich bis 16 GB, ganz selten mal zwischen 16 und 24 GB.
Also auf jeden Fall, wenn man hauptsächlich Comfy UI Sachen machen will, dann ist man mit einem dieser Apple Rechner nicht wirklich gut bedient.
Aber ganz wichtig, das kann sich natürlich alles ändern.
Es sind ja jetzt auf jeden Fall schon...
Unser Azubi hat auch seine Abschlussprüfung geschrieben jetzt vor ein paar Wochen und hat mündliche Prüfung im Februar, glaube ich.
Weil ihr es gerade im Chat davon habt.
Aber die kosten halt ordentlich.
Was hat er für ein Projekt?
Gut, ich will es jetzt ja nicht so sehr in Details, nicht so sehr die Details erzählen. Er hat ein Projekt, wo er automatisch mit irgendeinem Python-Skript Server testet, ob sie so regelkonform sind. So sinngemäß ist das, was er im Abschlussprojekt macht.
Mit Pi-Infra? Ehrlich gesagt keine Ahnung.
Ich glaube, da hat sich mit Chat-GPT was zusammen-Vibe-Coded oder so.
Also maximal 32 GB, dann fährt man nach wie vor günstiger und meistens auch schneller mit einem x86 Rechner mit einer dedizierten Grafikkarte.
Aber bei Modellen wie GPT-OSS 120B mit 63 GB und meiner Meinung nach...
50% Download fertig.
...oft erst anwärtlich interessant zu werden, dann gibt es zurzeit nichts Besseres als ein Mac.
Also auch in Sachen Preis-Leistung.
Also zumindest, wenn man einfach was kaufen will.
Klar, man kann sich irgendwelche krassen Rechner frankensteinen mit gebrauchten Grafikkarten,
aber das gibt es auf jeden Fall nicht von der Stange.
Zumindest nicht zu den Preisen.
Bei anderen...
Erinnert sich noch irgendeiner dran?
wie die ganzen Miner
Rechner gebaut haben vor ein paar Jahren.
Da gab es noch diese PCI
Multiplexer oder wie das hieß,
wo du dann aus einem PCI-Slot
irgendwie 16 PCI-Slots
gemacht hast und sowas.
Fürs schnelle Hashen.
Das ist ja
komplett
out jetzt.
Übrigens, ich habe letztens ein super
nices Bild gesehen.
Mal gucken, ob ich das noch finde.
Finde
mining data center cats
ja genau
das ist ja weinig körper das angeblich angeblich ja irgendeine in irgendeinem china china chinesen
Hinterhof standen
Bitcoin-Miner und die haben
sich gefragt, warum werden unsere Server
auf einmal so warm?
Und da sind sie reingegangen, haben reingeguckt
und da saßen auf den
Servern die ganzen Katzen rum.
Die haben festgestellt, da ist warm von unten.
Hast du mal den Link
dazu hier?
Ja.
Äh.
Hier.
Wie die Katzen da reinkommen.
Ja, wahrscheinlich ist das alles nicht dicht.
Er weiß, wo das steht.
In irgendeiner ollen Halle oder in irgendeinem ollen Keller oder keine Ahnung.
Aber das ist schon geil, oder?
Die stellen einfach fest.
Ah ja, hier ist ja schön warm.
Da sitzen wir jetzt mal eine Runde.
So, was sagt denn mein Model-Download?
60%
Und was sagt mein
Comfy-UI-Download?
Moment
Muss mal hier minimieren
Wir entpacken das mal kurz
Comfy-UI
Alter
About 20 minutes?
What the fuck? Ich bin auf ner
PCI 5
NVMe
SSD. Warum dauert
das so lang?
Was ist da los?
Heck, wait.
Windows Zip Extraction ist komplett
useless. Ja, ich habe kein
extra Zeug mehr installiert hier.
Ah, jetzt gibt er hier
Vollgas.
So auch nicht.
Naja, solange der Stream nicht ruckelt davon.
Was macht mein Download? 66%.
Okay. Das probieren wir
jetzt mal aus. Da bin ich echt gespannt,
wie schnell das Model bei mir ist. Also er hatte
ungefähr im Benchmark auf
seiner Apple-Kiste
80 Tokens pro Sekunde.
Was meint ihr, wie schnell es bei mir sein wird?
Wie gesagt, ich kann es ja nur über den RAM machen
und über 24 GB Grafikspeicher.
Das wird richtig hardcore lahm sein.
Wahrscheinlich irgendwie, keine Ahnung,
5 Tokens die Sekunde oder so.
Ja, mein Rechner wird wahrscheinlich ziemlich hochdrehen gleich.
Aber gucken wir mal.
Also meine Wasserkühlung musste in letzter Zeit tatsächlich ziemlich ackern.
Mit Steam Games.
unreal 5 unreal 5 game zieht ordentlich leistung und die grafikkarte wird richtig
warm und cpu und alles also das richtig das richtig am blasen der rechner
Oh, warten wir noch, bis der Download fertig ist.
So, was haben wir denn sonst noch?
Das haben wir jetzt...
Das wollen wir nicht gucken.
Das wollen wir jetzt auch nicht gucken.
Investigating the most expensive phone brand.
Das können wir gucken.
Warum will mir YouTube unbedingt diesen Short zeigen, dass Shoryoka pleite ist?
Das ist mir sowas von wurscht.
Das hört sich ja alles super legal an.
Mach doch nicht anzeigen lassen.
Ja, wie? Wie? Wo?
Hier? Ich bin nicht eingeloggt.
Das geht nicht.
Keine Chance.
Ja, geht nur, wenn man eingeloggt ist, ne?
79%
Alter, mach hinne!
Was macht mein, was macht mein Entpack, Entpack-Vorgang?
Äh
Ist es fertig?
Ich glaube, es ist fertig.
Comfy UI
Run CPU
Run
Read
Very important
If we have
Nvidia GPU, run
Nvidia But.
Warum irgendwelche Buts?
Was passiert da, wenn ich das ausführe?
Python Embedded.
Okay.
erst einmal kommt für juli
vielleicht ist doch besser nicht aus ich glaube nicht dass es problematisch ist ich
Ich glaube nicht, dass es irgendwie problematisch ist.
Ah, man weiß ja nie.
Wir gucken uns jetzt erstmal lieber das Model hier an.
Das ist gleich fertig runtergeladen.
Ups.
Oh ne.
Wie?
Ist es jetzt abgebrochen?
Wie?
Wie, ist es jetzt fertig?
Ist der Download fertig?
Ich glaube, der ist fertig mit Download.
Hä?
Habe ich den Download jetzt irgendwie abgebrochen aus Versehen?
Oh, nee, oder?
Fuck! Ich glaube, ich habe den Download irgendwie abgebrochen.
Unten links? Ach so, da.
Okay, ich habe nichts gesagt.
Ich bin halt nicht mehr so auf Zack, was das angeht.
Ich bin jetzt schon 41.
Da ist das nicht mehr so schnell.
Old Girl.
Die Anzeige ist übrigens auch viel besser.
Dieses Emote brauchen wir.
Okay, zeig mal her.
Ja, ich hatte mal so ein Old Emote.
Aber das ist irgendwie weg.
Aber wir fügen das hinzu.
Oldge.
Ja, 41 mittlerweile.
So ist der Download-Bot mal fertig.
Finalizing Download.
Okay, dann finalize mal.
Okay, keine Ahnung, was das da so lange macht im Hintergrund.
Guck mal kurz, Task Manager.
Macht der irgendwas?
Nee.
LM Studio.
Okay, der macht Dinger.
Dann müssen wir ihn mal kurz weiter brödeln lassen.
Dann schauen wir uns jetzt das hier an.
Investigating the most expensive phone brand.
43.
Wir sind alle echt alt.
Na gut.
Glücklicherweise ist der
Chat-Durchschnitts-IQ
immer noch höher als das
Durchschnittsalter.
Warum braucht man das so lang?
Traum ein Video.
Das ist ein 5400 Euro Smartphone von einer Firma namens Vertu.
Und es ist so luxuriös, dass ich es einfach...
Das sieht richtig billig aus.
Findet ihr das? Das aussieht wie ein 4500 Euro.
Das sieht aus wie irgendein billig China-Chinesen-Ali-Express-Ding.
Press this...
Oder? Das sieht richtig billig aus.
...this rupee button and be immediately connected to a personal concierge
who will try to solve my every need.
Das ist doch AI, oder?
Das ist irgendein AI-Chat.
Das sieht so billig aus, irgendwie das Ding.
Ihre offiziellen Social-Media-Accounts haben hunderts von Millionen echten Ansätzen erhoben.
Sie verkaufen in Harrods, einem wirklich gut errichteten Uber-Luxury-Departement-Store im UK.
Ich habe sogar einen Trip selbst genommen, um sicherzustellen und...
Na dann, Load Model.
Also, GPT, OSS, 64GB Model. Mal gucken, wie schnell wir sind.
Wow.
Es freest. Es ist komplett gefreest.
Mein Rechner ist gefreest.
MonkaS?
MonkaS?
Geht das Stream noch, Leute?
Ist doch alles da, ja?
der lädt der lädt einfach mit 730 megabyte sekunde das model gerade
Boah, das ist ein fettes Model
Äh, ist
Kann das sein, dass mein Speicher ausgelastet ist?
wenn er sagt 99%
oder ist das 99% frei?
Oh, fuck.
Mein Arbeitsspeicher ist komplett voll.
Sekunde, Leute. Ich mach mal die VM aus.
Ich mach mal kurz die VM aus.
Brauchst du nicht mehr als 64 GB für einen 64 GB?
Ich hab noch 24 GB RAM.
Äh, 24. 24 GB Grafikkartenspeicher.
Oh, shit, Alter.
Das ist ja komplett...
Das ist ja komplett am...
Am Anschlag, ey.
Also, übrigens.
Ich bin mir gar nicht sicher,
ob ich das richtig rechne überhaupt.
Darf ich denn überhaupt 64 GB
plus 24 GB für Grafik
Speicher rechnen?
Dass das überhaupt...
Die VM ist aus.
Ja, die ist aus.
Trotzdem, voll am Anschlag.
64 GB.
Okay, es ist geladen.
Es ist geladen.
Okay, clear all messages.
Keck W.
Task Manager.
Oh, Alter.
Du mein ganzer...
14 tokens die sekunde das geht doch das geht doch gar geht doch sogar voll klar oder gpu
auf offload soll es etwas platz für den kontext lassen ich verstehe den satz den
du sagst aber ich weiß nicht wie und wo
es wird der rahmen endlich mal genutzt okay was ist das beste twitch im ort
das beste twitch im ort ein kleiner überblick ja aber ganz ehrlich es ist
noch in einem sagen wir in einem halbwegs benutzbaren geschwindigkeit
das ist zwar es ist zu lahm um es jetzt wirklich regelmäßig täglich zu benutzen
aber es ist noch es ist auf jeden fall nutzbar
mein rechner tritt kann voll hoch der tritt kann tritt kann voll auf
konnte man den ich ja auch mal gpu anzeigen lassen ging es nicht
auch konnte der task manager nicht auch mal gpu
Ach hier.
GPU.
Ja, hier.
Wie viel Tonken braucht man für regelmäßig?
So viele, dass es für dich flüssig anfühlt.
Das wäre mir jetzt ein bisschen zu langsam.
Guck mal, wie lange man jetzt hier drauf warten muss.
Guck mal, jetzt hat er hier
10, 10 Talkens pro Sekunde
Das ist, das ist dann noch ein bisschen lahm
Ja
Ich weiß nicht, Chat
Ab wann fühlt sich, ab wann fühlt sich
Sowas gut benutzbar an
20 Talkens die Sekunde vielleicht
30 Talkens die Sekunde
Gibt dir mal das Rust Problem von gestern
Ich hab das schon gelöscht
Ähm
Vielleicht haben wir das noch.
Vielleicht haben wir das noch hier.
Aber ich kann die vor allem jetzt nicht starten.
Wir hatten den AI-Modus von Google.
Vielleicht hat man das...
Nee.
Hattest du das nicht in Chat-GPT auch?
Doch, ich mach mal die VM an.
Fuck.
Mein RAM ist total überladen jetzt.
Shit.
Ich guck mal, ob ich noch Chat-KPD von gestern aufhab, wo die Frage drinsteht.
Wonka ist.
Endlich hat mal meine Hardware was zu tun.
Ne, ist nicht mehr da.
Vielleicht habe ich es hier noch beim Copy-Paste.
Oh, wie das ruckelt, Alter.
Ne, das ist uralt.
Okay, ne, ne, ne, keine
Keine Chance, aber ich kann das
Ich kann das Problem
WTF, ich kann das Problem
Ich kann das nochmal fragen, hier, Moment, wir machen
Die VM wieder aus, das ist einfach zu krass
Ähm
Also ich kann das, kann das hier
Fragen, ähm
Du meinst dieses Problem mit
Nested, nested Jason, gell
Ich habe ein
Rastprogramm
mit dem Tracing Crate
und ich will eine
Hash Map als
Nested Object
mit Tracing Loggen.
Wie mach ich das?
Schauen wir mal.
Ich glaube, ich hab's gestern
anders
formuliert.
need german answer explaining
ja aber das ist nicht richtig
das stimmt halt so nicht
aber wir können wir können es ja danach noch mal fragen sage ich will es nicht
als String, sondern als echtes
Object Log.
Das hat uns die AI
gestern auch erzählt, dass man das so machen soll.
Aber
das war natürlich
Blödsinn.
Ah.
Ja, genau.
Das ist ja das Verkehrte.
Aber ihr seht, es ist jetzt schon ein bisschen
nervig zu benutzen.
Mit der Geschwindigkeit.
Da hätte ich jetzt
keinen Bock drauf, ehrlich gesagt.
Das regelmäßig zu benutzen.
Und es ist halt auch typisch Chat-GPT.
Es schwätzt halt hier ohne Ende.
Und über all diese
komischen dummen Emotes davor.
Ich weiß jetzt schon, dass die Antwort blöd ist.
Kann man das irgendwie abbrechen?
Ah, hier unten.
Egal, wir lassen es mal.
Also ich finde es auch zu langsam.
Ich finde es auch zu langsam.
Das könnte ich auf Dauer nicht benutzen.
Hast du ein Model mit 30 Tokens die Sekunde?
Ich habe ein Model mit 80 Tokens die Sekunde.
Kann ich dir zeigen zum Vergleich.
wie das flutscht.
Das ist zum Ausprobieren gut,
zum Benutzen nicht wirklich.
Copy Message.
Wir starten nochmal einen weiteren Chat.
Gott, es hört ja gar nicht mehr auf.
Das stimmt übrigens nicht.
Das stimmt überhaupt nicht.
Das schreibt totaler Mist.
Das sieht überhaupt nicht so aus.
Das stimmt überhaupt nicht.
Guck.
Der.
Der.
Das funktioniert.
Das funktioniert.
Kann ich...
Ich frag dir jetzt was.
Kann ich...
Ich will...
Das Object.
Ich will
die Hashmap
als Nested Object
loggen. Nicht als
String in String.
Geht das mit
Valuable?
Wir fragen ihn mal. Wir wissen ja schon,
was man braucht.
Gucken wir mal, ob es zumindest irgendwie auf die richtige
Antwort kommt.
Das ist zu lahm.
Das ist zu lahm.
Okay, okay.
Wenn man ihm erklärt, was er machen soll,
dann checkt das.
Mal gucken, ob die Erklärung sinnvoll ist.
Aber das ist zu lahm.
So, jetzt zeige ich dir mal was anderes,
weil ihr gesagt habt,
wie sieht das aus, wenn es schneller ist?
Also so ist halt lahm as fuck.
Ich brech das mal ab.
Eject.
So, neuer Chat.
Model A, nehmen wir Quen Coder 3.
Das ist nur...
Ich glaub 16 Gig.
Ne, noch weniger.
Noch weniger.
Das ist 3 Gig oder so groß.
Nicht groß.
Das passt also komplett in die Grafikkarte rein.
Quen-Coder ist aus China, ja?
Das ist Diebsieg, glaube ich.
Oh, stellen wir mal volle Pulle auf die Grafikkarte.
Und jetzt geben wir dem mal die gleiche
Messe. Ich habe mal nachgefragt,
wie mache ich das?
Bestes Object, also nicht
String in String
als echtes...
So, guck mal hier.
Das ist schon besser, oder?
Fertig.
108 Tokens die Sekunde.
Bam.
So sieht es halt aus, wenn es komplett in die Grafikkarte passt.
GPT führe ich aus.
So eine Mischung CPU und GPU.
Ja, bisschen GPU-Offloading.
Aber das Model checkt's halt auch nicht.
Das ist halt auch Blödsinn.
ich weiß nicht das stimmt das stimmt ja eben nicht
kann man das nicht mit value able machen
das eine sehr gute besonders aber wenn man ihm
Nee, das Model, also für Rust ist das anscheinend nicht so as valuable.
Nee, nee, das stimmt nicht.
Das stimmt nicht.
Das Model macht Mist.
Das macht Mist.
Das macht Mist.
Na gut.
Genug rum.
Gespielt.
mit AI stellst.
Und das aus.
Gucken wir jetzt noch das Video fertig hier.
Most expensive Telefon.
Also wie gesagt,
ich finde die Dinger sehr...
Das sieht aus wie so ein typisches
China-Chinesen-Ali-Express-Telefon.
Das sieht billig as fuck aus.
So klobig
und eklig
und das sieht einfach mies aus.
Es kostet, guck mal.
Es kostet nur, nur 8500 Euro.
Ein Schnapper.
Natürlich, natürlich.
Keine AI, garantiert nicht.
Die Uhr sieht auch super billig aus, man.
Das sieht...
Ich kann mir nicht helfen.
Es sieht einfach nach billigem AliExpress-Krempel aus,
wenn ich mir das so angucke.
Was ist denn das?
Hat da einer die falsche Farbe vorne draufgeklebt, oder wie?
Ja, kann man ja auch nicht erwarten bei 5000 Euro, dass da ein Ladegerät dabei ist.
Das ist ja fast wie bei Apple.
Es ist sehr interessant, dass das erste Sprachlanguage Arabisch ist.
Für eine Telefonbranche, die England...
Dann ist es wahrscheinlich die Target-Audience.
Irgendwelche Öl-Scheichs.
... als Teil ihres Namens.
Vielleicht verkaufen sie mehr in arabischen Ländern?
Dann kommt das Telefon selbst in sein eigenes, komplett separates, sehr faszinierendes Kompartment.
Das sieht so räudig schlecht aus.
Das sieht so mies aus, dieses Telefon.
Das ist wirklich...
Ja, es ist auch so klobig und ich kann es schlecht beschreiben, es vermittelt einfach einen richtig billigen Eindruck.
Das ist ein Anbieter, bei dem du in der Cloud extrem schnell LMMs nutzen kannst.
Ich will ja nichts in der Cloud nutzen.
Ich finde, das hat ein bisschen was von 3D-Druck hier unten, oder?
Findet ihr nicht auch?
Mit diesen Layern?
Aber mal ganz im Ernst.
Wenn ich mir die zwei Dinge...
Das iPhone sieht clean aus, ja?
Und irgendwie hochwertig.
Und das sieht overengineert, überkantitel, billig aus.
...
Das ist wahrscheinlich irgendein uraltes outdatedes Android drauf.
Natürlich, sicherlich, sicherlich alles offiziell licensed.
Hermes, das hat nichts mit unserem Versanddienstleister zu tun.
Ich brauche einen Quelle-Skin. Gibt es das überhaupt noch?
Das hört man jetzt schlecht, aber es hört sich ein bisschen übersteuert an.
ist nicht sehr hoch in Resolution.
Also alle diese supposierten Luxus-Wachfäden
sind nur...
Es fühlt sich auch laggy an, wenn er das scrollt.
... ein bisschen lecker
und nicht so überzeugend wie...
Ja, ja.
... echte Wachfäden.
Und der Kron ist nicht sehr konsistent
beim Scrollen.
Und es gibt viele Apps, wo der Text nicht richtig formattiert ist.
Es wirkt halt wie ein billiges AliExpress-Ding.
Ich bin nicht lustig, aber wo ist der Zeitpunkt?
Or just the fact that this flip phone, intricately hand-assembled as it may be,
with extra fancy cover-screen-customization befitting...
Es leckt! Es leckt! Seht ihr, dass es ruckelt beim Scrollen?
...price has a hinge that makes a concerning amount of noise when you open and close it.
Let's see what Arthur has cooked up.
Wait, what?
They've actually found a hotel room that has the London Eye perfectly framed in the middle of the window to...
Ist das ein AI-generated Bild?
...fulfill the entire view.
Es ist so perfekt, dass es mich fast so macht, als ob sie es AI-generiert haben.
Ja, das ist auch ein guter Satz.
Sie sagen mir, ich kann diese Wohnung jetzt booken.
Es ist ein Exekutivstudio, zwei Nächte, 580 Pounds.
Ich bin eigentlich interessiert, aber diese 580 Pounds, ist das das gleiche, weniger oder mehr, als was ich bezahlen würde, wenn ich es mir selbst booken würde?
Oh, das ist die Wohnung.
Also ist es real, aber das ist 409 Pounds.
Per Nacht.
Was bedeutet, dass es mich 818 Pounds kostet, um ein Buch zu booken.
Was ist das?
Auf dem Website.
Vielleicht benutzen sie einen anderen Website, wie booking.com.
And then because this is the Opera Browser, our sponsor, I can just drag one tab into another to instantly split screen them.
Executive Studio City View.
Wait, so they charge exactly 818 pounds too.
Book, please.
Booking name Richard Astley.
Send.
And now they want me to pay them on their PayPal account.
Okay, das klingt ja hart nach Scam.
Irgendein random PayPal Account, was hinüberweisen.
Das, das, das.
Das... weiß nicht.
Das hört sich schon hart nach Scam an.
Das sind auch AI-generated Avatar-Bilder hier.
So you've got six different people that you can chat to.
There's Arthur, Fiona, Samuel, Eleanor, Clara and then Amber.
These aren't real. Those are AI-generated images.
Can we expand to see more?
Oh, oh my god, yeah.
Das ist sowas von AI-generated.
That cannot be.
Und die Likes und Zeug, das ist 100 pro Fake. Das ist einfach hardcoded da drin.
A real person. I mean, whose room looks like this?
Das ist was AI sagen würde.
Okay, das hat funktioniert.
Die haben wirklich was gebucht für ihn.
Okay, das ist tatsächlich, ich hätte jetzt gedacht, das ist kompletter Scam.
Ich war im Prozess, ein anderes Hotel zu booken, mit einem der anderen Vertu-Hotels.
Der Konzern hat einen empfohlen und wir sind auf dem Punkt gekommen, wo alle Details
in einem beschlossenen Text für mich zu bestätigen wurden.
Okay, gut.
Aber dann, ungewissermaßen, kamen sie mir mit einer Fotoschicht zurück,
der Raum, in dem ich booken wollte.
Und sie haben mir gesagt, es nicht zu booken,
weil es eine Bunkerbett-Situation wäre, die sich nicht bewegen würde.
Das fühlt sich besser an als jede AI, mit der ich interagiere.
Aber das ist das Wahre.
Sie haben dann ein anderes Hotel empfohlen, das sie gesagt haben,
Das ist teuer.
Okay.
Ja, also doch AliExpress-Kram.
Da sitzt jetzt irgendeiner in irgendeinem Container und bearbeitet Chatnachrichten.
Das ist bestimmt auch AI-generated, die Website.
Hören wir mal aus bei dir.
Das ist alles AI-generiert.
Noch nicht mal AI. Billig photoshoppt.
Das ist AI. Das ist AI-generated.
Aber das Telefon kostet einfach mal 5000 Euro.
Die zoomen einfach nur das gleiche Foto.
Und das haben sie per AI generiert.
Das ist ein Stockfoto.
Was für ein Ding?
Was für ein Ding?
Ja, also,
mal gucken, ich meine, es deutet
jetzt ja wirklich alles auf irgendeinen AliExpress
China-Chinesen
Billighersteller
irgendwo hin, ja, der sich gedacht hat,
wir nehmen die Dinger und verkaufen sie einfach
Ich habe mal 5.000 Euro.
Folds in Handholds Universe.
It's really making me feel like this is not as big of a team as the company wants you to believe.
The customer service number, plus 86, that's China.
And then the head office is in Hong Kong.
The only other thing I'm wondering is there's a personal concierge phone number on the phone.
That's the same as the customer service number.
Also China.
China.
It started to make sense why they paid the hotel in Yuan.
Habt ihr gesehen, dass...
Irgendwie...
Guck mal, diese Nummern passen hier gar nicht richtig drauf, ne?
Aber dann hat Nokia sie verkauft.
Vertu wurde verkauft zu einem schwedischen Privat-Equity-Gruppe,
dann verkauft zu Hongkong-basierten Golden Holdings im Jahr 2015,
dann verkauft zu einem türkischen Geschäftsführer im Jahr 2017,
nur um dann der Firma dann zu einigen ziemlich ernsthaften finanziellen Problemen.
Ich habe hier einen Bericht von Telegraph, der sagt,
dass Vertu im Jahr 2017 ein Erkundungs-Defizit von 128 Millionen Euro hatte.
Das hat alle ihrer 200 UK-Mitarbeiter ausgelöst,
und dann die Verkaufs- und dann später das Zerstören dieser UK-Faktorie.
Nein, das ist kein Witz.
Wir sind hier.
Ich stehe im gleichen Spot wie damals.
Und es ist ein Aldi.
Ich werde hier auf dem Limmel rausgehen und sagen, dass sie dort nicht Vertu-Konten verkaufen.
Alle dachten also, dass diese Firma für immer tot war.
Nur, dass sie dann ein Jahr später 2018 wieder auf dem Markt kam.
Gleicher Brand, aber im Hintergrund eine neue Firma.
Mit einem anderen Direktor, einem anderen Set von Konto.
Hong Kong-slash-China-based operations, as opposed to this lovely...
Da lag ich doch mit AliExpress gar nicht so weit daneben.
...establishment in Church Crookham in the middle of England.
And also clearly a brand new strategy for social media.
You know, the only way I even realized Virtu was back
is because this TikTok popped up completely unprompted on my feed.
Three people who have Virtu-Phones, it's one person who has an iPhone,
and then they just throw the iPhone away.
Die Dinger sehen so billig aus.
Ich kann mir da nicht helfen.
Das sieht irgendwie so,
so als hätte ich das hier irgendwie zusammengeklebt,
sieht das aus.
Great burn, bro.
This video has over 170 million views.
Was?
There's another one over here.
Das ist doch auch fake views, sir.
6 million views.
It's just an unboxing of their phone.
Aber dann scheint es nicht etwas seltsam, dass es eine überluxuriöse Marke ist, die nicht veröffentlicht ist, und die sehr klare Grammatikerrungen in der Biografie hat.
Sie sehen nicht, wann ein Komma und wann Kapitalwörter benutzt werden.
Und das Fakt, dass sie Emojis benutzen, um euch zu beweisen, wo sie für besondere Offen kommen, kommt across wie die Art von Firma, die ihre Invoice in Comic Sans schreibt.
Sie haben hier einen Kamera-Test.
Wenn du dir vorstellst, dass dein 1.000 Dollar iPhone ein Spielzeug neben Vertu aussieht.
Das ist ein leichter Test.
Okay, das gleiche Foto auf beide.
Oh, they were right about the toy thing. It's just not the iPhone.
My teeth blend together on the Vertu.
Now the phones do do some pretty interesting AI-Camera things.
Like you can pull up any image and use text to change things in that image.
And you can even convert an image into a video with seemingly no guardrails,
even when you're using it for human subjects too.
The other thing I noticed while messing around with the camera is that this app looks very familiar.
This is the Vertu-Camera app and this is the Chinese phone makers.
Guck mal, dieses Telefon hier, das sieht einfach um Längen besser aus als das Worldshooting.
all over these devices.
Virtu have tried to hide them.
Like if you download a device info app,
it will tell you that the manufacturer is Virtu.
But when you dig deep,
if you go into the legal documents
or you find the actual names of the processes
running in the background,
the evidence is there.
The good news is that there is no ZTE device
that exactly matches all the hardware specs
of any of these phones.
So what they haven't done
is just taken a ZTE phone
and stuck some leather on it.
The bad news is that what they've done
is also not that far off that.
Because this Virtu Quantum, for example,
when you look closely,
... startet sich das ZTE Nubia Flip 2 anzusehen.
Eine unglaubliche Menge.
Es hat den gleichen Kamera-Layout, es hat den gleichen Cover-Screen-Satz.
Und ja, dieser Vertu hat einen viel stärkeren Snapdragon-Chip als der Mediatek-Chip in der Nubia.
Dann war ich nur mal interessiert, also habe ich mich in die Geräte eingeladen.
Ich habe Info über das und 4.325 Millionen Power-Batterie auf diesem Vertu.
Das ist so ein spezifischer, uniker Nummer.
Und es ist auch genau das, was ZTE auf ihrem Flip 2 hat.
Also, das ist nicht genau ein, lass uns ein ZTE nehmen und ein Vertu-Logo auf dem Topf stecken,
sondern es ist ein, lass uns alle möglichen ZTE-Parten schauen und diejenigen wählen, die wir für den Vertu wollen.
Was letztendlich ein sehr seltsames Set von Produkten macht.
Du bezahlst fünfmal den Preis eines Top-End-Flagships für eine Telefon-Erfahrung, die ungefähr eine halbe der Erfahrung wert ist,
eine Website-Erfahrung, die, sagen wir mal, negative Punkte wert ist,
aber dann ein Concierge-Service, das eigentlich ziemlich interessant ist.
das Ding,
beim ersten Blick sah das wirklich aus
wie, als hätte ich das daheim zusammengebastelt.
Oh, was war das?
10 Gigabit?
Und, äh,
wie heißt
das nochmal? Spiel und Haus?
Und Haus? Ne, Spiel und Zeug.
Spiel und Zeug.
10 Gigabit
in meinem 60 Jahre alten
haus endlich der zeitzeiten was wir hier ein netzwerk technisch gemacht haben zehn gigabit
netzwerk access points außen access points für kaninchen autos und uns im garten und bevor wir
damit so richtig loslegen können muss ich erst mal diesen sand kochen ich befinde mich hier ja
im winter des fertigwerdens und es gibt noch ein paar dinge netzwerk technischer natur die
passieren müssen und die werde ich jetzt unter dem vorwand dass es für dieses video absolut
notwendig ist. 10 Gig.
Oh.
Wenn man jetzt was baut,
das ist, denke ich, durchaus sinnig.
Zumindest mal die Kabel
dafür zu haben, die das supporten.
Machen. Ich erhitze diesen Sand, weil ich
gerade versuche PVC-Röhren zu biegen. Bisher
mit verhaltenem Erfolg.
Kommt mal mit.
Wir haben hier im Keller ja die offenen Betondecken
und wir haben im Studio auch schon das
Schienensystem für die Beleuchtung montiert.
Was hier an der Decke noch fehlt,
ist der Access Point, der hier noch so lieblos rumbaut.
Unify!
Das bedeutet auch, dass wir kein gutes WLAN im Keller haben.
Vor allem, wenn er...
Habe ich bei mir abgeschafft wieder.
Habe ich ja schon ein paar Mal erzählt.
Auch kein Unify mehr.
... so hängt, dass er einfach die Wand anstrahlt.
Darum gibt es hier die Kellertreppe des Verbindungsabbruchs,
wo ich jedes Mal, wenn ich telefonierend durchs Haus laufe...
Gut, die Verbindung verliere.
Das überrascht jetzt nicht irgendjemanden.
Aber bevor wir über Access Points und Netzwerkgeräte,
mein NAS und die Kameras sprechen, die wir hier verbaut haben,
Erstmal die wichtige Frage.
Unify kommt aus dem professionelleren Bereich
oder Semi-Profi-Bereich,
je nachdem von wo man guckt.
Und bereitet sich immer mehr in den Switch
oder den Access Point und nicht alles.
Ich wollte mir das ja schon länger mal anschauen.
Als Datei-Backups.
Gerade gestern ist xCloud Cube gestartet.
Kubernetes meines Maß und die Unterstützung
dieses Videos.
Welche Alternative?
Ich habe Ruckus,
oder wie auch immer man die ausspricht,
Access Points, gebrauchte von
Ebay habe ich mir gekauft, weil diese Dinger
sind neu, viel zu teuer.
Die hatten aber ein paar Features
damals. Mittlerweile hat Unify
ein bisschen nachgezogen in der Richtung.
Die Unify nicht hatte.
Deswegen habe ich mir die damals
geholt. Mittlerweile
denke ich, wird man mit Unify auch
wieder ganz gut hinkommen.
Also mir ging es hauptsächlich
um das Feature, dass ich pro Gerät
ein eigenes WLAN-Passwort vergeben kann.
Das konnte Unify
ganz lange nicht. Viele andere Produkte können es
mittlerweile. Unify war eines der letzten
ein bisschen teureren
Hersteller, die das eingebaut haben.
Und das ist halt enorm praktisch, wenn du viele
IoT-Geräte hast, kriegt jedes
IoT-Gerät ein eigenes WLAN-Passwort
und wenn du das Gerät
wegschmeißt, dann löscht es
einfach aus deiner
Gerätedatenbank und dann kann niemand
mehr was damit anfangen.
Wir haben hier aktuell ein Glas
faseranschluss mit einem gigabit down und 500 mbit ab ordentlich wegen jahrelanger
katastrophaler infrastrukturpolitik alles was uns hier zur verfügung steht danke
helmut kuh aber das ist doch ordentlich gigabit
internet der cdu an dieser stelle juni hat aber auch gerade noch schöne 5g
geräte angekündigt mit dem einen sein netzwerk darüber ins internet bringen
kann oder ausfallsicherer oder schneller macht doch so was geht das nennt sich bei
Jetzt muss erstmal wieder alles in RAM geladen werden.
Jetzt sende ich DPSK zum Beispiel.
Wifi.
Was war das andere jetzt hier?
Deutsches Polizeisportkuratorium.
Ah ja.
Dynamic Pre-Shared Key.
Das gibt es auch noch unter MPSK.
Die Hersteller nennen das alles ein bisschen unterschiedlich.
Aber das kann Unifile mittlerweile auch.
Das ist auf jeden Fall ein Thema fürs Frühjahr,
sobald ich eine von den Kisten in die Finger bekomme.
Also abonnieren, wenn ihr bei dieser aufregenden Netzwerkreise
dabei sein wollt. Jetzt habe ich ja völlig den
Netzwerkgeschwindigkeitstest verpennt.
Wichtig bei dem Folgenden ist, im Kopf zu behalten,
dass das hier nicht
normal ist für ein Einfamilienhaus.
Die wenigsten brauchen zu Hause
10 Gigabit Ethernet.
Manch einer würde mir unterstellen,
dass ich... Naja, also wie gesagt, zumindest
die Kabel dafür, die legen
wieder Support, ist nicht verkehrt. Haben wir auch.
Aber ansonsten
habe ich hier bei mir, habe ich 10 Gig,
aber im restlichen Haus
die access points beispielsweise auch nur mit eigentlich angebunden warum solltest da mehr sein
ja es auch nicht brauchen aber gut über die dream machine se haben wir eben schon kurz gesprochen
darauf läuft die juni ist die fallzeug mich ehrlich gesagt jetzt nicht so sehr für es
das ganze ins internet bringt und meine beiden switches und weil es noch nicht viele bezahlbare
zehn gigabit switches gab als ich das hier gebaut habe stecken auch zum beispiel mein rechner und
die aufnahme sachen im studio direkt hier dran genauso mein lieblings switch der 48 port also
also mikrotik hat ein paar ganz gute 10 gig switch es gibt auch mittlerweile noch ein
paar günstigere ich habe seit jahren habe ich einen es 16 g
es 16 xp oder irgendwie so heißt das ding
genau den switch das ist kein unified switch
ein switch
sehen habe ich schon jahrelang der hat damals
What the fuck? Das Ding ist ja teurer geworden.
Ich habe damals, keine Ahnung, 450 oder sowas Euro für bezahlt.
Ja, guck mal, der ist teurer geworden.
Geil.
Ah, was ist denn hier so? Keine Ahnung.
Wann ich den gekauft habe. Hier so wahrscheinlich dann irgendwann.
Guck mal, der ist teurer geworden.
Der ist nice, der hat 4 Kupfer, 10 Gig-Ports und 12 SFP-Plus-Ports.
Nein, sie nenne ich nicht wirklich Glasfaser, ich muss sagen SFP-Plus-Ports.
Das geht auch mit Kupferkabeln.
Du brauchst halt nur SFP-Plus-Stecker.
Da kann man auch SFP-Plus-Direct-Attach-Kabel nehmen für ein paar Meter.
Der ist eigentlich ganz gut.
Max, hier auf den zwei Patch-
Okay, das Video, komm mal und spalt es mit zu viel Unify.
Zu viel Unify-Stells, juckt mich nicht.
Ah, Moment, wo wir gerade bei ihm sind,
gibt es wieder ein neues Video.
Eure Heimautomatisierung.
Eure übertriebenen Smart Homes.
Ja, das sind immer gute.
Witz.
Das ist schon gut?
Du kleiner Fuchs.
Es ist wieder soweit.
Wir schauen uns an, was ihr bei euch zu Hause alles smart gemacht habt.
Holen uns Inspiration, Unterhaltung.
Das ist doch 3D gedruckt teilweise, oder?
Was ihr bei euch zu Hause alles smart gemacht habt.
Holen uns Inspiration, Unterhaltung.
Die Dinger.
Die sind bestimmt 3D gedruckt.
Ja, ja.
Oder?
Kennt man nicht so richtig.
Aber ich denke schon.
Vielleicht ein bisschen Kopf schütteln.
Menschen, Tiere, Automation.
Los geht's.
Retro.
Moment, der ist wirklich, ich habe gedacht, das wäre so ein Ding,
das wäre ein modernes Telefon, einfach nur auf Oldschool gemacht.
Das ist wirklich ein Alter.
Das, was Kevin hier gemacht hat, scheint weiter zu gehen,
als diese Demo, die Home Assistant auch mal gezeigt hat,
wo man einfach anrufen kann, weil er verschiedene Nummern wählen kann.
ist aber erstmal von der 0 bis 9 gelassen der gabelkontakt startet automatisch den
sprachassistent und über die wählscheibe kann ich jetzt mit automatisierung beliebige also
der benutzt quasi das telefon als der art schalterersatz eigentlich eine coole idee
den lieblings radiosender auf dem smart speaker eine coole idee rechte verletzung oder natürlich
einfach dem assistant eine frage stellen oder auch x-beliebige lese licht
einschalten kommentare gerne wiedergeben ich hoffe das projekt eigentlich eine
coole idee habe ich dafür einen github beitrag das ist schon cool also vor
allem weil dein altes siemens telefon hier oben drauf und noch einigermaßen
dekorativ dasteht und ich mag unauffälligen und unaufdringlichen
smart oben kam und das ist sicher ein ganz cooles projekt kevin's gitter projekt und alle weiteren
links findet ihr wie immer diese alten telefone überhaupt so normalen the stecker wie schließt
man die überhaupt an automatik mit einer siemens sps umgesetzt und ich möchte euch zeigen das ist
für mich auch so leise nicht wundern was passiert wenn bei mir ein rauchmelder auslöst
bp bp licht an backofen geht aus rollläden fahren hoch als jemand der gerade endlich den
großteil der fehlenden rauchmelder installiert hat muss ich mir das auch mal alles also meine
rauchmelder sind auch teil teilweise smart ja das sind wireless wireless rauchmelder falls
man die so nennen kann, die haben so ein Funkmodul
drinne und ich hab bei mir
im Serverraum,
wo auch der Home Assistant und so läuft,
hab ich ein Funkmodul
Empfänger vom Hersteller,
da schaltet ein Relay drinne,
wenn
das erkennt, dass Rauchmelder
ausgelöst haben. Die Rauchmelder sind auch
miteinander verbunden, das heißt, wenn es unten,
wenn ich hier gerade
vom Rechner sitze, Tür zu habe, Kopfhörer auf habe,
es geht unten der Rauchmelder an, dann geht meiner auch nach
kurzer Zeit an, die sind vernetzt miteinander
Ja. Und das Relay schaltet dann. Und daran ist, ich glaube, ein ESP2866 noch. Der erkennt das, wenn das schaltet und schickt es dann per MQTT an Home Assistant. Also ich kriege dann sogar eine Nachricht aufs Handy, wenn der Feuermelder ausgelöst hat.
Smart Home kann ja im Zweifelsfall auch wirklich wichtig werden, weil ja immer wieder Leute fragen, ja, aber was kostet Smart Home denn? Dann könnt ihr in Zukunft sagen, kein Smart Home kann in Zukunft das Leben kosten. Und ich notiere mir kurz, dass ich das auch einrichten muss, denn im Moment verbinde ich ja, zumindest was das angeht, das Schlechteste von beiden Seiten. Die Kosten von smarten Rauchmeldern mit der fehlenden Funktion von jemandem, der in einem dummen Haus lebt.
Ja moin, wir haben leider das Problem, dass unser Bad in der Wohnung nach innen liegt.
Normalerweise kommen ja Lüftungsanlagen zum Einsatz, hier wurde sich aber damals anscheinend beim Bau für ein Fenster entschieden, das in der Lüftungsschacht zeigt.
Problem daran ist, dass die Abluft und natürlich die daran haltenden Gerüche anderer Parteien hier im Haus denselben Schacht nutzen.
Das heißt, wenn unter dir einer am kacken ist, dann kriegst du das mit.
Ah gut.
Das ist dann vielleicht nicht so dolle.
Man kann das Fenster zum Lüften natürlich immer wieder auf und zu machen, aber das ist ja langweilig und man muss nach dem Duschen immer wieder dran denken.
Kommerzielle Lüftungsanlagen waren quasi allesamt entweder zu laut, zu teuer, zu groß oder nicht sinnvoll regelbar oder eine Kombination aus allem.
Daher hier der Eigenbau mit ESP32 und PC-Lüftern.
Das ist next level hier.
Das Ganze sitzt in einem 3D-gedruckten Rahmen, welcher in die Abkastung hier eingesetzt ist, die ich aus MDF-Platten gefuscht habe.
Wenn die Lüfter auf sind, verschließen Servo die beiden Lüfter mit Hilfe dieser Finn hier, um ungewollte Gerüche rauszuhalten.
Aha.
Wenn die Lüfter angehen, werden diese rotiert und geben den Luftschirm frei.
Das Ganze steuert ein ESP32 mit ESP Home und die Lüfter werden mit PWM angesteuert.
Da hat es sich aber richtig Mühe gegeben, sogar mit dem Case und sowas.
...leistung einfach variiert werden kann.
Dadurch werden die Lüfter übrigens auch ausgeschaltet
Man muss aber beim Kauf darauf achten, dass die Lüfter das auch können
Hier sieht man den Pupsknopf
Damit lässt sich der Lüfter einfach 5 Minuten
auf Vollgas laufen
Hihi, Vollgas
Temperatur und Feuchtigkeit
und zuletzt der Präsenzmelder
Wenn mehr als 3 Minuten jemand im Bad war
wird, sobald die Person nicht mehr erkannt wird
für einen kurzen Zeitraum mit geringer
Leistung nachgelüftet
Oh, gute Idee
Das mache ich auch
Wir haben ja oben, also wir haben ja auch eine Lüftungsanlage und wir haben im Prinzip auch einen Pupsknopf im Bad.
Und ich habe mir schon überlegt, wie ich das automatisieren kann, wie ich unterscheiden kann, welches Geschäft gerade wohl passiert ist.
Und offenbar sind drei Minuten die magische Grenze. Ich schreibe einfach die Hausaufgaben ab.
Das heißt, wer länger sitzt, hat gekackt.
aber an die Luftfeuchtigkeit gekoppelt. Dafür liegt im Flur auch ein Temperatur- und Luftfeuchtigkeitssensor, womit eine Differenz errechnet wird.
Die Lüftungsanlage wird dann abhängig von der Differenz eingeschaltet. Ist die Differenz klein, auf geringer Leistung ist die Differenz groß, zum Beispiel nach dem Duschen geht es richtig ab.
Mit theoretisch 276 Kubikmetern pro Stunde Luftstrom von beiden Lüftern zusammen wird der kleine Raum auch ganz gut durchströmt.
Zuletzt kann man das natürlich auch über Home Assistant steuern und wenn man mal baden will, die Lüftungsautomatik auch ganz einfach ausschalten.
Wer mehr Details dazu haben will, ich habe das alles mal in GitHub eingepackt.
Sehr schön. Auch immer wieder beeindruckend zu sehen, was ihr so baut.
Und warum nicht das Beste aus dem Stinke-Schornstein machen.
Das Gehäuse und die Steuerung, die dann nur reinpustet.
Nur, was hast du gesagt? 270 Kubikmeter Umwälzung die Stunde?
Ich habe keine Ahnung, ob das viel, wenig oder was auch immer ist.
Du musst dir aufpassen, dass du dir keinen Vakuum in die Bude saugst.
Aber sehr schön. Wohlverdiente 50 Euro für diese Einsendung.
Wenn ihr auch eine schöne und zeigenswerte Smart Home Automation habt, dann schickt sie mir gerne unter zeug.cool.de und jede gezeigte Automation bekommt einen 50 Euro Amazon Gutschein.
Damit ich das machen kann und damit deine nächste Einsendung auch filmreif wird, bietet Insta360 die Flow 2.
Danke Insta360 für die Unterstützung dieses Videos und der Belohnung für eure Einsendung.
Und jetzt sehe ich hier mich.
Ja, ist inspiriert von einem Video bezüglich des Huckensohns, der bei dir einbrechen wollte. Will ich mal zeigen, wie ich das Ganze zumindest ein Stück weit bei mir realisiert habe. Hintergrund ist, ich wollte im Endeffekt einen Trigger haben, ob ich gerade zu Hause bin oder nicht. Und da gibt es ja verschiedene Möglichkeiten.
Also das Zuverlässigste bei mir ist tatsächlich das Smartphone Positionsbestimmung zu Hause oder nicht zu Hause.
einen solchen Trigger der Anwesenheit setzen könnte.
Weil ich habe immer mein Handy dabei.
Ich glaube, die Homeoffice Companion App kann das von sich aus.
Oder man könnte es zum Beispiel über den Verbindungsstatus des Handys machen.
Aber ich wollte das Ganze so realisieren,
dass wenn ich mal die Wohnung verlassen sollte und trotzdem noch wer da ist,
weil ich alleine lebe und zum Beispiel Getränke hole oder so,
dass dann nicht trotzdem alles direkt ausgeschaltet wird.
Wie wir hier sehen, ich habe unter meinen Start hin eine Anzeige.
Entweder ich bin anwesend oder ich bin nicht anwesend.
beziehungsweise ist überhaupt irgendwie anwesend.
Das Ganze ist realisiert als ein Helfer.
Das Ganze ist eine Google-Eingabe.
Das heißt binär, entweder jemand ist da oder jemand ist nicht da.
Wie man hier sieht, ich bin schon ein bisschen länger da
und habe gestern das Haus nicht verlassen.
Das Ganze wird getriggert von Automationen.
So muss es sein.
Diese Automationen sind im Endeffekt...
Und was genau hat er jetzt eigentlich gebaut?
Bewegungsmelder, da habe ich zwei Typen im Einsatz.
einmal relativ stupide Tuya Bewegungsmelder oder auch von Tuya diese Präsenzmelder,
die mit im Millimeterbereich erkennen, ob jemand da ist oder nicht.
Millimeter?
Die haben wir in den Einzelmann verbaut und was passiert?
Sie melden eigentlich ständig auf diesen Trigger.
Das machen hier alle Trigger.
Okay, die Automatisierung interessiert mich nicht.
Da muss man so ein bisschen feintunen aufs eigene Haus und auf die eigenen Anforderungen, auf die eigenen Lebensumstände.
Das ist Oxel, mein E-Bike. Ich nutze es praktisch täglich und möchte gerne, dass es automatisch...
Ach, Axel oder ein kleiner Ochs?
Ich habe Ochser verstanden!
... Strom am günstigsten ist. Das ist mit Home Assistant und einer Shelly-Steckdose ja problemlos möglich.
So, was machst du? Also du lädst, wenn der Strom günstig ist, okay.
Was sicher bekannt ist, mögen es Lithium-Ionen-Akkus nicht, wenn sie immer voll geladen werden.
Autos haben dafür ein einstellbares Ladelimit, aber bei E-Bikes ist das leider noch nicht verbreitet.
Das ist korrekt.
Wegen des üblichen CC-CV-Verhaltens.
Ach, by the way, wo wir gerade beim Thema E-Bike sind, hat nicht was direkt damit zu tun.
Ich habe mir jetzt einen Elektro-Scooter gekauft.
Jetzt muss ich nur noch eine Versicherung abschließen und muss mir so ein komisches Kennzeichen holen.
für Strecken, wo ich mal keinen Bock habe,
zu laufen oder zu rennen oder im Auto zu fahren.
Der flutscht. Ich bin damit schon ein paar Runden im Hof
gefahren, weil auf öffentlichen Straßen
darf ich ja ohne Versicherung
geschillt und so nicht fahren.
Das Ding geht ordentlich
ab. Das Ladegerät
steigt die Ladeleistung stetig an,
bis sie bei etwa 80% Ladezustand
wieder zu sehen ist.
Tuning geplant.
Da wird nichts getunt.
sensor in home assistant diesen moment erkennen und die steckdose abschalten an der das ladegerät
angeschlossen ist ich hätte kleiner fuchs somit wird der akku wie gewünscht als mir gekauft habe
von segue ein nein bot heißen die dinger glaube ich moment nein bot f2 pro oder so hieß das ding
habe ich mir gekauft
bei Amazon.
Guck mal hier vielleicht.
Ja, guck, bei Amazon gibt es den gerade
günstiger.
Das ist irgendwie
200, 300 Euro billiger als sonst.
Deswegen habe ich dazu geschlagen.
389 Euro anstelle
500 oder noch was.
achtschmeer das ist nicht verkehrt
etwa 80 prozent geladen naja teuer
ist halt alles kostet alles geld für die für das ding ist der preis ganz gut gewesen wie
sorge ich dafür dass der ladevorgang nicht wieder beginnt sobald der strom das nächste
mal wieder günstig ist, falls das Fahrrad inzwischen nicht gefahren wurde. Ich musste
also einen Weg finden, um zuverlässig festzustellen, wann das Fahrrad den Raum verlässt und somit
beim nächsten Mal wieder geladen werden kann. Sobald also der Ladevorgang bei etwa 80% Ladezustand
beendet wird, wird eine Bullshear-Eingabe in Home Assistant aktiviert, die ab sofort
das Einschalten der Steckdose blockiert und man erhält eine entsprechende Notifikation.
Und sobald das Fahrrad rausnimmt, dann?
Dann nutze ich einen ESP32 mit ESP Home als BLE-Tracker und zwei BLE-Beacons aus Redundanzgründen, die ich am Fahrrad-Sattel befestigt habe.
Diese Geräte senden alle paar Sekunden ein Signal, das der ESP empfangen kann.
Bis die Batterie leer ist.
Und der ESP beide BLE-Beacons für mehr als 30 Minuten nicht gesehen hat.
Ja gut, ich schaue nicht weiter.
Sehr schön, danke sehr.
Die nächtliche Suche nach der Fernbedienung war mir irgendwann zu blöd, weil die meistens in irgendein Ritzelfeld sind, wo ich sie in der Nacht nicht wiederfinde.
Nein, das ist mir zu blöd.
Für was braucht er überhaupt eine Fernbedienung?
Für Licht und sowas. Und warum braucht er die nachts?
Ich habe gedacht, ich schalte das Nachtlicht einfach mit zwei Bewegungssensoren.
Den einen habe ich hier am Fußende angebracht und den anderen eben am Kopfende.
Das Licht geht an, das ist sehr gut. Also eigentlich stehe ich auf und das Licht geht an.
Ja, der erkennt den Fuß.
Und wenn ich mich dann hinlege, muss ich bloß eine Hand raushalten und das Licht geht wieder aus.
Und was ist, wenn er aus Versehen da irgendwie nachts sich mal falsch bewegt?
Rechtliche Suche nach der Verbindung erspart.
Licht geht an.
Wenn er sich mal nachts falsch rumdreht?
Auch eine Handbewegung, die in Deutschland immer üblicher wird.
Und konfiguriert wird das Ganze in der App All4Who.
Das Problem an der Sache ist nämlich, dass die Philips Hue eigene App den Befehl Lampen ausschalten nicht kennt.
Was? Moment. Moment. Jetzt soll bei Bewegung... Du hast recht.
Man kann nichts machen. Man kann auch den letzten Einschaltstatus, aber man kann nicht gesichert ausschalten.
Neue Regel. Die erste Bedingung ist der Bewegungssensor.
Also die Basic-Sachen wie Licht ausschalten geht nicht? Was? Hier? Hä? Wie? Was? Wo?
Er soll eine Bewegung erkennen. Ich habe jetzt mal eine Zeitspanne eingegeben, wo dann der Sensor reagieren soll, weil tagsüber soll er nicht reagieren, damit er meine anderen Lampen nicht durcheinander bringt.
Finde ich auf jeden Fall einen interessanten Ansatz. Also du darfst natürlich nicht zu expressiv schlafen und je nachdem, da sind wir wieder bei der Frage, mit wie vielen Leuten du zusammenlebst. Wenn du alle Lampen ausmachst, kann das auch ein Problem sein. Aber im Zweifel lässt sich das ja auch irgendwie anders lösen. Also man könnte das Ding auch irgendwo hinhängen, wo man den Arm dann einmal aus dem Bett drunter halten muss oder so.
nette kleine idee und ich habe gelernt was die uapp noch nicht kann ich lerne auch jedes mal
noch mehr denn einige wir schauen mal rein was axel gebaut hat an rät heute möchte meine
automatisierung zeigen ich bin ganz ohr und aus displays finde ich nice die räder hat die
displays finde ich nice was hat er da am start mit glas hat auf drei ebenen ich bin ganz ohr
Was sehe ich hier? Wie gesagt, der MBT-Glas hat auf drei Ebenen Informationen, kann er darstellen.
Hier oben ganz einfach die aktuelle Uhrzeit. Hat er das selbst gebaut oder?
Was hat er da für Schalter?
Wie ist die Regenwahrscheinlichkeit oder ob ich in den nächsten Tagen den Müll rausbringen muss.
Du hast ihn einfach nur als quadratisches Display gekauft?
Wie ist der Zustand des Garagentors? Ich kann damit auch rauf und runter fahren.
Und wenn ich das starte, gibt es dann eine kleine Animation.
Die Garage ist auf.
Im Zustand des Briefkastens.
Aktuell sehen wir grün.
MDT-Glas-Taster.
Wenn ein Brief kommt, dann wird das erkannt über einen Sensor am Klappdeckel.
Und das bekomme ich dann auch.
Ja, das habe ich auch probiert.
Das hat nicht so gut funktioniert.
Ich kann jetzt von hier aus auch meinen Briefkasten öffnen, indem ich die Taste betätige.
Der springt auf.
Kein Briefkastenschlüssel. Das sehe ich in meiner Zukunft.
Aktuell ist die Tür zu. Wenn ich die Taste betätige, wird die Garagentür geöffnet über einen E-Öffner.
Was, die Garagentür? Ne, die Briefkastentür.
Tür auf ist.
Das ist das Display.
Zeig mal her.
Alter, die lassen sich das aber gut bezahlen.
Die lassen sich das aber ordentlich bezahlen.
140 Euro für einen Schalter.
Ob das so viel kann, außer schalten?
Weiß ja nicht.
frag mich wie die wie das der inhalt vom display gesteuert wird wie man das dann drauf kriegt
unten links befindet der status zu allen fenstern sobald ich ein fenster aufmache
das display wirkt jetzt auch ehrlich gesagt ein bisschen billig also das ist
nicht schön also die auflösung ist nicht hoch genug sind nicht anti elaste schrift und so
das sieht ja auf dem auf dem t display was ich hier habe besser aus
das kostet 8 euro gut er hat aber auch kein glas drumherum gut zu wissen wer natürlich
auch welches office in dem ich die taste drücken hier und rechts noch das letzte
feld zeigt man ob im haus noch irgendein nicht brennt automatisiert indem ich die
die Taste drücke, werden alle Lichter im Haus ausgemacht.
Das Thema habe ich auch noch vor.
Wir haben einen Gira-Tastsensor oben an der Eingangstür,
der zum Beispiel die gleiche Fensterautomation bietet.
Und so eine Hausverlassengeschichte ist einfach super.
Das hatten wir auch schon in der Liste.
Also ich habe beim Hausverlassen, das Einzige, was ich habe,
ist, es guckt, ob ich noch Fenster offen habe.
Und ansonsten...
Ah ja, nein, das stimmt nicht.
Es guckt, ob ich noch Fenster offen habe
und ob der Heizlüfter im Bad an ist.
Auch wenn ich den noch nie vergessen habe auszuschalten.
Letzte Wohnung, im letzten Haus hatten wir das zwischendurch,
dann aber nicht so richtig.
Aber irgendwie so eine Taste direkt am Haus- oder Wohnungsausgang zu haben,
wo man drauf drückt und sagt, ich bin jetzt der Letzte,
der geht, mach, dass das Haus
in einem passenden Zustand ist.
Das ist schon ganz gut.
Da muss ich auch noch...
Welche Fenstersensoren hast du?
Ich kann es dir nicht genau sagen. Also es sind
Z-Wave-Sensoren, aber ich weiß jetzt nicht mehr genau,
welche.
Das war eines der ersten Sachen,
die ich mir vor Jahren gekauft habe.
Das andere
ist mittlerweile fast alles ZigBee,
aber Fenstersensoren
sind Z-Wave.
ich kann es dir aber nicht mehr sagen, welche das waren
das ist auf jeden Fall was von AliExpress
gewesen, was ich mir bestellt habe
irgend so ein 15, 20er
Pack wahrscheinlich, waren das bei AliExpress
da hatten ein, ich weiß nicht, super
billig die einzelnen
ich glaube 11 Euro oder sowas
das Stück dann
und
ja
die habe ich seitdem im Einsatz
die Neo
Irgendwas mit Neo heißen die Dinger.
Mal.
C-Wave.
Window.
Neo.
Irgendwas mit Neo.
Hier.
Die.
Die habe ich.
Aber AliExpress.
AliExpress.
Neo CoolCam.
Neocool
Cam
Z-Wave
So ungefähr
sehen die aus, nur meine sehen noch ein bisschen
runder aus. Das ist wahrscheinlich eine ältere Version,
oder? Ja, so ungefähr.
So ungefähr sehen die Dinge aus.
Z-Wave
Door
Ja
Und
Also China-Chinesen-Kram ist ganz schön teuer geworden
Äh
Was
Ich verstehe nicht, was AliExpress mir hier gerade anzeigt
Der Kombi-Knaller
Alter, diese Seite macht mich fertig
Was wollt ihr von mir?
Also, die Dinge
habe ich, aber die waren damals,
gab es die in einem größeren Pack
und waren günstig.
Ah, ich habe die, Moment, Moment, Moment,
ich habe die nicht bei AliExpress gekauft.
Ich habe die bei Banggood gekauft.
Banggood.
Sieht übrigens fast genauso aus wie AliExpress.
Kommt alles vom chinesischen Ministerium für Webdesign.
Gibt es hier nicht mehr.
Vielleicht auch bei DH-Gate.
Anderer China-Shop, der auch aussieht wie AliExpress.
Sieht alles gleich aus.
Gibt es auch nicht mehr.
Ich glaube, ich habe die bei Banggood damals gekauft.
ich weiß nicht was es war ein 10er packen 20er pack aber auf jeden fall auch welche hier
wahrscheinlich ein 10er pack wahrscheinlich ein 10er pack und ich habe mir umgerechnet
könnten sogar weniger als 11 euro gekostet war damals relativ günstig
es gibt genug zu tun für so müll benachrichtigungen soll denn der led streifen
dahinter dienen wenn er mal da ist aber ich denke mal verstärkt darüber nach was ich mit den
restlichen wirken anstellen könnte damit ich die irgendwann auch mal gravieren lassen kann habt ihr
hauseingangs oder ausgangs automation schreibt die gern in die kommentare oder schickt sie unter
zeug punkt cool slash zeigen und dann sind die vielleicht beim nächsten mal dabei hallo zusammen
um mal wieder den tieren im titel dieses videos gerecht zu werden zeige ich euch mal kurz wie
wie ich hier ein Tabletten-Reminder-System für unseren Hund gebaut habe.
Sehr gut. Fast hätten wir keine Tiere in Menschentiere-Automationen gehabt.
Eine Maus hier braucht einmal am Tag ihre Tablette, und zwar immer abends.
Ab 18 Uhr prüft Home Assistant dann alle 30 Minuten, ob die Tablette schon gegeben wurde.
Wenn nicht, dann kommen Push-Benachrichtigungen.
Und das futtert er freiwillig. Ich weiß, ich musste Chico auch mal Tabletten geben.
Das war größere Akt.
auf alle Handys und Alexa sagt hier im Haus Bescheid, dass es Zeit ist für die Tablette.
Detti hat ihre Tablette noch nicht bekommen. So vergisst man es garantiert nicht. Sobald also
der NFC-Tag hier in der Tablettenbox gescannt wurde, wird ein Input-Boolean auf angeschaltet
und alle Geräte bekommen die Benachrichtigung. Ja, aber gefressen hat die die doch immer noch nicht.
Parallel läuft ein Zähler, der den Bestand der Tabletten mitzählt. Wenn dann also der
Mindestbestand erreicht ist, landet automatisch Nachschub auf der Einkaufsliste. Das Ganze läuft
einfach für uns komplett automatisch und sorgt dafür, dass unser Hund immer zuverlässig sein
Medikament bekommt und dass man groß drüber nachdenken muss. Achso, nochmal zum Preis des
MDT-Tasters. Du musst also relativ klassisch in der elektrischen Installation sehen,
wenn du mehrere herkömmliche Schaltstellen mit Wippen von namhaften Herstellern verwendest,
kommst du auch ähnlich, ja, kann schon sein, aber ich
finde es trotzdem krass. Also ich habe hier
so einen ZigBee-Schalter
mit sechs Knöpfen, also ziemlich vergleichbar
zu dem da.
Mit dem Unterschied, dass man bei dem
ZigBee-Schalter,
man kann Single-Press, Double-Press,
Triple-Press, Long-Press machen.
Kann sogar mehrere Funktionen quasi damit
belegen. Der fühlt sich sicherlich
nicht so hochwertig an wie so ein Class-Taster
mit Display, hat auch kein Display.
Hat aber nur ein Appel und ein Ei gekostet.
schon preislich wenn man einfach nur schalten will ordentlich 150 euro dafür wirkt es natürlich
auch deutlich hochwertiger als so billig sick wie plastik ding
aha nice
exzellent sozusagen ob es neue package updates gibt wir haben immerhin schon zwei stunden kein
updates mehr gemacht und jawohl helm fast fetch container de so muss es sein
jetzt mal ordentlich updaten ich halte es nicht aus wenn mein system
zwei stunden hinten dran ist das ist mir nicht plädierig genug
So, Leute, wisst ihr, was ich jetzt mache?
Ich geh jetzt was essen.
Ich hab übelst, übelst Hunger.
Täglich eine Herztablette für die Katz.
Also,
Katzen irgendwelche Medikamente geben,
ist immer anstrengend.
Bei Chico hat's am Ende so,
also Chico ist die hier unten da,
Das ist übrigens eine Sie,
auch wenn sie Chico heißt.
Ich habe mir den Namen nicht ausgedacht.
Da habe ich das immer in so
Schleckpaste.
Da gibt es so
Schleck.
Wie nennt man das so?
Leckerlis.
Da konnte man das reinmachen.
Da sind die ganz verrückt danach.
Nudeln mit Lachs? Nein, es gibt keine Nudeln mit Lachs.
Was ist denn das andere, was es geben könnte?
Ihr kennt mich doch.
Was haben wir zur Auswahl sonntags?
Nudeln mit Lachs oder Nudeln mit Bolognese?
Genau.
Ja, es gibt Nudeln mit Bolognese.
Nicht Nudeln mit Lachs.
Auch wenn ich jetzt echt Bock hätte,
mir so ein
Dönerpide zu holen
mit Dönerfleisch. Also ein Pide
mit Dönerfleisch. So rum. Aber ich muss
die Nudeln futtern. Will ich nicht länger stehen
lassen.
Ja, wie gesagt, Chico hat die Tabletten dann auch in Medikamente genommen, nachdem ich die in diese Schleckpaste reingemacht habe.
Da war die ganz scharf drauf.
Ich bin übrigens mittlerweile sehr beliebt bei allen Katzen auf meiner Laufrunde.
Ich habe jetzt nämlich immer noch so einen kleinen Leckerli-Stick oder zwei kleine Leckerli-Sticks dabei.
Und immer wenn ich Katzen über den Weg laufe, dann frage ich die, ob die nicht ein Stück von dem Leckerli-Stick haben wollen.
Und es gibt zwei Stück.
Wenn ich da vorbeilaufe und ein bisschen so Schwarzgeräusche mache, dass die halt hören, dann kommen die direkt angeflitzt.
Die sehe ich total oft. Eine schwarz-weiße und die schwarze.
Die schwarze habe ich schon mal auf.
Die schwarze habe ich schon mal auf Twitter gepostet, glaube ich.
Warte mal.
Hier.
Gigachat.
Gigachat-Katze.
Vom Gesicht her, oder?
Hat ein bisschen was Giga-Chat-mäßiges.
Und auch die Farbe.
Bist du auf Mastodon?
Nee, ich bin auf Twitter.
Das ist einfach nur ein alternatives Frontend für Twitter.
Wo man auch nicht eingeloggt noch ordentlich bedienen kann.
Mittlerweile ist ja Twitter komplett useless, wenn du nicht eingeloggt bist.
Die offizielle Twitter-Seite.
Und von der
Schwarz-Weißen habe ich noch kein Foto gepostet.
Die sehe ich aber auch öfters.
Ja, so sieht es aus.
Und jetzt gehe ich was essen, Leute.
Ich habe übelst Hunger.
Mal gucken, ob wir heute Mittag weiter
Raststream machen.
Muss man mal schauen.
Ich muss erst mal mein Handy anstöpseln.
Dass es mal wieder lädt.
Oh Leute, ihr glaubt es mir nicht, aber...
Ich habe 6, 7% Akku gerade auf meinem Handy.
Da würden die ganzen Zoomer...
Ne, Gen-Alphas...
sich jetzt freuen.
Ey, 69 ist out.
Das Gen-Alpha-Meme ist 6, 7.
Ich checke auch nicht, warum.
Ja, ich habe mir das historymäßig mal angeguckt, so von irgendwelchen Basketball-Memes oder so, aber ich verstehe es nicht.
Ich verstehe es nicht, was man daran so lustig finden kann.
Auf der anderen Seite muss ich sagen, 69 ist auch nicht wirklich jetzt so ein super lustiges Meme.
Die Gen-Alpha- und Beta-Generation, die, wobei gibt es Beta überhaupt schon, die finden halt 67 total lustig.
In ein paar Jahren sagen die dann immer noch 6-7 und finden es lustig und die nächste Generation kann damit nichts anfangen, so wie das immer ist.
Was heißt jetzt 6-7? Das ist ja das Dumme an diesem Meme, das heißt gar nichts.
Das heißt gar nichts, das sind einfach nur zwei Zahlen, die in Form von irgendwelchen komischen Baseball, TikTok, Basketball, keine Ahnung, TikTok-Memes aufgekommen ist.
Das heißt gar nichts
Das ist richtig dumm
Das ist richtig hängen geblieben
Na gut
So Leute, dann gehe ich jetzt was essen
Wir hören uns, bis denn, macht's gut
Wer noch nicht hat, kann mir auch gerne ein Follow dalassen
Freue ich mich immer
Bis dann, macht's gut, see you
