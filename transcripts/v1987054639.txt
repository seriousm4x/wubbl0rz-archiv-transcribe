mega pock exzellent wir müssen aufpassen und zwar ich habe hier das handy von der
arbeit liegen weil es kann sein dass ich angerufen werde bis montag früh 37 kann
das noch sein oder 7 uhr ich glaube 37 kann das noch sein weil ich habe ich
habe dieses wochenende wieder passives einkommen ist ja der neueste trend
überall 200k passives einkommen im monat der nur hier aber ich habe wirklich
passives einkommen wobei so passiv ist das gar nicht so passiv ist das gar
nicht ich wurde heute morgen angerufen und morgen wurde ich angerufen
wegen der das kann ja nicht so genau nicht sagen wegen wegen einem
umschreiblichen ist jetzt am besten so pass
worts und system was nicht funktioniert hat und irgendwie leute wollten
wartungsarbeiten am wochenende machen aber das ging nicht weil das aus
irgendwelchen gründen alle keine berechtigung mehr hatten und ich hatte
keine ahnung von dem system ich kann ja auch nicht alles kennen
die waren ich habe dann glücklicherweise den erreicht der plan von hat dann wird
es gefixt dns nein ein passwort singt was vorzügen
ob sie laut ja passwort sinkt aber ich habe das auf 20 prozent volume
herstellen oder was so leise so gut exzellent ist das excel es war kein dns
problem ja dass der spruch der ist schon seit ein paar jahren irgendwie outdated
overrated sie betet weiß nicht ob man ob man wirklich pauschal irgendwie sagen
kann was so
ist und
der ist investigating
die probleme sind aber die ns ist erstaunlich selbst in letzter zeit dabei
er ist stark deixa den spruch ich würde sagen eigentlich ist es eher eine
komplexität problemeaky zeit war es überall tausend sachen gibt und keiner
wirklich gegenüber política
über alles ist ja auch gar nicht mehr geht
oder ihr macht immer nur im Dezember?
Also, ihr fangt jetzt halt
neu an, was die Firma
sich jetzt ausgedacht hat. Ab Dezember geht's los.
Also, ihr habt das quasi dann auch das nächste
Jahr über. Ich muss mal kurz Update machen.
Hogu!
So, soll ich euch
nochmal sehr, sehr
nice Sachen sagen? Sehr
extremely nice.
Und zwar,
zwei Sachen.
Excellent, excellent.
Zwei Sachen. Das erste ist, ich hab jetzt
Moment, ich muss mal kurz meine Zeit ein bisschen
richten. So, muss besser.
Ich hab jetzt Urlaub.
Quasi
ab gestern
bis Januar.
Wobei
das noch nicht so ganz stimmt,
weil
streng genommen hab ich noch Bereitschaft bis Montag
und Dienstag und
Mittwoch haben wir nochmal
ein Teambuilding-Workshop
auf der Arbeit.
In irgendeinem Hotel hier in der Nähe.
Da wird dann zwei Tage
wahrscheinlich wieder ganz tolle
Spiele gemacht, auf die alle wahnsinnig
Bock haben. Ihr kennt sowas, ja?
Und dann
war's das aber für mich.
Das ist richtig weird, Champ.
Mal gucken, mal gucken. Ich werd mich
zunächst zwingen lassen, wenn ich
gar keinen Bock drauf hab.
Ich mein, das muss ja auch nicht so schlimm sein.
Aber meistens, wenn man sich denkt,
das muss ja nicht, dann ist es auch.
Dann ist es auch schön. Montag, Dienstag steht die Schimmel,
übrigens, nicht, was ich erzählt hab. Dienstag, Mittwoch
ist das ja. Aber gab es keine...
Achso, okay, ihr fangt jetzt
quasi direkt damit an.
So, warte mal, ich wollte euch
ja noch was erzählen. Achso, ja, und eine Sache, die ist
wahrscheinlich nicht so gut für... Doch, drei Sachen,
drei Sachen kann ich euch erzählen, ja?
Also, das Erste ist...
Das Erste hab ich ja schon erzählt. Urlaub jetzt
bis Januar.
Das Zweite ist, ab 2. Dezember
mach ich den Ultra-MMO-Kreisel-Crime
wieder.
Ihr kennt mich immer, wenn irgendwelche
privaten...
einfach rauskommen, muss ich irgendwie mal
ein paar Monate krassen MMO-Kreisel-Crime
machen.
Das Game spiel ich halt schon seit
20 Jahren. Und das muss
immer mal wieder so
einmal im Jahr oder so.
Und dann wieder für ein paar
Monate muss ich krassen
Kreisel-Crime machen.
Und das Zweite ist... Ach, nee, das Dritte.
Das Dritte ist,
Dezember mach ich wieder viele Videos.
Ich hab mir jetzt auch ein bisschen überlegt.
Ich mein, nachdem ich ja mit Gaming
in letzter Zeit wirklich gar nicht mehr so viel am Hut habe,
dass ich da zu groß was sagen könnte.
Ja, und ich weiß, dass, sagen wir mal,
viele Leute über das Gaming
zwar zum Channel gekommen sind, aber mittlerweile auch
sich für viele andere Sachen interessieren.
Deswegen hab ich mir gedacht, ich werd mal so ein paar
allgemeine Themen abarbeiten.
Also zum Beispiel muss ich euch endlich mal
meine Bewerbung zeigen. Die hab ich euch
ja schon seit einem Jahr oder so gesagt.
Ich zeig's euch mal. Hab ich ja noch nie gezeigt.
Dann könnt man sich mal über
so Sachen unterhalten, wie
ob Open Source wirklich sicherer ist.
Oder ob es auch kack Open Source Sachen gibt.
Dann könnte ich eine...
Hab ich mir überlegt, was auch
immer bei Videos recht beliebt ist, so Tierlists
zu erstellen. Ich wollte mal eine Linux
Distribution Tierlist machen. Das machen wir
wahrscheinlich im Stream zusammen.
Und dann frag ich den Tyler, ob er das
zusammenschneidet.
Ja, ich wollte mich mal so ein paar allgemeinen
Themen widmen, die
vielleicht nicht so sehr mit Gaming zusammenhängen
im Dezember. Was, du darfst
eine Schulung zu ISO? Was zum...
Wie viele von diesen Kackdingern gibt's dann
eigentlich? Okay, ISO
2, 1, 4, 3
2, 1, 4, 3, 4
Road Vehicle
Cyber Security Engineering. What?
Cyber Security...
Eine Norm zur Cyber Security
in Kraftfahrzeugen.
Was es nicht alles gibt, ey.
Was es nicht alles gibt, ey.
What the fuck?
Ja, beste, ne?
Leute,
ich bin mal gespannt. Ich bin mal gespannt.
Also, ich hab mir die letzten Monate,
heute über, so ein paar
Punkte aufgeschrieben, die ich
sehr sinnvoll fänden würde,
wenn man die mal diskutiert zum
Teambilden.
Zum Beispiel, was Komplexitätsreduzierung
angeht, oder
dass viele quasi nur vor sich hin basteln
und ihr eigenes Ding machen
und sowas. Man könnte
sicherlich die Zusammenarbeit, oder zum
Beispiel, dass während man eine Besprechung
hat und man mit Leuten redet,
die nicht halt mit dem Kopf
AFK sind und was anderes machen. Was ich ja auch
teilweise, was ich auch gefühlt
immer mache, ja. Also, es gibt
sehr viele Sachen, die man machen könnte, um die
Zusammenarbeit zu verbessern.
Ich fürchte aber, dass
für die wirklich wichtigen Sachen auf diesem
Teambuilding-Workshop, zumindest, wenn ich mal davon
ausgehe und das vergleiche mit den
Teambuilding-Workshops, die ich schon die letzten Jahre
über ab und zu mal gemacht hab,
dass für die wirklich wichtigen Dinger, die
tatsächlich was bringen würden, eigentlich
gar kein Platz ist, dass es dann eher um so
bescheuerte Spiele geht, wie
wir machen eine Schnitzeljagd im Wald, oder sowas.
Ja.
Was war das Dümmste, was ihr mal
machen musstet?
Auf so einem Teambuilding?
Also, mir
fallen zwei Sachen ein.
Das erste ist
Sport. Ja, das ist doof.
Ich werde übrigens, nachdem das so ein Hotel
ist,
da ist auch ein See
und sowas in der Nähe.
Da werde ich morgens mal meine 5-6 Kilometer
um den See rennen. Mal gucken, ob ich dann
morgens früh, bevor es losgeht.
Zumindest...
Jetzt wurde ich abgelenkt
von der Seite.
Also, genau.
Zwei Sachen, die mir
so im Kopf hängen geblieben sind,
die richtig dumm waren bisher bei Teambuilding-Workshops,
die ich schon mitgemacht hab. Das erste war
tatsächlich auch so eine Art
Sitzkreis und da musste man Dinge
beschreiben.
Aber ohne, dass du es
sagen durftest.
Kennt ihr dieses Spiel, wo die Leute sich so Dinge auf die Stirn
kleben müssen?
Und wurde dann quasi raten
musst, welcher Promi man ist und sowas.
Übelst dummes Spiel, hab ich nie gerne gespielt.
Aber sowas in der Richtung
war das. Nur, dass man dort Wörter
bekommen hat. Sowas wie
Baumstumpf.
Baumstumpf.
Und da musstest du quasi durch...
Du durftest auch noch mehr machen.
Du musstest das erklären und du dürftest
das auch zeigen.
Also du dürftest dann quasi so
auf der Erde so einen Kreislauf so drum kreisen.
Und du durftest quasi erklären
und zeigen und die anderen mussten dann
raten, was du führen wolltest.
Ultra dumm. Wie auch immer.
Also das hat tatsächlich das Team gebildet.
Das hat das Team gebildet in der Form,
dass es alle kacke fanden und alle
einstimmig dagegen waren. So kann man ja auch
Teams bilden. Das ist ja auch okay.
Also die dummen
teambilligen Sachen, die ich da damals
beim Provider machen musste, wo ich euch
mal ein Video drüber gemacht hab.
Und das andere, das andere.
Leute, ihr lacht euch jetzt
das ist so dumm gewesen, ist so dumm.
Die hatten mal
dort, die hatten mal vom
vom Ulmer
vom Ulmer
Schauspielhaus oder so, hatten die mal
irgend so einen Teambuilding-Typ. Keine Ahnung, warum die da
sowas haben. Zumindest
der hat mit uns Sprechübungen
gemacht und die waren so unglaublich dämlich.
Man sollte sich
also man sollte sich wegdrehen gegen
die Wand, ja. Also da
haben sich quasi alle, die sich vorher angeguckt haben,
rumgedreht gegen die Wand und dann
Leute, ich hoffe mein Mikrofon macht das jetzt mit.
Ich hoffe mein Mikrofon pickt das ab, richtig.
Du solltest dich umdrehen, an die Wand stellen.
Deine Hände, es ist eins zu eins so gewesen.
Ja, du solltest deine Hände an die Wand legen
und dann solltest du gehen.
Dann solltest du gegen die Wand machen.
Das war so dumm.
Alter,
das war so dumm.
Mann, das hat mit Kaufplatz zu tun.
Und das haben die uns damals, das haben die uns als
Teambuilding verkauft. Ich meine,
das einzig Gute war auch wieder, wir haben
uns alle gemeinsam abgelehnt und deswegen
hat das das Team gebildet.
Okay. Nein, das war
das war irgendwie
irgendwie so ein Schauspiel-Drehen oder so.
Der wollte mit uns Sprechübungen machen.
Du musstest dich, aber das war wichtig, war wichtig.
Du musstest die Hände auf die
Wand legen und dich dann, und wir
haben dann halt immer gesagt, so nach dem Motto,
wir spucken jetzt die Wand an oder wie.
Wo solltest du denn...
Wo solltest du denn wirklich an die Wand gehen
und machen?
Das war so dumm.
Aber es war, es war so unglaublich dumm,
dass man sich's gemerkt hat.
Mikronavi, danke schön für den Zapp.
Also so dummes Zeug merkt man sich.
Ich hoffe, ich hoffe,
dieses Teambuilding nächste Woche da
bei uns, da wo ich jetzt bin,
das wird nicht ganz so blöd.
Oh Mann.
Ja.
Ihr habt bestimmt auch schon dummen
Teambuilding-Kram mitgemacht, oder?
Ich, ich, ich gehe von aus,
Chatke, ich gehe von aus.
Ja, alles mag's.
Ja, also ich gehe von aus. Jeder, jeder hat
schon mal ultra dummes Teambuilding mitgemacht.
Und wisst ihr, ich frag mich
bei dieser ganzen Teambuilding-Geschichte immer,
mach mal kurz hier mal
meinen ganzen Krempel an,
also ob das Absicht ist, dass die so dumm sind
oder ob man
wirklich denkt, das bringt was.
Also es könnte ja auch sein, dass das
absichtlich so dumm ist, dass die Leute
wie gesagt sich einig sind, dass es
dumm ist und quasi
gemeinsam an einem Strang ziehen, weil
sie es dumm finden. Das könnte ja auch
sein. Aber ich glaube, dass es
zu high IQ und zu weit gedacht
ehrlich gesagt dafür.
Glaube ich, glaube ich dann doch
nicht irgendwo.
Echt.
Was, verrätst du
uns, was Schlimmes gewesen ist?
Ihr musst zu Beginn einen Partner
auswählen und ihn fragen, wie ob ich so ein Lieblings-
Oh nein!
Das sind auch
so Dinger. Ich hasse solche
Sachen, Alter. Ich hasse.
Zumindest, ich hab mir so eine
Liste gemacht, da sind glaube ich mittlerweile 12
Punkte drauf oder so,
wo ich glaube, wenn man sich da mal drüber unterhält,
das würde wirklich
was bringen und die Zusammenarbeit
verbessern.
Da bin ich stark davon überzeugt, dass es
wirklich was bringen würde, wenn sich alle
mal wirklich da ein paar Sachen
Gedanken machen würden und eventuell
versuchen, sich ein bisschen so entgegenzukommen.
Aber ich glaube nicht, dass es um wirklich
essentielle Sachen da
gehen wird.
Gebt mal die Liste, die hab ich. Also erstens
hab ich die nicht hier auf dem Account
und zweitens kann ich euch die auch nicht zeigen.
Ich bin mal gespannt.
Ich bin mal gespannt, wie blöd
es wird. Vielleicht wird es auch gar nicht so blöd.
Man sollte sich ja die Option
wenigstens offen halten, dass es nicht so doof wird.
So, ich pull mal kurz
Shit up.
Shit up.
Changes.
Pog. Changes
Pult.
Ja, es macht nix übrigens, wenn ihr die letzten
Streams nicht dabei gewesen seid.
Wir werden heute ein bisschen was anderes machen.
Ich meine, wir benutzen die gleiche Anwendung weiter,
aber wir werden heute das machen, was ich die ganze Zeit
machen wollte, nämlich endlich Videos in Browser
streamen vom Server aus.
Was? Wie soll ich das verstehen?
Deine Firma wird bald
Teambuildings anbieten. Ja, da bin ich mal gespannt.
Kannst du im Chat ja mal ausprobieren.
Wenn es im Chat klappt, dann ist es
alltagstauglich.
So, den Kram hier an.
Was ist jetzt los hier?
Aha, aus irgendwelchen Gründen geht es wieder.
So, Rust. Rust.
Idee starten. Oh, haben die ein neues Bild
oder sah es schon immer so aus?
Moment.
Soll ich vielleicht mal den ganzen
Krempel aktualisieren?
Java Zeug. Java Zeug zieht einfach
mit 300% CPU.
Updating. Okay, ja, ich hätte es vielleicht mal
updaten sollen.
Ich mache es manuell.
Manuell. Ohne Binding
Generator. Es ist ja auch nicht so
viel. Es sind irgendwie
8 verschiedene Funktionen,
die ich aufrufen muss. Das reicht
für WebRTC.
Habt ihr auf Windows auch immer so Probleme
mit Docker Desktop?
Keine Ahnung. Ich würde im Traum nicht
drauf kommen, Docker auf Windows zu benutzen.
Das ist wahrscheinlich das erste Problem,
was du hast.
Es gibt so ein paar Sachen,
da hätte ich echt keinen Bock drauf.
Gibt es noch Black Friday Shopping?
Ne. Also, vielleicht
morgen Abend oder so, weil es ist ja
Montag ist ja auch nochmal, ne?
Montag ist ja Cyber Monday wahrscheinlich wieder.
Muss ich mal gucken. Vielleicht
machen wir noch eine Runde.
Aber, ich weiß nicht.
Also, ist...
Ich habe keinen Bock,
mich jibbelten zu lassen. Deswegen kaufe ich einfach nichts.
So, jetzt hat er hier geupdatet.
Gibt es Updates
für die IDEs oder sowas?
Ne, okay. Passt. Nice.
So, Rust am Start.
Visual Studio Code aufmachen. Wir haben ja hier
Multilingual
Cross-Plattform-Technology
High IQ
Anwendung am Start.
Und dann zeige ich euch mal kurz,
was es aktuell macht.
Dann werdet ihr feststellen, dass es
Extremely Pog
und alle gleich subscriben und
followen. So,
Backend.
Müssen wir starten.
Hier brauchen wir noch ein Terminal.
Äh, Rust.
Das kompilieren wir
nochmal schnell.
Äh, nicht mit Go.
Cargo.
Jawoll.
Bild, weil ich habe auch an der ganzen Rust-Geschichte
noch was geändert.
Also, Ground-Breaking-Application
werdet ihr gleich sehen.
Auf jetzt.
Guck mal hier. 500% CPU-Last.
Was treibt es denn?
Oh, fertig. Okay.
Nice. So, ich hoffe, ich habe nichts kaputt gemacht.
Das funktioniert noch.
.NET, Run.
Okay, sieht schon mal gut aus.
Also, folgendes.
Das ist die Anwendung.
Absolut Ground-Breaking.
Ich glaube, sowas Geiles habt ihr noch nicht gesehen.
Wie ging das nochmal bei
WebRTC-Logs?
Äh, nee.
Einfach nur WebRTC?
Nee, WebRTC
Internals?
Ja, Internals.
Aus irgendwelchen Gründen habe ich zwei
Verbindungen, die ich nicht checke.
Woher die kommen, aber okay.
So. Also, das ist die aktuelle Anwendung.
Ihr müsst nichts mitbekommen haben von dem, was...
Okay.
Ihr müsst nicht wirklich was davon mitbekommen haben,
was wir das letzte Mal gebaut haben.
Ich werde es jetzt ganz kurz nochmal erklären,
damit man der Sache grob folgen kann.
Und ja, ich sage es jetzt gleich.
Zumindest werden wir uns heute
um das Streamen von Videos
in den Browser kümmern.
Wie lange hat es gedauert,
den ursprünglichen Go-Code zu streamen?
Wie lange hat es gedauert, den ursprünglichen Go-Code zu streamen?
Wie lange hat es gedauert, den ursprünglichen Go-Code zu streamen?
Das ging relativ schnell,
weil, weiß ich nicht, so ein...
zwei Stunden oder so.
Weil, ich kenne die Library schon
und ich habe sowas ähnliches...
Wir haben sogar sowas ähnliches schon mal im Stream zusammen gemacht
vor ein paar Jahren.
Das ist tatsächlich nicht sonderlich kompliziert gewesen,
das in Go zu basteln.
Also.
Ja, also, was das machen soll,
ist folgendes.
Ich habe einige Webcams bei mir.
Wie sieht deine CPU-Prozessor-Konfiguration
in VMware aus?
Äh...
Vier... Vier... Oder acht... Acht Kerne.
Acht Cores.
Und...
24 GB RAM.
Also so hier sieht das aus.
Number of Processors,
acht Cores.
Standardmäßig macht VMware acht
und da unten eins.
Merkwürdig, warum auch immer.
Das habe ich an,
dass ich nested Virtualisierung machen kann.
Euren Max.
Community-Games.
Ist am Start.
Dann habe ich 256 GB SSD.
Und ich glaube,
warum auch immer
acht Gigabyte Grafikspeicher.
Macht überhaupt keinen Sinn.
I3 ist auch zufrieden
mit 256 MB.
Das braucht keine acht Gigabyte.
Aber wisst ihr was?
Ich habe ja so viel RAM,
dass ich gar nicht weiß, wohin damit.
Deswegen einfach RAM.
Beste.
Und ihr wisst doch,
unbenutzter RAM ist verschenkter RAM.
So, also was soll das Ganze machen?
Ich werde es kurz mal zeigen.
Irgendjemand hat es doch gefragt.
Hier.
Also ich habe...
Jetzt habe ich mit dem Finger gegen das Headset gehauen.
Ich habe eine...
Wobei eine stimmt.
Ich habe acht Kameras bei mir im Haus.
Und...
Die Kameras sind erreichbar über RTSP
und streamen über H264.
Ja, acht Stück.
Acht Stück.
Heiß Security.
Wobei, lass mal zählen.
Mal gucken, ob das überhaupt stimmt, was ich hier erzähle.
Also.
Eine am Eingangstor.
Eine vorne im Hof.
Eine hinten im Hof.
Eine im Keller.
Eine im Flur.
Eine oben da, wo die Katze immer rumgammelt.
Nee, Leute, es sind nicht acht.
Ich glaube, es sind nur sechs.
Ja, ja.
Wenn ich jetzt irgendwas vergessen habe,
sind es, glaube ich, nur sechs.
Ja.
Also, wenn ihr einbrechen wollt, wisst ihr jetzt, wo die Kameras sind.
Keck, wait.
So.
Und...
Die Kameras, die will ich streamen in den Browser.
Das Problem dabei ist nur...
Das ist übrigens extrem underrated, finde ich, das Emote.
Ich finde das geil.
Ich weiß auch nicht, warum.
Aber es verwendet kaum einer.
Also.
Das Problem ist, dass man Kameras nicht einfach in den Browser streamen kann.
Das funktioniert nicht.
Weder...
Weder kann der Browser RTSP, noch kann der Browser irgendwie...
Ja, so lange es in Decoder drin ist.
Noch kann der Browser ordentliches Realtime-Video über RTSP von der Kamera.
Also das funktioniert nicht.
So.
Deswegen gibt es verschiedenste Varianten, wie man das machen kann.
Video-Streaming in den Browser.
Die allereinfachste Variante ist wahrscheinlich...
Ähm...
HLS.
HTTP-Live-Streaming.
Das ist das, was Twitch auch macht, wenn ihr nicht...
Glaube ich zumindest.
Wenn ihr nicht...
Ähm...
Den Latency-Modus...
Low-Latency-Modus bei Twitch aktiviert habt.
Wobei ich bin mir nicht sicher, ob...
Ich glaube, selbst beim Low-Latency-Videodings macht Twitch das auch so.
Also.
HLS-Streaming ist ganz easy.
Es wird einfach über HTTP immer kleine Häppchen vom Videoclip runtergeladen und in ein Video-Element
im Browser gerendert.
Das funktioniert natürlich nur, solange der Browser den Codec kann.
Aber wenn der Browser den Codec nicht kann, hat man andere Probleme.
Viel nicer ist das.
Und viel schneller.
Und viel...
Weicher.
Und...
Ja.
Noch kein AV1.
Ne.
Und auch viel mehr ohne Lag.
Ist das, wenn man das ganze bei WebRTC macht.
WebRTC ist eigentlich dafür gedacht...
Für Echtzeit-Video-Audio-Audio-Kommunikation von Clients zu Clients.
Also.
Wenn ihr zum Beispiel Teams verwendet.
Oder Zoom.
Oder irgendwas.
Ist eigentlich egal.
Discord.
Ist eigentlich vollkommen wurscht.
Vieles davon.
Wobei Discord nicht.
Discord glaube ich nur das Video.
Glaube...
Weiß ich gar nicht.
Ehrlich gesagt.
Ähm.
Aber dann machen die WebRTC.
WebRTC ist...
Steht's ja hier.
Ein offener Standard, der eine Sammlung von...
Bla.
Okay.
Die Beschreibung ist halt richtig pepega.
Das ist für Echtzeit-Video-Audio-Kommunikation wie zum Beispiel bei Microsoft Teams.
Und Teams benutzt es auf jeden Fall.
Was man jetzt macht.
Wie gesagt.
Das ist eigentlich gedacht.
Für Client zu Client.
P2P-Kommunikation.
Also.
Du machst einen Gruppencall.
Mit fünf Leuten.
Und die streamen dann untereinander ihr Audio und Video.
Was man aber auch machen kann ist.
Man kann.
Ja.
Einen.
Eine.
Eine Server-Komponente hinzufügen.
Die dann zwar auch im WebRTC nur ein Client ist.
Aber die auch Videos schickt.
Und jetzt.
Wird's advanced.
Und da müssen wir heute weiterbauen.
Deswegen ist es nicht schlimm, wenn ihr nicht dabei gewesen seid.
Weil den Part haben wir noch gar nicht gebaut.
Man kann jetzt.
Zum Beispiel.
Auf Server-Seite.
Die Kameras auslesen.
Per FFmpeg zum Beispiel.
Per FFmpeg sich zu den Kameras connecten.
WebRTC ist in JavaScript und C++ geschrieben.
Das stimmt nur zur Hälfte.
Kann ich gleich was zu sagen.
Also pauschal ist erstmal nicht richtig.
Aber auch nicht.
Auch nicht ganz verkehrt.
So.
Was wollte ich jetzt sagen.
Genau.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
Also.
aufgebaut hat, zu einem Browser,
so quasi
im Browser schicken, so wie sie
kommen, ohne so zu decoden und neu
encoden, wie sie kommen, kann man die da reinschicken
und quasi so tun, als ist man
im Endeffekt eine Webcam in einem Teams-Call
und jetzt mal
bis in höherem Niveau zu sagen
und dann kann der Browser das auch anzeigen.
Also man wandelt quasi
den Webcam-Stream
um in was, was der Browser in Echtzeit
anzeigen kann. Was ja nice ist,
da hast du überhaupt kein Delay
drin, also wenn die Kamera
Delay hat, wenn die Kamera
Delay hat, natürlich schon, ja,
aber du hast ab dem Zeitpunkt des
Stream-Abgreifens und in den Browser zu
streamen, so gut wie, so gut wie,
sagen wir mal, kein Delay. Also deutlich
unter einer Sekunde,
eher im Bereich von ein paar Millisekunden,
also 100, also das ist wirklich
ziemlich Echtzeit, was halt auch nice ist,
wenn du zum Beispiel, wenn es klingelt
und du siehst unten den Typ dann an der
Gegensprechanlage stehen
und die Mundbewegung
passend zu dem, was du hörst zum Beispiel, ja, das ist halt
halt nice. Könnte man nicht auch über
Nginx, RTMP, nö, wie willst du denn das in den Browser
kriegen? Kann kein Browser,
kann das nicht. Browser können
HLS dann da drüber machen zum Beispiel, ja,
aber das ist dann mit ein bisschen Delay und
Lack verbunden. Außerdem
ist WebRTC ein Pogger, eine Poggers
Sache, mit der man sich mal beschäftigt
haben sollte. Kann auf jeden Fall
nichts schaden. So, um jetzt
da was dazu zu sagen, also
Icos, du hast im Prinzip recht.
WebRTC ist eine
Technologie für den Browser, ganz klar.
Wurde auch von Browserherstellern mit
initiiert und die Referenzimplementierung
ist in C++,
weil, ja, die Browser
sind halt in C++.
GitHub, WebRTC, die Referenzimplementierung
gibt es auch, gibt es auch
irgendwo auf
GitHub, kann man die sich
angucken.
Irgendwo
habe ich die, habe ich die schon gesehen.
Aber macht keiner,
weil die C++ Geschichte ist.
Eklig. Deswegen
gibt es
auch alternative
Implementierung von WebRTC,
die nicht in C++ geschrieben sind
und auch kein JavaScript auf
Serverseite brauchen. Zum Beispiel
gibt es da Pion, das ist
in Go programmiert. Das ist
eine, hier eine Pure
Go Implementation von WebRTC
und dann gibt es zum Beispiel
auch noch
für Rust, das ist das, was wir
hier verwenden, gibt es für Rust, gibt es in WebRTC
Implementierung, auch alles jetzt nicht ganz unbeliebt,
wenn man sich die Sterne anguckt. Es gibt
auch, es gibt glaube ich auch eine
Python-Implementierung, die habe ich mal kurz ausprobiert,
die war richtig schrottig.
Zumindest für das, was ich machen wollte.
Also, das gibt es,
es gibt verschiedene Implementierungen, aber
prinzipiell hast du nicht unrecht, wenn du, wenn du sagst,
dass es JavaScript und C++
ähm
Akara-Sensoren und so.
Hast du die selbst geflasht? Da hast du jetzt
wirklich, du musst auf jeden Fall
die Zeit, was die zum Senden
brauchen, runterstellen. Stell das auf
12 Minuten, 15 Minuten oder so.
Zeit zum Sensorabfragen runterstellen, äh
Hochstellen, nicht runterstellen, Hochstellen
und Zeit zum Verschicken hochstellen,
weil das reicht, wenn du alle 15 Minuten
weißt, wie warm es bei dir im Flur ist
und dann hast du 2 bis
3 Jahre, mindestens 2,5
hatte ich, ich hatte fast 3 Jahre Batterielebenszeit
von so einer kleinen
CR2302-Knopfzelle.
Das hast du mit sonst keinem anderen Sender,
äh, keinem anderen Sensor.
Das ist extrem pogu.
So, falls ich irgendwas überlesen hab, sagt Bescheid.
RTSP Relay,
die verwenden WebSocket. Na, WebSocket
alleine bringt denen ja nix, ne, die müssen
streamen die, streamen die dann
die Videodaten über WebSocket
und
irgendwie in den Video-LM, kenn ich nicht,
kenn ich nicht.
Aber WebRTC ist für sowas halt gemacht.
Also ich weiß nicht, wie die das machen,
aber WebRTC
ist auf jeden Fall lower latency.
Würdest du empfehlen,
wenn man sich mit Kubernetes beschäftigt?
Ja.
Ach was? Nicht ob, was?
Ja, also ich würd's,
ich würd's auf jeden Fall, ich würd's auf jeden Fall
empfehlen, sich mit Kubernetes zu beschäftigen.
Wenn man
irgendwie Interesse
daran hat,
wenn man sich mit Kubernetes zu testen
würde, also, also, Minikube.
Wenn du anfängst, Minikube. Minikube ist das
allereinfachste, was du verwenden kannst.
Zeig ich dir, das ist so einfach, dass ich das jetzt
einfach zeigen kann. Minikube
Start.
Nein, zum einfach mal schnell was ausprobieren.
Nicht. Aber kann man sich drüber streiten,
aber ich find, zum einfach mal schnell, Minikube ist das
beste, was du machen kannst. So, es gibt
anscheinend eine neue Kubernetes-Version, die man neu runterladen
muss. Okay, nice. Dann müssen wir
kurz warten. Du kannst
Minikube übrigens einfach auch hier
über, also
falls du Arch, by the way, verwendest,
was du hoffentlich machst, weil
High-IQ-Stream,
Arch, by the way,
use ich auch, so wie
allen coolen Leuten natürlich.
Arch. Und es ist wichtig,
dass man das öfters erzählt.
So, guck, das war's.
Minikube Start, der lädt die
neueste Kubernetes-Version runter,
startet entweder eine VM
oder Docky, äh, Docky, äh,
oder Docker-Container mit der
Kubernetes-Control-Plane drinne.
Außerdem hat es Emojis.
Und jetzt sagst du
kubectl, ja, hab ich doch nicht.
kubectl get pods-a und du siehst,
du hast einen laufenden Kubernetes-Cluster.
Also, viel einfacher als
Minikube zum lokalen Basteln
gibt es meiner Meinung nach
nicht. Minikube hat
ein paar Nachteile, wenn du
etwas advancedere Features verwenden willst.
Zum Beispiel, wenn du Kubernetes-Loadbalancer
verwenden willst, also
den
Service-Typ Loadbalancer
verwenden willst, dann
geht das nicht so ohne weiteres.
Aber das geht offline eh nicht so ohne weiteres.
Da muss man sich da ein bisschen Gedanken machen.
Aber, wenn du einfach nur basteln willst,
ist Minikube das Beste. Und wenn du fertig bist,
noch besser, Minikube stopp.
Oder noch besser,
wenn du Platzfehler freigeben willst, Minikube delete.
Dann löscht er den ganzen Krempel wieder
rückstandslos weg und
du hast keinen Kubernetes-Cluster mehr.
Also, kann man sich
sicherlich drüber streiten. Ich persönlich würde Minikube
empfehlen. So sieht's aus.
Und an Projekten
würde ich mal klein anfangen.
Nimm irgendwelche
Hello-World-Applications,
die einfach funktionieren. Irgendwelche
Web-Anwendungen. Lass dir mal ein paar
anrufen. Lass die mal möglich stateless.
Lass die mal deployen.
Skalier die mal hoch und runter.
Bau einen Service davor. Setz
den Ingress davor. Guck, dass
du vielleicht anfängst mit, okay,
wie sieht's denn aus, wenn man da
Configs reinmouten will, wenn man da Secrets
reinmouten will, wenn
man...
Vielleicht Zertifikate kannst du dir angucken.
Vielleicht Persistent Volumes,
falls man das doch mal braucht. Was man
öfters mal braucht.
In der Theorie ist immer so geil,
das Planet ist alles stateless.
Es ist alles stateless, bis es nicht mehr stateless ist.
Also man braucht schon ab und zu nochmal
Volumes.
Und wenn man's ganz übertreiben will,
und wenn man's ganz übertreiben will,
kann man sich alles angucken. Aber wenn man's ganz
übertreiben will, dann geht man einfach auf...
Wie heißen diese...
Wie heißen die? Cloud Native
Cloud Foundation.
Cloud Native Computing
Foundation, die meine ich.
Und wenn du's voll übertreiben willst,
dann guckst du dir den...
...den Cloud...
...den Cloud Native...
...
...Cloud Native
Computing Foundation
Landscape an,
von allen Projekten, die
was mit Kubernetes zu tun haben.
Und du wirst feststellen, du bist erschlagen.
Du blickst überhaupt nicht mehr durch, man.
Und damit es dich nicht so komplett überfordert,
musst du hier umstellen, dass du nur...
...dass du nur...
...CNF-Projekte
anzeigen willst, aber selbst dann
sind's immer noch ein paar.
Das, was Kubernetes kompliziert macht, ist
zum Großteil mit
das Kubernetes-Ökosystem drumherum.
Aber was man auch braucht,
weil mit Kubernetes alleine
wird man halt auch nicht glücklich.
So.
Gut. Dann fangen wir mal an.
Mal gucken, ob mein Connection-Abbauen
richtig funktioniert. Warte mal, ich mach mal die
Connection zu. Connection direkt.
Gleich schreiben. Active Connect. Okay.
Stay disconnected. Er hat das schon mal gecheckt.
Okay. Nice. Hat funktioniert.
Also. Soweit so gut.
Ich hab jetzt ausgeholt,
was wir heute machen wollen. Also heute...
Ne. Also was die Anwendung machen soll.
Wie weit wir bisher sind.
Wir haben's bisher nur geschafft,
dass eine Webseite
ausgeliefert wird. Hier. Das ist die
gesamte Webseite hier.
Das ist alles. Und
die baut aktuell nur eine WebRTC-Verbindung.
zum Server auf.
Da legt er eine WebRTC-Verbindung an.
Callt den Endpunkt für WebRTC-Start.
Dann kriegt
er...
Dann kriegt er eine Liste geschickt,
mit was der Server für Codex unterstützt.
Das ist nur H.264.
Und dann schickt der Browser selbst zurück,
was er für Codex unterstützt.
Der Server nimmt das an und dann ist die WebRTC-Verbindung
aufgebaut. Ja. So. So ganz
grob. Rust
ist auf dem Low-Level
WebRTC-Layer am Start.
Weil wir verwenden hierfür
die, ich glaub die heißt einfach
WebRTC-RS-Library.
Das Ganze, ihr werdet's vielleicht
hier sehen, ab und zu mal, das Ganze
hab ich auch mal in Go gemacht.
Aber hab mir überlegt,
ey, wenn man schon mal sowas neu
baut, was man schon mal gebaut hat, dann kann man's doch auch
mit ein bisschen was anderem machen.
Und jetzt ist Rust am Start. Genau.
Im Prinzip, ich zeig euch mal ganz kurz
den Rust-Part. Lasst euch mal nicht von
abschrecken, dass Rust so eklig aussieht.
Das ist normal. Ich finde, das ist,
wo sind eigentlich unsere zwei, unsere
zwei Spezial, unsere zwei Spezial
High-IQ Rust
Enjoyers?
Moment. Ich weiß, ich weiß die Namen
auch noch.
Weil, die hab ich letztens
ins Commit reingeschrieben.
Wo sind denn
FronAqua
und Odolmed?
Wo sind die
Ober-Rust-Enjoyer? Rust
sieht eklig aus. Ja, Rust sieht
eklig aus. Ja, Go ist
auch nicht die schönste Sprache, aber
ganz ehrlich, im Vergleich, im Vergleich zu
Rust
ist Go noch hübsch.
Ich lass mir das ja
gefallen, dass es unterschiedliche Ansichten
gibt. Aber in dem Fall
nicht.
Also, okay. Okay,
sagen wir mal so. Es ist vielleicht kein C++,
aber schön ist es wirklich nicht.
Das hier ist jetzt auch
halbwegs ordentlich.
Ja. Glaube ich zumindest. Ich bin ja auch
kein großer, kein großer Rust-Checker.
Also, ich zeig euch mal ganz kurz, was die
Rust-Seite macht.
Ich hab sicherlich vieles
drinne, wo jetzt die
richtigen, nicen
Krustentiere sagen würden, dass das nicht
Wie sagen sie immer? Das ist nicht
idiomatic
rust oder idiomatic
Wie spricht man das aus, Chat?
Low IQ time.
Oder vor allem,
wie heißt das auf Deutsch?
Das ist nicht,
das ist quasi nicht, wie man Rust macht.
Das Ding ist, viel anders werde ich's nicht
machen können, weil ich halt Interop mit C
brauche und deswegen Rust. Ganz kurzer
Überflug über das Ganze. Was passiert?
Idiomatisch, ja. Nicht ideologisch,
idiomatisch. Irgendwie sowas.
So, also mal ganz kurzer, ganz
kurzer Überflug über das, was hier
Low-Level-mäßig in Rust passiert.
Es gibt eine Init-Methode, die wird als
allererstes aufgerufen. Sieht man auch hier.
Achso, hier ist noch das alte,
das alte Go-Zeug drin. Das könnte man mal wieder
rausschreiben. Es gibt eine Init-Methode, die
wird als allererstes aufgerufen, sobald
wir, sobald die Web-Anwendung
Warum werden meine
Active Connection
One? Was ist das?
Achso, ich habe tatsächlich
eine Active Connection. Mein Programm
funktioniert besser als mein Kopf. So, gucken
wir mal, ob die Verbindung, gucken wir mal, ob das
jetzt, ob das jetzt gleich weggeht, ja. State is
disconnected. Ihr sollt jetzt eigentlich
checken, dass es zero Active
Connections gibt, ja.
15 Sekunden.
Guckt alle 15 Sekunden nach.
Zero, okay, nice.
Also, das als
allererstes wird hier
einmal, einmal Init aufgerufen.
Init in Rust macht folgendes.
Initialisiert das ganze WebRTC
Zeug. Ja, frag.
Frag ruhig. Initialisiert
das ganze WebRTC Zeug. Macht
ein Netzwerkport auf und setzt das
Zeug, was man für WebRTC braucht.
Wichtig ist das hier. Das
setzt, dass wir auf Server-Seite nur
H.264 unterstützen als Video-Codec.
Sieht man hier oben.
Wir unterstützen als Video-Codec
nur H.264 und das ist auch
hier Rust, Rust-Logik.
Hab im PC TPM aktiviert, aber
kann nicht auf Windows 10 wechseln. Warum?
Keine Ahnung. Ich hab von Windows keinen
Plan. Vielleicht wird die CPU nicht unterstützt.
Wobei ja eigentlich, theoretisch
alles unterstützt werden soll, was
TPM hat, oder? Oder braucht man nicht
sogar TPM2? War
das nicht so, dass es nur mit TPM2 läuft?
Windows 11? Chatgear?
Also, wenn es nicht TPM2 hat,
ach, TPM2. Also, vielleicht,
wird die CPU nicht unterstützt. Ich meine,
es gibt, es gibt diesen, es gibt ja diesen
komischen Trick.
Gibt doch diesen Trick, wie man
das trotzdem installiert, aber den hab, das
hab ich noch nie gemacht und ich hab auch von Windows keine Ahnung.
Also, da, da kann dir wahrscheinlich der Chat besser
helfen, als ich. Ich hab da keinen Plan von.
Nichts planlos. MonkaS.
Ja, dann müssen wir, dann ist
halt die, Secure Boot, ja stimmt, Secure Boot
brauchst du auch noch. Ja gut, das muss ja irgendeine Fehlermeldung
geben. Oder es ist irgendeine Standard Microsoft
Fehlermeldung. Es ist ein unbekannter
Fehler aufgetreten. Klicken Sie auf
fahren.
Keine Ahnung.
Von Windows bin ich der falsche
Ansprechpartner.
Ok, Chatgear. Also,
wir, wir, wir sagen, dass wir nur
H.264 unterstützen.
Weil, in dem Stream sind halt auch
die Videos von der Webcam. Das ist das erste,
was aufgerufen wird. Und dann machen wir
nochmal einen kurz, kurzen Überblick über die anderen zwei
Sachen, was passiert. Ähm,
es gibt
eine Create Connection.
Das baut die WebHTC-Verbindung auf.
Der sammelt erstmal alle, alle
IP-Endpunkte ein. Erzeugt
eine Liste, mit was für Codecs
unterstützt werden und sendet das
zurück an den Browser. Wie gesagt, eigentlich müssen wir
das gar nicht wissen, für heute. Deswegen machen
wir das jetzt nur ganz schnell. Ähm,
dann stellt er noch ein paar Sachen bei der
neuen WebHTC-Connection ein.
Zum Beispiel, dass
die entfernt wird, wenn
sie geschlossen wurde.
Ähm, wenn nach 10 Sekunden die
Verbindung immer noch im State New ist,
dann
wird sie auch gelöscht.
Antwort vom Browser
setzen.
Track anlegen. Track ist quasi das, wo man dann
die Videobilder schickt.
Und hier,
wo man Videomaterial schicken kann.
So, das ist im Prinzip alles.
Der Rest ist Rust-
Zeremonie, damit es funktioniert. Da müssen wir uns
gar nicht so genau angucken. Das heißt, heute
gibt es auch eine Mischung aus Rust und C Sharp.
Wie viel Rust wir brauchen, muss ich nochmal gucken.
Ähm, also
wenn ihr was wissen wollt, könnt ihr mich gerne fragen.
Ich bin absichtlich jetzt da im Schnelldurchgang
drüber gegangen, weil erstens ist es für heute
nicht so wirklich relevant. Und
zweitens, für die, die das letzte Mal dabei waren,
die kennt ihr wahrscheinlich noch. Also, insofern.
Gucken wir mal.
Jetzt bin ich gerade am überlegen,
wo wir weitermachen.
Wir müssen eigentlich jetzt ein bisschen C Sharp
machen und FFmpeg.
Und damit FFmpeg
funktioniert, brauchen
wir erst einmal
ein Video. Also Ziel für
heute ist, dass ich mich
verbinden kann per WebRTC und hier
kommt ein Videoplayer hin.
Ich glaube, wir haben gar keine sinnige Erklärung
heute drin für das Projekt.
Also Ziel für heute ist, das kommt mal theoretisch,
theoretisch könnte man, wenn ich
jetzt schnell bin, könnte man das mitschneiden und
als Track machen.
Also Ziel für heute ist, dass wir hier
einen Videoplayer kriegen und vom Server
über WebRTC
einen Videostream schicken können an den
Browser. Deswegen können wir
theoretisch schon mal, damit wir wissen,
wohin das
Ganze gehen soll,
können wir theoretisch schon mal
hier oben einen Videoplayer reinpappen.
Wo haben wir das hier?
Video
ID
gleich
Player.
Dass es wenigstens so aussieht, als könnte er was anzeigen.
Inline Style beste.
Breite 100%.
Massive.
Backgrounds
Black.
So, jetzt haben wir einen Videoplayer.
Der Videoplayer macht natürlich noch nichts,
weil es zur Zeit keine Videoframes zum Playen gibt.
Aber man sieht zumindest schon mal einen Videoplayer.
Dann schalten wir hier noch ein
Auto
Play.
Man muss es muted machen.
Und dann gab es hier noch so ein
Wie hieß das?
Inside?
HTML Plays
Plays inline, nicht inside.
Plays inline.
Die Dinger sind wichtig für Mobile.
Also falls ihr,
jetzt nochmal, pass auf, krasse Web-Frontend
Developer-Tipps und Tricks hier.
Vom Web-Developer
High-Skiller,
Ultra-Skiller schlechthin.
Wenn ihr Probleme habt mit
Autoplay-Content auf Mobile,
dann liegt das daran, dass
die Videos nicht muted und Plays inline
nicht gesetzt sind.
Also sowohl iPhones, also iPhones definitiv,
bei Android bin ich mir nicht sicher,
aber ich glaube bei Android ist es auch so,
sowohl iPhones als auch Android
spielen Videos nicht ab, solange die nicht muted sind
und solange die nicht auf Plays inline stehen.
Spielen die nicht automatisch ab auf der Webseite.
Und warum? Weil Spam.
Weil ansonsten Werbung halt alles voll spammen kann.
Browserseitig wird doch immer gemuted.
Das wird aber nicht abgespielt,
wenn es nicht gemuted ist.
Zumindest auf iOS ist das so.
Muted hast du keine Chance.
Du kannst noch so viel Autoplay einstellen,
wird nicht abgespielt.
Es muss muted sein, sonst wird das nichts.
Du kennst mich, das ist
Pogu, dass du deinen Weg hierher gefunden hast.
Wie hast du das gefunden? Zufällig?
Über Empfehlung auf Twitch oder bist du
über den Link auf YouTube hergekommen?
Recommendation auf Twitch da ist.
Hast du erkannt am Logo,
gehe ich mal von aus.
Vermute ich jetzt einfach mal,
weil du siehst ja in der Vorschau nur unten links
so kleine Icons.
Yuki Cat ist wieder am Start.
Immer noch
nicer Weep Name.
So, jetzt muss ich mal kurz
konzentrieren.
Wo sind wir stehen geblieben?
Video Player, also
HTML Zeug scheint ja zu funktionieren,
das brauchen wir jetzt erstmal nicht.
Rust Zeug geht auch, brauchen wir auch erstmal nicht.
Also, wir müssen FFmpeg
Zeug, wir müssen FFmpeg
Kram machen. Also,
ich hab hier sogar schon
minimal angefangen mit FFmpeg.
Also, das Ding ist folgendes.
Damit wir das jetzt überhaupt ausprobieren können,
brauchen wir erstmal
ein Testvideo.
Weil ich brauche hier irgendwas, was ich im Browser
anzeigen lassen kann. Deswegen würde ich sagen,
wir gehen jetzt einfach mal
bei mir auf YouTube
und ziehen uns irgendein Testvideo.
Irgendein kurzes, irgendein kurzes Video
vielleicht. Man kann ja nicht mal
gescheit sortieren auf YouTube. Habe ich irgendein
kurzes Video, irgendwie 5 Minuten oder so?
Hier!
Neuer Unreal 5 Shooter, sieht fast zu real aus.
Das ist gut, das können wir nehmen.
Ist auch 60 FPS
und alles, gell?
60 FPS, perfekt.
Pock. Das, das kann man...
Oh. Was?
Weh.
Außerdem haben wir vielleicht noch ein anderes Video, ein bisschen...
Hier, morgen ist mein letzter Tag.
Okay, da gibt's Schneiber.
Schneiber Gameplay.
Der Schnitzel-Stil.
Ich verwende schon nämlich mein Video.
Katschi Roll!
Ähm...
Max, du wirst doch mal
irgendwo ein kürzeres Video gemacht
haben, Mann.
Mein neuer PC ist Overkill.
Das ist gut, das nehmen wir jetzt.
Alter, warum laggt mein Browser so?
Das nehmen wir jetzt. Also, machen wir hier
mkdir temp-verzeichnen.
Ah, den haben wir schon, ne?
Hier, keine Ahnung, RTSP Video.
YouTube DL.
Dann laden wir mal das Video
runter.
Ah, ne, es ist Groß F, gell?
Groß F.
PainRespect wieder.
So, wir laden das Video
in...
Ich glaube 720p reicht erstmal
aus. Und zwar auch
nur das Video runter.
So. Und als nächstes brauchen wir
einen RTSP Server, um die Webcam zu
simul... äh, nicht die Webcam, die Kamera zu
simulieren. Und da habe ich früher immer
den hier verwendet. RTSP
Simple heißt dieses Ding. Der heißt
jetzt nicht mehr RTSP Simple.
Der heißt jetzt MediaMdx.
Warum auch immer.
RTSP Simple war zu simpel.
Das ist jetzt MediaMdx.
Gibt's das?
Lass mal gucken, ob Arch, Arch
Linux wieder superior ist.
Ja, gibt's als Package, aber...
Wir laden das Binary runter.
Annehmen wir einen Empfehl für möglichst
leisen Managed 48
Port Switch.
Ich muss dir sagen, ist schon ein bisschen her,
dass ich geguckt habe. Ich kann dir
was empfehlen, aber
nicht blind kaufen. Guck erstmal, ob das
wirklich was passt für dich.
Ähm, was hältst du von Mikrotik
switchen?
Zum Beispiel...
Brauchst du 10 Gig?
Oder, oder 1 Gig?
Oder, was brauchst du?
Also, was ich dir
empfehlen kann, ist... Also, das ist...
Das ist ja eigentlich fast schon...
Das hier ist ja fast schon der Klassiker.
Ach Moment, 48
Port?
Ähm, die sind passiv gekühlt.
Die sind passiv, die haben überhaupt keinen Lüfter.
Ähm...
Das ist ja nur 24 Port.
24 Port reicht hier nicht, gell?
Dann müssen wir weiter gucken, ob
die auch... Haben die davon auch einen 48
Port?
Ja.
Ja, da bin ich tatsächlich überfragt für
48 Port von denen.
Ja, das hier sind
24 Ports.
24... Tatsächlich, die haben
48. Okay.
Das ist natürlich schon ein bisschen
advanced da.
48 Gigabit,
4x10 Gig,
240 Gig, oder ist 2
cool, ist das 40 Gig?
Ne, dann kann ich dir leider nichts
Gutes empfehlen.
Weil ich nicht weiß, wie die sind.
Also, bei den anderen wäre
es relativ no brain gewesen, aber
ich weiß, was die tun.
Ne, da...
Dann weiß ich es nicht.
Ne, da kann ich dir nichts empfehlen.
Aber der Chat, der Chat
ist high IQ.
So, laden wir uns mal den
LTSP Server runter.
Copy Link without
Site Tracking. What?
Was soll denn hier getrackt werden?
Wo ist das Video, das du
angekündigt hast?
Was denn? Was habe ich da angekündigt?
Das mit der Bewerbung?
Ja, das mache ich noch.
Das mache ich im Dezember. Okay.
Also,
jetzt starten wir mal den Server.
Und
also, das hier ist jetzt unsere
Webcam, ja? Beziehungsweise unsere Kamera.
Das ist ein lokaler
LTSP Server zum testen.
Und jetzt müssen wir uns auf der Seite nochmal
raussuchen, wie man hier mit FFmpeg...
Das hat nichts mit unserem Serverseitigen FFmpeg
zu tun.
Wie man mit FFmpeg da rein streamt.
Ja.
Wir übernennen das Video mal kurz um.
Äh, mein
neuer PC ist Overkill, mein
.mp4.
So, und jetzt
streamen wir das hier rein.
Und ich hoffe, der Codec passt.
Weil, da ist es teilweise
ist der Browser da sehr wählerig.
Okay, so, jetzt haben wir den Fake
LTSP Stream lokal.
Und da gucken wir mal, ob wir das Ganze
abgespielt bekommen.
Ob der überhaupt funktioniert.
FFplay oder VLC.
VLC geht genauso.
Kann FFplay das spielen?
Okay, FFplay kann das.
Warum auch immer VLC
das nicht kann? Kein Plan.
Aber FFplay spielt mal ein Video
ab, über RTSP.
Also, das ist unsere
Beispielkamera, quasi, ja?
Das ist der gleiche Weg,
wie irgend so ein 115 China Chinesen Cam,
die ihr bei AliExpress oder
Amazon kauft, den Videostream
ausliefert. Nur, dass das hier
ein bisschen höhere Qualität hat vom Videostream.
Gut, das funktioniert.
Jetzt können wir uns um den FFmpeg
Part kümmern.
Glücklicherweise habe ich
schon ein paar Sachen mit FFmpeg gemacht,
sodass ich nicht komplett
planlos bin, was
FFmpeg angeht. Aber so
hundertprozentig High IQ aus dem Kopf
jetzt auch nicht
unbedingt. Wir machen das jetzt einfach mal
testweise.
Also, wir brauchen die URL von dem Stream.
Also, wie gesagt, Ziel ist,
hier mit FFmpeg,
also mit der FFmpeg Library, nicht
mit der FFmpeg, mit dem FFmpeg Command Line
Tool, was die meisten kennen,
mit der FFmpeg Library den Stream auszulesen
und dann den Stream an den Browser
zu schicken.
Soweit, so gut. Soweit die Theorie
des Ganzen.
Let's go. Also, das
Okay.
Ich habe ja schon mal angefangen.
Wofür habe ich das?
Hier muss die URL rein für unseren Stream.
So.
Jetzt muss ich das Result ausgeben,
um zu gucken, ob das alles
funktioniert hat. Lass uns mal checken.
Wir warten.
Wir warten einfach mal.
Okay. FFmpeg macht
einfach gar nichts. Ich glaube, das
crasht oder so.
Warum crasht das?
Suckt, wenn das crasht,
Alter.
Mal kurz ohne Task.
Das ist ja richtig Schrott, wenn das crasht.
Was hat er für Schmerzen?
Okay, es crasht, weil
Not supported exception.
Specified method is not supported.
Dynamically loaded bindings.
Nice.
Excellent. Also, ich meine, ich habe
FFmpeg offensichtlich installiert.
Ich glaube, ich weiß, dass man musste
irgendwie den Pfad
zu den Libraries setzen.
Jetzt ist nur die Frage, wo unter
Linux wahrscheinlich lib oder so.
Lib.
Ne, es heißt nicht FFmpeg,
es heißt libav, genau hier.
Libavfilter. Okay.
Legt das in lib? Probieren wir es mal aus.
Lib. Crasht es immer noch?
Es crasht nicht
mehr. Fixed.
Easy.
Hier müssen wir noch
to do auto detect.
Ich habe nicht
FFmpeg 4.4. Ich weiß auch nicht, warum
das so heißt. Ich habe FFmpeg
6.1. Ja, 6.1.
Ich gehe davon aus, das ist zur
Abwärtskompatibilität da irgendwie mit
verlinkt noch. Aber unter der Haube ist es
wahrscheinlich 6.1.
So.
Also, das funktioniert. Es ist auch returncode 0.
Also FFmpeg
ist in der Tat etwas gewöhnungsbedürftig
als Library. Ja.
Aber wenn man sich einmal dran gewöhnt hat,
so an diesen FFmpeg-Style, wie man es verwendet,
ist das, finde ich,
eines der angenehmeren Libraries
zu benutzen.
So. Man merkt aber, dass es
Low-Level-Kram ist, weil man
Sachen machen muss, wie
AV-Format, Alloc-Context
und solche Geschichten. Und mit Pointer
und Unsafe und sonst was.
So.
Wenn ich das jetzt richtig im Kopf
habe, was wir jetzt als nächstes machen müssen,
ist sowas wie,
ich glaube Find, irgendwas mit Find
heißt das.
Find-Stream-Info, das meine ich.
So.
Da muss das rein
und
das
Dictionary
braucht man da glaube ich nicht,
aber ich kann es ja auch mal mit übergeben.
Der Reference
gibt auch ein Result
zurück.
Kurz gucken, ob das funzt. Okay.
Passt. Passt.
Laut genug.
So. Und jetzt müssen wir irgendwie die einzelnen Frames
auslesen. Ich bin, ich bin
gespannt, ob ich das aus dem Kopf noch zusammenkriege,
wie das funktioniert hat. Also wir brauchen
auf jeden Fall eine Schleife.
Eine, erstmal, erstmal eine
Endlosschleife zum Testen.
So. Also. Wir haben FFmpeg
jetzt gesagt, wir wollen diese
URL hier öffnen. FFmpeg
ist wirklich, wirklich auch ziemlich
clever, was das angeht.
Wenn ich jetzt hier beispielsweise
http irgendwie angebe, eine URL
oder irgendein lokales File
oder sowas. FFmpeg
kann relativ gut Auto-Details,
was in diesem Stream
drinne ist. Also man muss so gut wie nie
von Hand irgendwas setzen.
Also FFmpeg ist da ziemlich, ziemlich schlau.
While
true 0w. So. Und jetzt müssen
wir irgendwie Packages auslesen.
Ich glaube, dazu brauchen wir erstmal
ein Package. Package ist
bei, ist bei FFmpeg
quasi encodete Videoframes
im Endeffekt. So. Das gibt's
irgendwie sowas wie Unlock Packet.
Naja, war umgedreht.
Packet.
Oh.
Okay. Und wie
ging das jetzt nochmal?
Oh. Ich weiß es
nicht mehr. Ich glaube irgendwas Read Frame
oder sowas. Read.
Read Frame.
Genau.
Read Frame
Format.
Und da muss jetzt das Packet rein.
Oh.
Und jetzt, und jetzt bin ich
gespannt, ob das funktioniert.
Theoretisch sollte der jetzt den
Webcam-Stream einlesen. Das ist übrigens schon
alles, was man in FFmpeg machen muss. Also
kommt auch ein bisschen mehr drum rum, klar.
Aber FFmpeg ist, wenn man sich dran gewöhnt hat,
Extremely Pog
zu benutzen. So.
Result. Schauen wir mal. Der sollte jetzt eigentlich
in Endlosschleife den Videostream einlesen.
Macht er auch.
Können wir einfach ausprobieren, ob er
das wirklich macht. Pack. Oh.
Ich hab so ein kleines
Memory-Leak hier am Start, wie euch vielleicht
auffällt. Erkennt
ihr es auch, Leute?
Erkennt... Ja.
Filter ist abartig.
Erkennt ihr auch mein kleines Memory-Leak?
Free is bloated. Wir müssen hier nichts freeen.
Ja. Ich kann euch auch zeigen,
dass es etwas
Memory-Leak... ähm...
Hä?
Wie? Warum Memory-Leak das nicht?
Das Memory-Leak gar nicht.
Doch.
Doch, das Memory-Leak.
Doch.
Doch, doch.
Guckt. Jetzt.
Ja, es sind halt immer nur 1,
2 MB pro Durchlauf.
Und es sind nur 30, oder 60 FPS pro Sekunde.
So krass liegt das nicht.
Aber es liegt.
Ja, ja. Ne, es geht nicht.
Leute, wenn...
Das kannst du 2 Stunden laufen lassen, ist dann RAM voll.
Guckt, es ist Unmanaged Memory
auch das größte Teil. Ja.
Also.
Leak.
Woop. Leak.
Also ihr seht, das ist keine so gute Idee.
Ich hab 64GB RAM.
Ich kann es ja weiter laufen lassen. Ja.
Also, das können wir auf jeden Fall nicht so lassen.
Und...
Es ist auch ganz einfach zu fixen.
Nämlich einfach Packet
raus aus der Schleife
und gut ist.
Ich bin mir jetzt bloß nicht sicher, ob das das Package
einmal komplett cleart.
Ich bin mir nicht sicher,
ob wir das Package clearen müssen.
Oder ob das
AV-Read Frame macht.
Das müssen wir mal gucken.
Da bin ich mir unflüssig.
Hat Packet nen Dispose?
Ne.
Packet ist
ein Pointer zu nem Packet.
Nein.
Das ist alles RAW.
FFmpeg Zeug.
Da wird nix Disposed.
Ne, ne.
Aber so ist ja gut.
Da hat's auch kein Memory Leak mehr.
So.
Jetzt lesen wir den Stream ein.
Und jetzt müssen wir noch checken.
Weil das Video könnte ja
Audio
und Video Streams haben.
Aber wir wollen ja nur den Video Stream.
Jetzt müssen wir checken.
Achso. Wir können übrigens mal gucken.
Packet.
Wir können mal gucken, ob da auch wirklich
immer neue Frames kommen.
Das sollte jetzt hochzählen, theoretisch.
Ja.
Also.
Das sieht gut aus.
Das sieht gut aus.
So. Jetzt müssen wir noch irgendwie überprüfen.
Ob das ein Video Frame ist.
Oder ein
Also. Ob das Packet.
Müssen wir sagen.
Ob das Packet Audiodaten oder Videodaten hat.
Weil wir wollen ja nur Videodaten an den Browser schicken.
Da
weiß ich grad nicht mehr genau
wie's funktioniert.
Irgendwie.
Also.
Ich glaub das ging über
Stream Index.
Ich glaub das ging über Stream Index.
Man musste sich im Vorfeld rausholen
welche Streams es gibt.
Gucken ob das ein Video Stream ist.
Und dann den Stream Index vergleichen.
Ja das war ein bisschen.
Ich erinner mich. Das war ein bisschen eklig.
So Streams.
Gibt's glaub ich hier.
Was ist das?
Pointer zu nem Pointer.
Okay.
Also.
Vorschleife.
Bo.
Alter.
Nerv mich.
Bo.
So.
Format.
Wie ist das?
NB Streams.
Stream gleich.
Format.
Context Streams.
I.
Jetzt konnte man hier glaub ich gucken.
Stream Type oder so.
Hä?
Hier war das drin.
Codec Parameter.
Und da gibt es jetzt Codec Type.
Und da kann man jetzt gucken
ob das wie ein Video Stream ist.
Bert Wolf.
Excellent. Trinken. Ja. Muss ich machen.
Yes. So.
Also wir wollen gucken ob das ein Video Stream ist.
Und wenn das ein Video Stream ist
dann
speichern wir den hier.
So.
Besser.
Temp ist immer mit Abstand der beste Variablen Name.
Da gibt's nix.
So. Sobald wir nen Video Stream gefunden haben
wird er gesetzt und gut ist.
Wir könnten das Ganze jetzt natürlich
auch schön machen.
Wollen wir das schön machen Leute? Soll ich euch mal zeigen
wie ich das machen würde?
Würde es nämlich ne. Oh.
So würde ich das machen. Genau so.
Achso. Ja. Ah. Lul.
Okay passt.
Ja. Also. Wisst ihr wie ich das mache?
Was machen wir normalerweise?
Ich würde jetzt wahrscheinlich ne Extension Method bauen.
Ich würde ne Extension Method bauen.
Für.
Formatkodex.
Glaube ich.
Oder?
Für Format nicht Kodex. Kontext.
Würde ich sagen.
Das probieren wir mal.
Komm wir machen heute ein bisschen.
Wir machen heute ein bisschen hübscheres.
Lass uns das mal ausprobieren.
Wir machen hier ne neue Datei.
Extensions.cs
Also.
Wer Extension Methods nicht kennt.
Wir können ja auch ab und zu mal ein bisschen.
Ich kann ja auch ab und zu mal ein bisschen was drum herum erklären.
Wer Extension Methods nicht kennt.
Das gibt es seit C Sharp.
Ne oder seit .NET 3.5 oder so.
Das gibt es ewig schon.
Das ist ne Sache die C++ beispielsweise sehr gut tun würde.
Weil man dann den Standardgramm
den die da drin haben und der Sack ein bisschen erweitern könnte.
Aber.
Zum Beispiel wenn man sich jetzt mal hier die
verfügbaren Methoden anguckt.
Oder naja Methoden ist gut.
Die verfügbaren ähm.
Felder von Format Context.
Da sieht man jetzt es gibt Streams.
Es gibt Nummer. Es gibt auch die Anzahl an Streams.
Aber was es natürlich nicht gibt.
Ist.
Irgendwas managt.
Was sich gut in .NET integriert.
Ist ja auch klar.
FFmpeg ist ne C Library.
Das heißt wenn man jetzt beispielsweise eine Liste bekommen möchte.
Mit allen Streams.
Dann muss man ne Schleife machen.
Und das ist ein bisschen unschön.
Auch ein bisschen unübersichtlich hier drinne.
Deswegen könnten wir ne Extension Method bauen.
Die alle Streams zurück gibt.
Und die können wir dann hier drauf benutzen.
Wie als wäre sie.
Bei Format Context definiert.
So.
Ich tu mir immer bei der allerersten Extension Method.
Pro Projekt tu ich mir immer schwer.
Weil ich immer Probleme hab.
Die.
Die Syntax mir in der richtigen Reihenfolge zu merken.
Also.
Es muss auf jeden Fall.
Schonmal Static sein.
So viel ist klar.
Und die Methode muss auch Static sein.
Public Static.
Ähm.
Gute Frage.
Irgendwie get.
Get Streams.
So.
Und nun muss man.
Wie war das.
Und dann AV Format.
Context.
So.
Okay.
So wenn man das angelegt hat.
Dann werdet ihr feststellen.
Sobald ich jetzt hier auf Format Context gehe.
Richtig gemacht.
Format Context.
Hier taucht meine Get Streams Methode auf.
So als wäre sie auf Format Context.
Definiert.
Das ist enorm praktisch.
Und Leute.
Hätte C++ sowas.
Wäre auf einen Schlag.
Besser.
Weil du dann den ganzen eingebauten Shit.
Den die nicht auf die Reihe kriegen.
Äh.
Über irgendwelche zusätzliche Extension Libraries fixen könntest.
Ja.
Du könntest zum Beispiel eine Default String Klasse.
Ordentliche Methoden geben.
Dass man damit auch was anfangen kann.
Man könnte beispielsweise Vector.
Und den ganzen Containern.
Ordentliche Filter Methoden geben.
Aber das geht nicht.
Weil C++ keine Extension Methods kann.
Also.
Ich finde.
Magst du Senf.
Ah du bist auch mal wieder am Start.
Ich habe heute Senf gefuttert.
Ich habe heute Nudeln mit Lachs gefuttert.
Und da war ein bisschen Senf dabei.
So so.
Süßer Senf.
In der Soße drin.
Ich hoffe du bist jetzt glücklich.
Du fragst das ja schon seit 2 Jahren.
Magst du denn C++ nicht.
Doch.
Beste.
Muss die File dafür Extensions heißen?
Nein.
Die File muss nicht Extensions heißen.
Ich nenne das einfach jetzt gerade so.
Wichtig ist.
Das hier.
Es muss in der Static Class sein.
Und es muss selbst Static sein.
Und am Anfang muss es eben.
Die das Struct.
Oder die Klasse haben.
Ich glaube für Struct geht das auch.
Das ist doch ein Struct oder?
Ja.
Das können wir jetzt machen.
Jetzt gehen wir einfach hier hin.
Und sagen Extensions Methods.
Wir kopieren uns das hier raus.
Kontext Streams Streams.
Mit Video.
Wir können es sogar filtern lassen.
Ist eigentlich auch nicht verkehrt.
Können wir hier sagen.
Noch so als Zusatzoption.
Type.
Als Zusatzoption das man das filtern kann.
So Type.
Das muss unsafe sein.
Sortieren.
So.
Was hat der jetzt für Schmerzen?
Achso.
Streams.
Stream.
Stream gleich Type.
Das können wir eigentlich fast so benutzen.
So nur mit dem Unterschied.
Das wir jetzt noch eine Liste brauchen.
Streams gleich New.
Lists.
AV Stream.
Streams.
Stream.
To��.
In Generics kann man keine P überall painter in sich ab.
Und de And am Ende.
Return Streams.
Und dass hier.
Wir wollten keine Liste
UNTERTALE cóα
Read Only.
Liste
Und sowas.
So.
Und schon.
Können wir uns
das hier alles viel einfacher machen.
Guck mal.
Wir können diesen ganzen shit hier einfach wegschmeißen.
wegschmeißen und einfach jetzt sagen
Formatkontext
GetStreams
gefiltert nach
Video
Gefiltert nach Video
und davon den ersten.
Zack.
Und schon haben wir
anstatt diesen ganzen Krempel hier
in Line stehen.
Was will der hier eigentlich von mir?
Make Enamorable.
Ne, machen wir nicht.
Anstatt diesen ganzen Krempel hier zu stehen
haben wir
jetzt was relativ übersichtliches
wo man jeder so, wo denke ich
mal jeder halbwegs versteht
was es macht.
Manchmal wünsche ich mir, ich könnte
ein paar Prämien oder so und dann sehe ich das hier
und denke mir Glück, dass ich sowas nicht mache. Wieso?
Ich verdiene damit nicht mein Geld.
Zumindest nicht.
Hauptsächlich.
Und es macht auch überhaupt keinen
doch nice sich damit zu beschäftigen.
Du musst ja nicht gleich sowas bescheuertes machen wie ich hier.
Mit drei verschiedenen Sprachen
Interop und Low Level
WebRTC
FFmpeg-Geschiss.
Das machen die meisten Leute ja auch nicht.
So, jetzt haben wir den Stream hier am Start.
Jetzt können wir das gleiche
wieder machen. Index.
Nur das ist jetzt deutlich
Okay.
Achso. Bin verwirrt.
Was ist das Problem?
Achso.
Wenn man das mal richtig schreiben würde.
Packet
Index.
So.
Und jetzt sollte es funktionieren.
Und übersichtlicher sein.
Jawoll. Er lest den Stream noch aus.
Nice. Gut.
Jetzt können wir auch schon mal
gleich probieren. So Proof of Concept
mäßig.
Ob das funktioniert.
Wir werden jetzt mal den
Stream senden
an den Browser.
Mit WebRTC.
Da bin ich enorm gespannt
ob das funzt.
Task Run. Das ist by the way nicht
the way.
Das zu machen.
So ein einzelner Task am Anfang mit nur
einem Dings und unsafe gerappt und ohne
Exception Handling und nix.
Das packen wir am Ende in irgendeinen Background
Service. Der dann automatisch gestartet
wird am Anfang. Aber zum Testen ist das ja erstmal okay.
Okay. Starten wir
das mal. Es läuft.
Unser Browser funzt auch noch.
Gut. Dann können wir jetzt mal versuchen
den Stream an den Browser rüber zu senden.
Chatgear, ihr dürft mal
grad euren Senf dazu abgeben, ob ihr denkt
dass das funzt. Wir machen mal kurz eine Abstimmung.
Geht gleich das Video
im Browser.
Ja.
Auf keinen Fall.
Bin mal gespannt. Also was wir jetzt
machen müssen ist, die Video
Frames, die wir von hier bekommen,
rüber senden über WebLTC.
Also von hier in RUST
und RUST sendet es an den Browser.
Das bringt ihr aber dann nicht die Vorteile
davon. Ich stream ja meine
Designology
streamt ja nicht über WebLTC in
den Browser. Oder, gut
vielleicht können die das auch.
Hast du im Browser ein Web Socket auf? Nö.
Warum? Ich hab ne WebLTC
Verbindung auf. Ihr seid
aber äußerst zuversichtlich, dass
das funktioniert. Also ich glaube
nicht dass es funktioniert allein schon aus dem grund weil ich nicht glaube dass
das video im richtigen format ist es zwar grundsätzlich im richtigen codec
aber wahrscheinlich nicht im richtigen format
du kannst jetzt auch mit einem java applet plugin im browser angucken von
zehn jahren china kamera 20 30 jahren china kamera also irgendwie angucken
kann man sich das immer aber du kriegst nicht beispielsweise alle deine sechs
webcams per in echtzeit auf die gleiche webseite so dann schauen wir doch mal
ob wir das rüber geschickt bekommen an web rtc also interop rast eigentlich
könnte ich den go interop teil doch mal raus schmeißen und nur noch rast oder
was hat er okay wir haben so was wie send frame das ist eine methode die gibt
schon in rast und zwar ist das die hier guckt send frame was die macht ist
folgendes die braucht als argument eine id
vom vom track für den frame gesendet wird die länge von den von den bytes und
ein pointer zu den bytes also die länge von dem von dem von den videodaten und
die videodaten an sich und dann sucht sich den track raus mit dieser id
übrigens guckt mal leute ich habe high iq rast manuell gelesen da kann man so
was hier machen
und und wenn track id was findet dann steht das in sam track ansonsten funks
das nicht habe ich habe ich im rast in diesem rast handbuch handbuch gefunden
so und was der macht der nimmt sich die länge der nimmt sich den pointer u8 ist
ein byte in rast weil es gibt keine bytes in rast es gibt nur u8 also unsigned im prinzip unsigned 8 bit man könnte sagen
halt ein byte aber in
in rast ist es u8 ich weiß es gibt bestimmt auch je 8 oder
so gibt es nicht es ist aber es ist halt ein sehtimately ist halt ein byte und
dann kann man sagen man möchte einen slice bauen dass das rast logik von aus
den raw parts die raw parts hinter pointer und die länge und das hat den
vorteil wenn man da einen slice daraus baut das ist nicht kopierbar
.
Sch rarely a ask or don't know the wrong助
werden muss. Ein Slice
ist in Rust quasi
so ein Managed, das ist das falsche Wort,
ein halbwegs
Memory-Safe-View
auf
Speicher. Nachdem das
ja hier mit Pointer-Magic ist, musst du das
auch in Unsafe-Rust machen.
So, und danach
baut er ein Video-Sample draus.
Das habe ich mir in der Hilfe angeguckt von der Library.
Bei Data
muss der Byte-Slice
gesetzt werden. Und bei
Duration, da bin ich noch ein bisschen
planlos, bei Duration
habe ich im Example gefunden, eine Sekunde.
Aber das ergibt ja keinen Sinn.
Weil ein Frame
ist ja bei
60 FPS
nicht eine Sekunde lang.
Das ergibt ja keinen Sinn.
Und dann schreibt
das in den Track und schickt es an den Browser.
Rust das Spiel.
Ja, genau.
Ich spiele...
Wir bauen gleich die Base.
Ich habe, ehrlich gesagt, Leute, ich habe noch nie
Rust gespielt. Ich kenne das nur aus ein paar Videos.
Aber das ging voll an mir
vorbei. Ex-Kolleg von
mir auf der Arbeit, müsst ihr euch mal
vorstellen, der war
voll im Rust-Game
am Start.
Und der hat das auf der PS4
gespielt. Und er hat
auf das mal Nachtschicht gehabt. Und er hat
zur Nachtschicht seine PS4
mitgebracht auf die Arbeit.
Und hat dann dort auf dem großen Fernsehen
Rust gespielt.
Also soweit der Rust-Part. Ich hoffe,
das klappt, was ich mir hier
ausgedacht habe. Ich glaube, so
kurz war der Rust-Hype gar nicht.
Es gibt immer noch Channels, die ziemlich viel
Views damit generieren.
Ich glaube, das hat immer noch ziemliche
Dedicated-Follower.
Was einen kurzen Hype hatte,
warum Ex-Kollege?
Weil ich nicht mehr da arbeite.
Es gab doch von den Rust-Herstellern
so Nachfolge-Games.
Das hat, glaube ich,
nicht so viel Anklang gefunden.
Gucken wir mal, was Rust
Sorry, Leute.
Ich habe euch Mist erzählt.
Der hat gar nicht Rust gespielt.
Der hat nicht Rust gespielt.
Ich habe das verwechselt.
Der hat, äh, wie heißt das
Survival-Dings? Ark
hat der gespielt. Nicht Rust.
Gibt es Rust überhaupt auf der
PS4? Was ich entwickle?
Dass du Webcam-Streams
per WebRTC in den
Browser schicken kannst.
Ey, Rust hat
saumäßig viele Spieler noch.
Ark hat der gespielt.
Oder Ark...
Nicht Arch-Linux.
Hat auch noch.
Ist jetzt auch nicht übel, oder?
Weil Rust ist natürlich...
Aber ist auch nicht übel für so...
Weil das Game ist jetzt ja auch nicht...
Warum gibt es denn da...
Ist das ein neuer Part?
Äh.
Was ist denn da der Unterschied?
Das gibt es erst neu.
Also das hat sich auch gut gehalten.
Ihr kann es nicht sagen.
Da sieht man halt wieder, was langlebige
Games ausmacht.
Das gab es auch noch? Ich blick da nicht durch.
Was zum Teufel?
Survival of the fittest?
Das ist ein Battle Royale-Ark, oder was?
Ich blick da nicht mehr durch.
So, machen wir mal weiter.
Send Frame.
Okay, schauen wir mal, ob das
funzt. UID.
UID, äh, Track ID. Track ID weiß ich.
Das ist die Track ID von oben.
Länge.
So, jetzt wird es
etwas komplizierter.
Packet.
Wenn ich das richtig in Erinnerung habe,
es gibt in...
Es gibt in dem Packet
einmal Data und Size direkt
und es gibt
Buffer Data und Size.
Ich bilde mir ein,
dass ich damit schon mal
Tage verbracht habe, zu debuggen,
warum ein Video nicht richtig funktioniert.
Boah, zwei, drei Jahren.
Und ich bilde mir ein,
dass Data aus Packet
direkt
nicht richtig
benutzbar war,
aber Data aus dem Buffer
aus irgendwelchen Gründen
gut funktioniert hat.
Ich kann euch nicht erklären, warum.
Ich weiß nur, dass ich da tagelang
rumprobiert habe.
Deswegen nehmen wir das jetzt gleich mal hier.
Da gibt es auch...
Buffer und Data und Size.
So, Size brauchen wir.
Also, was brauchen wir als erstes?
Size und
Data.
Okay, Funze aus irgendwelchen Gründen nicht,
weil Byte Sternchen ist not assignable
to Endpointer.
Dann werden wir einfach...
Moment.
Dann werden wir das einfach casten zu Endpointer.
Das ist ja nur mit casten los.
Dann funktioniert das.
Okay.
Also, von der Theorie her,
sollten jetzt Daten
von
meinem Backend an den Browser
geschickt werden.
Ich lasse hier noch mal kurz was ausgeben,
dass ich auch weiß, dass der das
immer, immer schickt.
Und jetzt müssen wir
die Frontend-Seite bauen.
Also, nach dem Verbindungsaufbau
werden auf jeden Fall Daten an den Browser geschickt.
Jetzt müssen wir dem Browser noch beibringen...
Geh mal weg.
Jetzt müssen wir dem Browser noch beibringen,
diese Daten in das Video,
hier in den Videoplayer zu schreiben.
Ähm, oh, wie ging das nochmal?
Also, wir bekommen den Videotrack
irgendwo...
Irgendwo hier, Track.
Hier. On Track.
Und den Track, den kann man
irgendwie setzen. Ich weiß aber wirklich nicht mal genau,
wie. Da müssen wir mal das Internet
befragen gleich.
Wie man das hier als
Daten setzt für den
Videoplayer.
War arg nicht übel, unperformant.
Ja, aber das...
Arg ist auch alt. Mittlerweile
wird es wahrscheinlich auch auf ordentlicher
Art und Weise ganz gut laufen.
So, also. Document.
Get Element
by ID. Pass auf, hier. Richtiger
Frontend-Champ wieder am Start.
Let Player.
So.
Und jetzt weiß ich
nicht weiter. Player?
Okay, das muss ich im Internet nachgucken.
Video Element
WebRTC Set Stream.
Changing Moving
Video Element.
Ne.
What? Was?
Nein.
Das ist auf jeden Fall... Okay.
Was macht der Dude hier überhaupt?
Was macht er hier?
Das da. So was brauche ich.
Genau.
So was. So was in der Richtung. Okay.
Also.
Ja.
Source Object.
Gibt das sowas hier? Source Object?
Moment.
Null? Okay, das heißt aber
das gibt es, oder?
Wobei es ist JavaScript. Shit.
Man weiß nicht, ob es das gibt.
Okay. Source Object?
Und was jetzt?
Web... Okay. Wie?
Oh, meine Güte.
Ähm.
Track. Was hat denn dieses
Track-Element hier drinne?
Streams.
Track.
Was ist jetzt der Unterschied zwischen dem Track und dem Stream?
Track.
Track.
Stream.
Was? Media Stream Track?
Und hier oben gibt es ein Array mit
Media Streams.
What the fuck? JavaScript.
Wer denkt sich den Scheiß immer aus, Alter?
Und was davon soll ich jetzt benutzen?
Streams.
Okay. Track.
Kein Video.
Okay. Wir verwenden Track.
Player.
Player. Source Object.
Ah, nee, nee, nee.
Okay. Wir brauchen doch... Ich glaube, ich glaube, wenn ich es mir recht...
Ich glaube, wenn ich es mir recht überlege, brauchen wir wahrscheinlich doch den Stream,
weil ein Track kann mehrere Streams enthalten.
Also brauchen wir wahrscheinlich doch den Stream.
Ich denke, wir brauchen doch den Stream.
Aber wir probieren es mal aus. Wir setzen mal Track.
Gucken, was dann passiert.
Uncored. Track is not defined.
Ach so. Ja.
Track.
Äh, was?
Fail to set Source Object. Ja. Toll.
The provided value is not of type Media Source Handler or Media Stream.
Okay. Hey. Okay.
Leute, wir sind nicht die einzigen, die den Fehler machen.
Sonst hätten die im Leben nicht diese idiotensichere Fehlermeldung eingebaut.
Dass man weiß, man muss das andere verwenden.
Na gut, idiotensicher ist bei JavaScript nix.
Nee. Funst nicht. Shit.
Zedke.
Zedke!
Das wäre jetzt auch zu einfach gewesen,
wenn das Video einfach anfängt zu spielen.
Ich weiß nicht woran es liegt.
Entweder liegt das daran, dass das Video in der F...
Okay. Warte.
mal was was für einen codec hatten das wie also er nicht codec was für ein geht
es jetzt eigentlich von vorne los für mich wartet war aber ff probe main dass
das video ist er hat den falschen das falsche profil aber ffm pack
constrained base oder sowas base ist das doch oder constrained base line profil
was man braucht dafür wobei es eigentlich auch so funktionieren sollte
du musst glaube ich wohl create media uhr ne glaube ich nicht ich habe das ja
auch schon gemacht und ich bilde mir ein so wobei ich habe das schon gemacht
warum gucke ich einfach nach best logo gucke ich einfach nach source ist es
noch eine view gs app man
stettage baut man views home streams ach das habe ich mit magic view sachen
immer streams cam id und kommt streams her
kraft ql max was zum teufel habe ich da auf
reingeniert kraft ql
ok ich keine ahnung ich check's hier
ok ich keine ahnung ich check's hier
ok ich keine ahnung ich check's hier
ich war stark über North
ich war stark über North
ich war stark über North
ok
ich das das war wir haben ok ich muss das war ich muss das ich muß das wars
noch malerweise nicht wirken ich nicht notwendig ich bin mir aber nicht sicher
ob ich es organisations muss ich finde mir ein ich habe auch schon video video
streams mit main profil ok input mein mp4 profile high missionなんです
profile baseline level ist mir vollkommen egal copy audio haben wir nicht wir machen audio nun
und ja output mp4 wunderbar was also copy geht ja nicht was das super lahm wobei geht eigentlich
hat 264 ffm pack very fast kommt man auch setzen preset preset very fast preset ultra fast super
fast very fast meine güte jetzt übertreibt es halt mal ffm pack okay es ist okay ich habe
nichts gesagt es ist doch deutlich schneller ultra fast das ist auch rücken in rast blazing
die fahrt
das flutscht das flutscht schon schon vier minuten vom video einfach encoded das video
selbst war nicht so lang dass das video wieder war das video irgendwie sieben minuten oder sowas
also gucken wir mal output ist mein vlc irgendwie ein bisschen im arsch kann das sein ff player
hat überhaupt keine probleme mit dem video okay also dann probiere es doch mal mit output
wir uns doch mal mit dem anderen ffm pack stream loop output mp4 output mp4 deine augen sehen ffm
pack auf der command line und ffm pack c library so schauen wir mal ob es jetzt funktioniert
präge time präge chat präge
chat rail
nutrition
so
passt
ok
what
last
你是
ist
testen wir mal was wir sagen hier from minic Sing program
das video hat glaube ich 60 fps 60 fps heißt ein frame alle 16 millisekunden korrekt quick
maps nein ich weiß es aus dem kopf das sind 16,6 millisekunden also ich hab das nicht ich
habe sie ausgerechnet okay formel ist aber einfach mal 16 millisekunden okay gucken ob es jetzt funst
decken sich denn überhaupt bei meine argumente hier okay all die länge pointer all die länge
pointer passt was ist damit millisekunden hier cargo bild ja aber das muss auch so funktion
weil die china chinesen streams von den kameras die entsprechen auch keinen standards
ok prege prege oft warum jederzeit was mache ich okay ich mache was verkehrt ich muss ich
muss irgendwas verkehrt machen weißt du etwas okay wir starten wir das hier neu und wir starten wir
das hier neu okay okay alles klar okay mal gucken mal gucken ob auch das richtige hier passiert so
buffer
wie groß das ist was der da aus liest ob das überhaupt
irgendwie schlüssig sinne gibt okay war fast da ist das einmal so 15 15 15 k oder so 20k
oder sowas als funzt es klappt nicht ist ja ganz schön scheiße mann umgeht das nicht jetzt
bin ich gerade etwas kommen wir gucken ob ein firefox geht firefox der matte ein bisschen um
Umgänglicher.
Show Controls.
Okay.
Da geht nix.
Aber warum geht da nix?
Liegt es an meinem Video?
Liegt es an meinem WebRTC-Kram?
Bei dem OnTrack bekommst du dann nur ein Track und ein Medias...
Medias...
Äh, ein Track.
Ich bekomme ein Track, in dem Mediastreams drin sind.
Guck da.
Dann nehme ich den ersten davon.
Mal gucken, was ist, wenn man den...
Wenn man den ausgibt, was JavaScript dann da sagt.
Das ist Streaming-Plattform.
What?
I don't understand the question.
C-Sharp im Backend.
Ja, Backend und Rust.
Backend im Rust...
Back...
Im Backend C-Sharp und Rust.
A type of project.
I try to read RTSP-Streams from China Webcams, from China Cameras.
And extract the frames and send it via WebRTC to the browser.
I have already implemented something similar in Go and it works, but in Rust it does not work.
So, aus irgendwelchen Gründen funzt das nicht.
Woran könnten das liegen?
Hier, Mediastream.
Active.
True.
Lulwe.
Also ich...
Warum beides?
Warum nicht?
Warum nicht?
Ach so, du meinst...
Warum Webframework in C-Sharp und WebRTC in Rust?
Das ist ganz einfach, weil ich keinen Bock habe, mir mehr als notwendig in Rust anzutun.
Ich würde mal sagen...
Nachvollziehbar, ne?
Ich würde mal sagen, dass mein Frontend-Zeug...
Ich weiß nicht, ob mein Frontend-Zeug funktioniert.
Das ist das Problem.
PlayerSourceObject.
Also ich würde mal drauf tippen, mein Frontend-Shit funktioniert halbwegs.
Frontend...
Noch mit Go testen.
Den Part habe ich hier in Go nicht eingebaut.
In VLC testen.
VLC funktioniert gar kein Problem.
Ja, guck.
Aber VLC geht ja auch einen komplett anderen Weg.
Okay, VLC FF Play.
Das geht ja auch einen komplett anderen Weg.
Das geht direkt auf meinen Test-RTSP-Stream.
Ja, ja.
Und nicht über WebRTC.
Okay.
Gehen wir einfach mal von aus...
Mein...
Mein Frontend-Zeug funzt, okay?
Wir tun einfach mal so.
Okay, mein Frontend-Kram tut.
Was könnte kaputt sein?
Mein FFM-Pack-Zeug könnte kaputt sein?
Oder mein Rust-Zeug könnte kaputt sein?
Ich konnte ja beides nicht testen bis jetzt.
Äh...
Ja...
Also ich glaube, der hat Schmerzen mit der Duration.
Wobei 16 Millisekunden ziemlich gut hinkommen.
Lass uns das doch mal ausrechnen hier in .NET.
Das hier...
Das hier stimmt.
Alles okay.
Lass uns das doch mal ausrechnen.
Es gibt doch...
Es gibt doch hier eine Package-Duration oder sowas in der Richtung.
Genau.
Rust-App-Kompiliert.
Also passt das.
Die Chancen sind bei Rust so hoch wie bei keiner anderen Sprache, ja?
Okay.
Es ist immer...
Tausend...
Fünfundhundert.
Moment, ist das Video überhaupt 60 FPS?
FF Probe.
60 FPS.
Okay.
Wir rechnen einfach mal die Duration aus, okay?
Also...
Wie ging das jetzt nochmal?
Ist sonst...
Okay, lass mal überlegen.
Ist sonst irgendwas...
doof von dem, was ich hier mache?
Es ist auf jeden Fall ein Videostream.
Es gibt ja auch nichts anderes als Videostreams bei mir gerade hier drinnen.
Also mir fällt jetzt echt nicht ein, woran das liegen könnte.
Okay, lass uns mal die Duration...
Ich tippe immer noch auf die Duration.
Lass uns mal die Duration ausrechnen.
Also in Millisekunden.
Duration of this package in...
Moment, was?
Moment, was?
Duration of this package in AV-Stream time-based Units.
Okay, so eine Duration in Millisekunden oder Mikrosekunden wäre auch, glaube ich, deutlich zu einfach gewesen.
Aber es ist FFM-Pack, die haben wahrscheinlich echt einen guten Grund dafür.
Also in was?
In Stream?
Time?
Was?
Timebase.
Kannst du schauen, ob was im Client ankommt über den Netzwerk-Tab?
Du hast...
Das ist eine gute Idee.
Nicht über...
Das ist eine wirklich gute Idee.
Nicht über Netzwerk-Tab.
Und Netzwerk-Tab geht das nicht mit WebRTC.
Aber wir können in den WebRTC...
In der WebRTC-Analytik, in der Analytics-Seite gucken, ob was ankommt.
Irgendwo hier.
Wenn ich jetzt wüsste, wie.
Oder kommt das nur auf Firefox?
Hier, Stats-Graph.
Stats for Transport.
Guck mal hier.
Bytes sent.
Bytes received.
Der kriegt was.
Guck mal.
Der kriegt Videodaten.
Nur zeigt er nichts an davon.
Okay.
Okay, er kriegt Videodaten.
Das ist schon mal gut.
Das ist eine gute Idee gewesen.
Also, das Streamen von was auch immer funktioniert.
Machen wir das Ganze nochmal.
Ich kommentiere das mal aus.
Und wir starten das jetzt nochmal.
Ich glaube, ich habe irgendwas einfach eben bei mir verkehrt.
Oh.
Crafts.
Okay, jetzt wird nichts received.
Was richtig ist...
Okay, es ist auch viel weniger hier.
Jetzt wird nichts mehr received.
Großartig, weil ich habe es ja auch auskommentiert.
Okay, lassen wir es mal einkommentiert.
Okay, woran könnte das Ganze liegen?
Duration.
Wie rechnet man diese Kack-Duration aus?
In Time-Base-Units.
Was?
Oh.
Oh ne, Quick-Muffs.
Complex Numbers.
Was ist denn?
Und was ist Num in dem Fall?
90.001, okay.
Muss man die Frames terminaten oder so?
Normalerweise nicht von Hand.
Das macht eigentlich die Library für einen.
Ich gehe davon aus, dass hier irgendwas stimmt hier nicht.
Also, lass mal die Duration ausrechnen von so einem Frame.
Die Frage ist, wie rechnet man die Duration von so einem Frame aus?
Also, ich habe aus irgendwelchen Gründen...
...habe ich jetzt hier die Infos 90.001.
Und Duration 1.500.
Zweimal Result?
Ne, das ist kein Problem.
Wir sollten aber, Chatge, wir sollten aber...
...tatsächlich...
...das mal überprüfen, ob das Result...
...ob das Result...
...auch wirklich 0 ist.
Weil, weil, wenn es nicht 0 ist, dann klappt das Lesen des Streams nicht.
Das Result ist 0.
Okay, das Lesen vom Stream funzt.
Äh, funktioniert, okay.
Das wäre jetzt zu einfach gewesen, wenn da irgendwas...
So, wir machen das auch nochmal anders.
Wir sagen hier, if...
...wenn das hier nicht gleich ist, dann sagen wir continue.
Ein bisschen einfacher zu lesen hier unten.
Okay, so.
Also, wie rechnet man diesen Krempel aus, Mann?
Wie rechnet man das aus?
Da muss ich Google befragen.
Okay.
FFM-Pack?
Packet, Duration, Time, Base.
Time base working for video, okay.
How to set duration always 0.
Question about packet duration.
Gucken wir mal.
Seconds, irgendwie.
Kein Plan?
Keine Ahnung.
Ey, gibt das Sinn?
Ich weiß nicht, ich kann das mal machen.
Ich hab...
Ich hab...
Ich hab es jetzt noch gar nicht gecheckt, was mir diese Sachen überhaupt sagen sollen.
Aber wenn der Chat das meint, wir können es mal ausprobieren.
Also, was meinst du?
Ja.
War.
Neue.
Duration.
Millisekunden.
Also, was jetzt hier?
Stream.
Time base.
Num.
Durch.
Stream.
Time base.
Denn.
Die Camps stehen in China.
Nein.
Das sind Chinesen, China-Chinesen-Camps.
Die.
Von.
Von.
Chinesen Herstellern.
Okay, Duration Millisekunden.
Da sollte irgendwas wie 16 rauskommen jetzt.
Null.
Nice.
Ah, ich weiß, woran es liegt.
Der ist wieder zu dumm.
Das sieht nicht richtig aus.
Naja, wobei, warum eigentlich nicht?
Das sind Sekunden jetzt, oder?
Und was ist, wenn man das hier umdreht?
Nicht, dass ich wüsste, was ich mache, oder so.
Äh, nein.
Das funktioniert nicht.
Moment, Moment, Moment.
Da fehlt ja auch Package, da fehlt ja auch noch Package Duration in dem Ganzen.
Moment, Moment, Moment.
Moment, Moment, Moment.
Package Duration fehlt ja da noch.
Da muss ich.
Packet.
Hier.
Packet Duration.
Mal.
Das da.
Okay, so.
Und das sollte jetzt die Duration pro Package.
60 FPS hat das Video.
Das sieht gut aus.
Das sieht gut aus.
16 Millisekunden, sage ich doch.
16 Millisekunden.
Dü, dü, dü, dü.
16 Millisekunden.
Das sieht gut aus.
Das Dumme ist nur, dass ich 16 Millisekunden eingestellt habe in Go schon.
So, ziemlich hardcoded.
Äh, nicht in Go.
In Rust.
Vielleicht ist mein Video aber auch einfach kacke.
Was ich hab.
Wobei, ich hab's, wobei, ich hab's, ich hab's re-encoded mit FFM-Pack.
Also, da hätte ich eigentlich vermutet, dass
Funst besser
stream ich überhaupt das richtige Video?
Ja, mach ich.
Gibt's da keine Sample-Videos?
Doch, sicherlich, sicherlich.
Aber ich wüsste nicht, welche.
Stimmt.
Gibt's solche.
Okay, komm.
Wir machen jetzt einfach mal hier.
Duration?
Nee, nee, nee, nee, nee, nee.
Keine Rust-Duration.
Äh, Duration, äh, Double.
Ähm, oh.
Alter.
Was ist ein Double?
Ein Bloat?
Ein F64 oder sowas?
Okay.
Okay, Duration.
Was will er nicht?
Oh, grad hit.
Ey, ernsthaft?
Er frisst keine Floating-Point-Units bei Duration?
Was ist das schon wieder für ein...
...Schrott?
Musst du das jetzt selbst umrechnen, oder was?
Was haben wir denn da zu bieten?
From?
From Seconds, from Millis, from Mic...
Okay, from Micros.
From Micros.
Also, also, okay.
Äh, let Micros, Mikros.
Äh, Duration mal, äh, mal Tausend, hä?
Pfeifert, what?
What?
Cannot multiply F64 mit Int.
Oh Gott.
Rust.
Rust!
Ähm.
Debated!
Ach shit, jetzt geht das andere nicht.
Und der, und der will, der will ja keine Floats.
Rust!
Please, mach's mir doch nicht so schwer immer.
Hi, vielleicht jeder in zwei, jeder zweimal fragt.
Ja, das kommt öfters vor, aber das macht nix.
Aber was empfiehlst du als erste Programmiersprache?
Mit welcher hat man mehr Arbeitsperspektive?
Python oder JavaScript?
Ich bin 28 und will meinen Job programmieren.
Ähm, also.
Beides ist gut zum Einstieg.
Ich empfehle JavaScript zum Einstieg aus dem einfachsten Grund, aus dem ganz einfachen Grund,
weil JavaScript die noch kleinere Einstiegshürde hat.
JavaScript brauchst du, zum Beispiel Studio Code und Browser.
Fertig, kannst du anfangen.
Und du lernst ein bisschen Frontend-Zeug, was auch ganz nice ist, weil man das immer braucht.
Egal was man macht.
Ein bisschen Frontend, CSS, JavaScript, HTML brauchst du immer.
Es ist schade, definitiv nie sich damit auszukennen.
Ja.
Ja.
Und du siehst halt visuell auch was, wenn du was baust.
Ich würde dir gar kein JavaScript-Framework empfehlen, wenn du erst anfängst.
Einfach ein bisschen sich die Sprachbasics angucken.
Du kannst aber auch mit Python anfangen.
Es sind beide gute Sprachen zum Einstieg.
Es gibt noch mehr gute Sprachen zum Einstieg.
Solange es nicht gerade C++ ist oder sowas.
Die Sprache ist noch nicht mal, also weder für Einstieg noch für irgendwas anderes gut.
Aber Python und JavaScript ist beides nice.
Ich würde dir gar kein JavaScript-Framework empfehlen, wenn du erst anfängst.
Ich würde sagen, wenn du dir schon grob vorstellen kannst, auf was du Bock hast,
dann würde ich die Sprache danach aussuchen.
Also wenn es dir mehr ist nach Frontend-Sachen oder vielleicht Node.js.
Bei Node.js, nun ja, mein Favorit ist es ja nicht.
Dann JavaScript, wenn du vielleicht irgendwas AI- und Machine-Learning-mäßiges machen willst.
Oder bei den hippen Leuten sein willst, dann eher Python.
Also.
Hängt ein bisschen von deinen Vorlieben ab.
Es ist beides gute Einsteiger-Sprachen.
Ich persönlich würde JavaScript empfehlen, weil die Einstiegshürde geringer ist.
Was für ein JavaScript.
Also wie gesagt, ich würde, wenn du anfängst, gar keins empfehlen.
Ansonsten mittlerweile Svelte.
Svelte ist mein Lieblings-Framework zur Zeit.
Gut.
So, das müssen wir jetzt erwarten.
Okay.
Wie kriegt man das jetzt hin?
Wie kriegt man das in Rust hin?
Ein Float.
Okay.
Rust.
F64 to U64.
Ja.
Jawoll.
Das will ich haben.
Looks like F64 2-Bits.
Obviously.
Was sonst?
Ganz klar, dass diese Methode dafür benutzt werden muss.
2-Bits U64.
Alter.
Ist was komplett anderes, wirklich?
Convert.
Doch, das.
Oder?
Doch, das ist.
Das ist das, was.
Reinterpret.
U64.
Doch.
Raw Transmutation to U64.
Wobei.
Ne.
Ne.
Das ist nicht das, was ich haben will.
Du hast recht.
Der.
Dann habe ich auf einmal eine riesengroße Nummer.
Da habe ich nicht 16, irgendwas, sondern ich habe.
Was bekomme ich denn dann da raus?
16 Milliarden oder so.
Okay.
Chat.
Chat.
Das muss ich jetzt mal ausprobieren.
Ich habe keine Ahnung, was da jetzt rauskommt.
Sind.
Brindeln.
Zu.
Putz.
Rast.
Was jetzt?
Na ja.
Duration.
Ration.
Duration.
Okay, ist halt hier.
Oh.
Massive, dann müssen wir das Ganze in dort nicht noch schnell
anpassen, dass das funktioniert.
Doppel.
Duration.
Und jetzt Duration.
Sei ich egal ins Fall.
Wir verwenden es immer.
noch nicht.
Ich will jetzt bloß gucken, was der ausgibt.
Uh!
Nein, das ist echt nicht das, was ich
hab.
Der nimmt einfach die Bits und castet
quasi zu einem
1 zu 1. Das ist wirklich nicht das, was ich haben will.
Ach!
Oh mein Gott, das sind
From Seconds. Ich hab's doch
als Milliseconds.
Alter, Rast!
Was? Into? What?
Okay. Into?
Ne, ne, ne.
Chat, so einfach
geht das nicht.
Ihr habt gesagt, ich soll
machen SU64.
Can be replaced?
Ach so, ja, ja.
Mikros.
Nice. Chat,
ihr wisst Bescheid.
Pass auf, ich wette, es geht
immer noch.
Shit! Man, es funktioniert nicht.
Okay, jetzt glaube ich, dass es doch
am Video liegt.
So, Packages werden auch geschickt.
Okay, okay.
Jetzt könnte es
echt am Video liegen,
was ich schicke. Das ist irgendein
Mist. Versuche, ein Standbild
zu senden. Ich brauche ein Standbild
im richtigen Format. Das ist halt das Ding.
Mein H2...
Warte mal.
FFM-Pack. Wie hab ich das?
Das sieht doch
eigentlich gut aus. Das ist alles
ziemlich 0 nach 15. Das müsste funktionieren.
Oder es liegt
am Frontend. Ja, ich schiebe noch mal
das andere Video rein.
Ne.
Ach, Kacke. Alter, warum geht das nicht?
Ne. Aber
das stimmt quasi. Ich meine, es sind zwei Zeilen
im Frontend. Guck mal hier, so, Video.
Wo setzt er das denn? Was?
Es ist outdated, overrated,
she baited, oder?
Das Source Object gibt's.
Okay, wir machen das mal so. Aber ich glaube nicht,
dass das besser von...
Äh, FFM-Pack.
Äh, das funktioniert nicht.
Das ist schon richtig
so hier.
Ich hab das ja schon mal gemacht. Das sieht
sehr nach dem aus, was ich in Erinnerung hab.
Ich glaube nicht, dass das...
Muss man überhaupt so
das jetzt machen, oder?
Gibt's nicht. Öffnen wir das mal
in Firefox. Okay, ID Player.
Funzt das denn überhaupt hier?
Warte mal.
Findet er hier was, was Player heißt?
Video Player. Autoplay,
Muted Place. Okay, sieh was?
Wir machen Autoplay mal weg. Wir machen
Muted, Muted Place, Inner und Controls
anzeigen. Ja, okay.
Oh, der Scheiß funktioniert nicht.
Source Object.
Ja.
Stream.
Und wo kriegt der Stream her?
Get User Media.
Ja. Okay, das ist schon
richtig, was ich mache. Gut.
Get User Media hab ich nicht, weil
das ist ja von der Webcam.
Ja, also es ist Source Object.
Was ist das denn?
Oh, ein Funst, das Netz.
Öffnen wir in Firefox.
Haben wir doch vorhin schon gemacht.
Ne.
So, Chat.
Ich hab keine Ahnung.
Ich habe keine Ahnung, was der für Schmerz...
